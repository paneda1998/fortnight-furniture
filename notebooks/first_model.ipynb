{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "# Keras imports\n",
    "from keras.models import  Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import glob\n",
    "\n",
    "from loader_bot import LoaderBot\n",
    "from splitter import get_skfold_data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/DeepLearningSandbox/DeepLearningSandbox/blob/master/transfer_learning/fine-tune.py\n",
    "\n",
    "IM_WIDTH, IM_HEIGHT = 299, 299 #fixed size for InceptionV3\n",
    "NB_EPOCHS = 3\n",
    "BAT_SIZE = 32\n",
    "FC_SIZE = 1024\n",
    "NB_IV3_LAYERS_TO_FREEZE = 172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_to_transfer_learn(model, base_model, lr=0.0001):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(optimizer=SGD(lr=lr, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    \"\"\"Add last layer to the convnet\n",
    "    Args:\n",
    "    base_model: keras model excluding top\n",
    "    nb_classes: # of classes\n",
    "    Returns:\n",
    "    new keras model with last layer\n",
    "    \"\"\"\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(FC_SIZE, activation='relu')(x) #new FC layer, random init\n",
    "    \n",
    "    predictions = Dense(nb_classes, activation='softmax')(x) #new softmax layer\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def setup_to_finetune(model):\n",
    "    \"\"\"Freeze the bottom NB_IV3_LAYERS and retrain the remaining top layers.\n",
    "    note: NB_IV3_LAYERS corresponds to the top 2 inception blocks in the inceptionv3 arch\n",
    "    Args:\n",
    "    model: keras model\n",
    "    \"\"\"\n",
    "    for layer in model.layers[:NB_IV3_LAYERS_TO_FREEZE]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    for layer in model.layers[NB_IV3_LAYERS_TO_FREEZE:]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "def get_nb_files():\n",
    "    file_paths = glob.glob(\"../data/stage1_imgs/*.jpg\")\n",
    "    \n",
    "    return file_paths\n",
    "\n",
    "def y_labels(file_paths):\n",
    "    train_img_files = get_nb_files()\n",
    "\n",
    "    y = np.zeros(len(nb_train_files), dtype=np.int16) # lol int8 overflowed at 128th label resulting in -128\n",
    "\n",
    "    for idx, file in enumerate(train_img_files):\n",
    "        # ex file: '../data/stage1_imgs/5766_86.jpg'\n",
    "        y[idx] = int(file.split(\"/\")[-1].split(\".\")[0].split(\"_\")[-1])\n",
    "        \n",
    "    return y, train_img_files\n",
    "\n",
    "def give_labels_get_dummies(y):\n",
    "    '''\n",
    "    y comes in as a list of ints from 1 to 128\n",
    "    \n",
    "    returns one hot matrix of the y values\n",
    "    '''\n",
    "    return pd.get_dummies(y.loc[:, \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_link_dict = get_skfold_data()\n",
    "\n",
    "# Parameters for Generators\n",
    "params = {'dim': (299,299),\n",
    "          'batch_size': 64,\n",
    "          'n_classes': 128,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': False}\n",
    "\n",
    "# Datasets\n",
    "X_train_img_paths = data_link_dict[\"X_train_1\"]\n",
    "y_train = data_link_dict[\"y_train_1\"]\n",
    "\n",
    "X_test_img_paths = data_link_dict[\"X_test_1\"]\n",
    "y_test = data_link_dict[\"y_test_1\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "training_generator = LoaderBot(X_train_img_paths, y_train, **params)\n",
    "validation_generator = LoaderBot(X_test_img_paths, y_test, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2570/2904 [=========================>....] - ETA: 1:20 - loss: 1.5509 - acc: 0.5890"
     ]
    }
   ],
   "source": [
    "# setup model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
    "model = add_new_last_layer(base_model, 128)\n",
    "\n",
    "# transfer learning\n",
    "setup_to_transfer_learn(model, base_model, lr=0.01)\n",
    "\n",
    "history_tl = model.fit_generator(generator=training_generator,\n",
    "                                 validation_data=validation_generator,\n",
    "                                 epochs=2,\n",
    "                                 use_multiprocessing=True,\n",
    "                                 workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
