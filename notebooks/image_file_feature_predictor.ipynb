{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/metadata_splits.json\") as infile:\n",
    "    data = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aspect_ratio': 1.0,\n",
       " 'b_accum_err': 0.017017211562164382,\n",
       " 'b_mean': 164.05480625,\n",
       " 'file_size': 94648,\n",
       " 'g_accum_err': 0.017224911024578352,\n",
       " 'g_mean': 163.66376875,\n",
       " 'h': 800,\n",
       " 'path': '../data/stage3_imgs/70691_65.jpg',\n",
       " 'pix_pb': 6.761896712027724,\n",
       " 'pixels': 640000,\n",
       " 'r_accum_err': 0.01741619515134654,\n",
       " 'r_mean': 166.2122390625,\n",
       " 'w': 800}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"X_train_1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['path', 'h', 'w', 'pixels', 'aspect_ratio', 'file_size', 'pix_pb', 'r_mean', 'g_mean', 'b_mean', 'r_accum_err', 'g_accum_err', 'b_accum_err'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"X_train_1\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data[\"X_train_1\"], columns=['h', 'w', 'pixels', 'aspect_ratio', 'file_size', 'pix_pb', 'r_mean', 'g_mean', 'b_mean', 'r_accum_err', 'g_accum_err', 'b_accum_err'])\n",
    "X_test = pd.DataFrame(data[\"X_test_1\"], columns=['h', 'w', 'pixels', 'aspect_ratio', 'file_size', 'pix_pb', 'r_mean', 'g_mean', 'b_mean', 'r_accum_err', 'g_accum_err', 'b_accum_err'])\n",
    "y_train = np.array(data[\"y_train_1\"])\n",
    "y_test = np.array(data[\"y_test_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h</th>\n",
       "      <th>w</th>\n",
       "      <th>pixels</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>file_size</th>\n",
       "      <th>pix_pb</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>r_accum_err</th>\n",
       "      <th>g_accum_err</th>\n",
       "      <th>b_accum_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>640000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94648</td>\n",
       "      <td>6.761897</td>\n",
       "      <td>166.212239</td>\n",
       "      <td>163.663769</td>\n",
       "      <td>164.054806</td>\n",
       "      <td>0.017416</td>\n",
       "      <td>0.017225</td>\n",
       "      <td>0.017017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>541</td>\n",
       "      <td>590</td>\n",
       "      <td>319190</td>\n",
       "      <td>1.090573</td>\n",
       "      <td>39796</td>\n",
       "      <td>8.020655</td>\n",
       "      <td>162.796294</td>\n",
       "      <td>158.073473</td>\n",
       "      <td>153.525897</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.006235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>640000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54903</td>\n",
       "      <td>11.656922</td>\n",
       "      <td>211.940197</td>\n",
       "      <td>208.954892</td>\n",
       "      <td>207.897623</td>\n",
       "      <td>0.013972</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>0.016104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>498</td>\n",
       "      <td>750</td>\n",
       "      <td>373500</td>\n",
       "      <td>1.506024</td>\n",
       "      <td>45580</td>\n",
       "      <td>8.194384</td>\n",
       "      <td>142.680809</td>\n",
       "      <td>142.629668</td>\n",
       "      <td>144.688286</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.010733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>480</td>\n",
       "      <td>480</td>\n",
       "      <td>230400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15351</td>\n",
       "      <td>15.008794</td>\n",
       "      <td>239.123312</td>\n",
       "      <td>239.176745</td>\n",
       "      <td>239.901237</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>0.032382</td>\n",
       "      <td>0.037846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     h    w  pixels  aspect_ratio  file_size     pix_pb      r_mean  \\\n",
       "0  800  800  640000      1.000000      94648   6.761897  166.212239   \n",
       "1  541  590  319190      1.090573      39796   8.020655  162.796294   \n",
       "2  800  800  640000      1.000000      54903  11.656922  211.940197   \n",
       "3  498  750  373500      1.506024      45580   8.194384  142.680809   \n",
       "4  480  480  230400      1.000000      15351  15.008794  239.123312   \n",
       "\n",
       "       g_mean      b_mean  r_accum_err  g_accum_err  b_accum_err  \n",
       "0  163.663769  164.054806     0.017416     0.017225     0.017017  \n",
       "1  158.073473  153.525897     0.006082     0.006002     0.006235  \n",
       "2  208.954892  207.897623     0.013972     0.015094     0.016104  \n",
       "3  142.629668  144.688286     0.013406     0.011876     0.010733  \n",
       "4  239.176745  239.901237     0.026496     0.032382     0.037846  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65, 48, 65, 48, 44])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Mini-Train:   1 Test Accuracy: 7.71% Learning Rate: 0.0025000\n",
      "Mini-Train:   2 Test Accuracy: 8.56% Learning Rate: 0.0012500\n",
      "Mini-Train:   3 Test Accuracy: 8.89% Learning Rate: 0.0008333\n",
      "Mini-Train:   4 Test Accuracy: 9.22% Learning Rate: 0.0006250\n",
      "Mini-Train:   5 Test Accuracy: 9.18% Learning Rate: 0.0005000\n",
      "Mini-Train:   6 Test Accuracy: 9.27% Learning Rate: 0.0004167\n",
      "Mini-Train:   7 Test Accuracy: 9.29% Learning Rate: 0.0003571\n",
      "Mini-Train:   8 Test Accuracy: 9.25% Learning Rate: 0.0003125\n",
      "Mini-Train:   9 Test Accuracy: 9.30% Learning Rate: 0.0002778\n",
      "Mini-Train:  10 Test Accuracy: 9.34% Learning Rate: 0.0002500\n"
     ]
    }
   ],
   "source": [
    "LR = 0.005\n",
    "DECAY = 1e-4\n",
    "DO = 0.15\n",
    "# EPOCHS = 250\n",
    "EPOCHS = 5\n",
    "MINI_TRAINS = 10\n",
    "BAT\n",
    "\n",
    "# X_train\n",
    "# zero base y_train\n",
    "y_train -= 1\n",
    "y_train = to_categorical(y_train, 128)\n",
    "\n",
    "# X_test\n",
    "# zero base y_test\n",
    "y_test -= 1\n",
    "y_test = to_categorical(y_test, 128)\n",
    "\n",
    "_input = Input(shape=(12,))\n",
    "x = Dense(256)(_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(DO)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = Dense(512)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(DO)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = Dense(256)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(DO)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "output = Dense(128, activation='softmax')(x)\n",
    "model = Model(inputs=_input, outputs=output)\n",
    "\n",
    "OPTIMIZER = Adam(lr=LR, decay=DECAY)\n",
    "\n",
    "model.compile(optimizer=OPTIMIZER, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "for idx in range(MINI_TRAINS):\n",
    "    temp_lr = LR / (2 * (idx + 1))\n",
    "    \n",
    "    K.set_value(OPTIMIZER.lr, temp_lr)\n",
    "    \n",
    "#     print(\"\\nMini-Train: {:3d} Learning Rate: {:2.7f}\".format((idx + 1), temp_lr))\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=EPOCHS, batch_size=1024, verbose=0)\n",
    "\n",
    "    test_score = model.evaluate(X_test, y_test, batch_size=1024, verbose=0)\n",
    "    train_score = model.evaluate(X_train, y_train, batch_size=BATCH, verbose=0)\n",
    "    \n",
    "    print(\"Mini-Train: {:3d} Test Accuracy: {:2.2f}% Learning Rate: {:2.7f}\".format((idx + 1), score[1] * 100, temp_lr))\n",
    "    \n",
    "    model.save(\"../src/weights/model_raven.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "logit.fit(X_train, data_dict[\"y_train_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04146469278134416\n"
     ]
    }
   ],
   "source": [
    "score = logit.score(X_test, data_dict[\"y_test_1\"])\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04100615747412551\n"
     ]
    }
   ],
   "source": [
    "logit2 = LogisticRegression(C=1e5)\n",
    "\n",
    "logit2.fit(X_train, data_dict[\"y_train_1\"])\n",
    "score = logit2.score(X_test, data_dict[\"y_test_1\"])\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
