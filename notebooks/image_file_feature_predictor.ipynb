{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout, Activation\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>h</th>\n",
       "      <th>w</th>\n",
       "      <th>pixels</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>file_size</th>\n",
       "      <th>pix_pb</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>r_accum_err</th>\n",
       "      <th>g_accum_err</th>\n",
       "      <th>b_accum_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/imgs/28491_68.jpg</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>640000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>85320</td>\n",
       "      <td>7.501172</td>\n",
       "      <td>229.413972</td>\n",
       "      <td>227.713289</td>\n",
       "      <td>212.647266</td>\n",
       "      <td>0.026861</td>\n",
       "      <td>0.036141</td>\n",
       "      <td>0.053210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/imgs/11997_101.jpg</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>640000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166938</td>\n",
       "      <td>3.833759</td>\n",
       "      <td>126.274078</td>\n",
       "      <td>149.567391</td>\n",
       "      <td>155.617066</td>\n",
       "      <td>0.054656</td>\n",
       "      <td>0.036767</td>\n",
       "      <td>0.035571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/imgs/68542_80.jpg</td>\n",
       "      <td>634</td>\n",
       "      <td>793</td>\n",
       "      <td>502762</td>\n",
       "      <td>1.250789</td>\n",
       "      <td>157616</td>\n",
       "      <td>3.189790</td>\n",
       "      <td>180.925826</td>\n",
       "      <td>158.143263</td>\n",
       "      <td>141.555036</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>0.031391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/imgs/79412_25.jpg</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>640000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>151186</td>\n",
       "      <td>4.233196</td>\n",
       "      <td>216.552556</td>\n",
       "      <td>186.867486</td>\n",
       "      <td>176.672427</td>\n",
       "      <td>0.032652</td>\n",
       "      <td>0.038144</td>\n",
       "      <td>0.046619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/imgs/25196_117.jpg</td>\n",
       "      <td>462</td>\n",
       "      <td>600</td>\n",
       "      <td>277200</td>\n",
       "      <td>1.298701</td>\n",
       "      <td>51651</td>\n",
       "      <td>5.366789</td>\n",
       "      <td>179.549928</td>\n",
       "      <td>135.804163</td>\n",
       "      <td>100.765664</td>\n",
       "      <td>0.022439</td>\n",
       "      <td>0.034735</td>\n",
       "      <td>0.061929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         path    h    w  pixels  aspect_ratio  file_size  \\\n",
       "0   ../data/imgs/28491_68.jpg  800  800  640000      1.000000      85320   \n",
       "1  ../data/imgs/11997_101.jpg  800  800  640000      1.000000     166938   \n",
       "2   ../data/imgs/68542_80.jpg  634  793  502762      1.250789     157616   \n",
       "3   ../data/imgs/79412_25.jpg  800  800  640000      1.000000     151186   \n",
       "4  ../data/imgs/25196_117.jpg  462  600  277200      1.298701      51651   \n",
       "\n",
       "     pix_pb      r_mean      g_mean      b_mean  r_accum_err  g_accum_err  \\\n",
       "0  7.501172  229.413972  227.713289  212.647266     0.026861     0.036141   \n",
       "1  3.833759  126.274078  149.567391  155.617066     0.054656     0.036767   \n",
       "2  3.189790  180.925826  158.143263  141.555036     0.015865     0.030551   \n",
       "3  4.233196  216.552556  186.867486  176.672427     0.032652     0.038144   \n",
       "4  5.366789  179.549928  135.804163  100.765664     0.022439     0.034735   \n",
       "\n",
       "   b_accum_err  \n",
       "0     0.053210  \n",
       "1     0.035571  \n",
       "2     0.031391  \n",
       "3     0.046619  \n",
       "4     0.061929  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/image_file_features.csv\", delimiter='\\t', index_col=False)\n",
    "\n",
    "data = data.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152221\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>h</th>\n",
       "      <th>w</th>\n",
       "      <th>pixels</th>\n",
       "      <th>aspect_ratio</th>\n",
       "      <th>file_size</th>\n",
       "      <th>pix_pb</th>\n",
       "      <th>r_mean</th>\n",
       "      <th>g_mean</th>\n",
       "      <th>b_mean</th>\n",
       "      <th>r_accum_err</th>\n",
       "      <th>g_accum_err</th>\n",
       "      <th>b_accum_err</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../data/imgs/28491_68.jpg</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>640000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>85320</td>\n",
       "      <td>7.501172</td>\n",
       "      <td>229.413972</td>\n",
       "      <td>227.713289</td>\n",
       "      <td>212.647266</td>\n",
       "      <td>0.026861</td>\n",
       "      <td>0.036141</td>\n",
       "      <td>0.053210</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../data/imgs/11997_101.jpg</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>640000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166938</td>\n",
       "      <td>3.833759</td>\n",
       "      <td>126.274078</td>\n",
       "      <td>149.567391</td>\n",
       "      <td>155.617066</td>\n",
       "      <td>0.054656</td>\n",
       "      <td>0.036767</td>\n",
       "      <td>0.035571</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../data/imgs/68542_80.jpg</td>\n",
       "      <td>634</td>\n",
       "      <td>793</td>\n",
       "      <td>502762</td>\n",
       "      <td>1.250789</td>\n",
       "      <td>157616</td>\n",
       "      <td>3.189790</td>\n",
       "      <td>180.925826</td>\n",
       "      <td>158.143263</td>\n",
       "      <td>141.555036</td>\n",
       "      <td>0.015865</td>\n",
       "      <td>0.030551</td>\n",
       "      <td>0.031391</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../data/imgs/79412_25.jpg</td>\n",
       "      <td>800</td>\n",
       "      <td>800</td>\n",
       "      <td>640000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>151186</td>\n",
       "      <td>4.233196</td>\n",
       "      <td>216.552556</td>\n",
       "      <td>186.867486</td>\n",
       "      <td>176.672427</td>\n",
       "      <td>0.032652</td>\n",
       "      <td>0.038144</td>\n",
       "      <td>0.046619</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../data/imgs/25196_117.jpg</td>\n",
       "      <td>462</td>\n",
       "      <td>600</td>\n",
       "      <td>277200</td>\n",
       "      <td>1.298701</td>\n",
       "      <td>51651</td>\n",
       "      <td>5.366789</td>\n",
       "      <td>179.549928</td>\n",
       "      <td>135.804163</td>\n",
       "      <td>100.765664</td>\n",
       "      <td>0.022439</td>\n",
       "      <td>0.034735</td>\n",
       "      <td>0.061929</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         path    h    w  pixels  aspect_ratio  file_size  \\\n",
       "0   ../data/imgs/28491_68.jpg  800  800  640000      1.000000      85320   \n",
       "1  ../data/imgs/11997_101.jpg  800  800  640000      1.000000     166938   \n",
       "2   ../data/imgs/68542_80.jpg  634  793  502762      1.250789     157616   \n",
       "3   ../data/imgs/79412_25.jpg  800  800  640000      1.000000     151186   \n",
       "4  ../data/imgs/25196_117.jpg  462  600  277200      1.298701      51651   \n",
       "\n",
       "     pix_pb      r_mean      g_mean      b_mean  r_accum_err  g_accum_err  \\\n",
       "0  7.501172  229.413972  227.713289  212.647266     0.026861     0.036141   \n",
       "1  3.833759  126.274078  149.567391  155.617066     0.054656     0.036767   \n",
       "2  3.189790  180.925826  158.143263  141.555036     0.015865     0.030551   \n",
       "3  4.233196  216.552556  186.867486  176.672427     0.032652     0.038144   \n",
       "4  5.366789  179.549928  135.804163  100.765664     0.022439     0.034735   \n",
       "\n",
       "   b_accum_err  label  \n",
       "0     0.053210     67  \n",
       "1     0.035571    100  \n",
       "2     0.031391     79  \n",
       "3     0.046619     24  \n",
       "4     0.061929    116  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:, \"label\"] = data.loc[:, \"path\"].apply(lambda x: int(x.split(\"_\")[1].split(\".\")[0]) - 1)\n",
    "\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152036\n"
     ]
    }
   ],
   "source": [
    "data = data[data.loc[:, \"h\"] > 50]\n",
    "data = data[data.loc[:, \"w\"] > 50]\n",
    "data = data[data.loc[:, \"file_size\"] > 1000]\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y = data.loc[:, \"label\"].values\n",
    "all_x = data.loc[:, [\"h\", \"w\", \"pixels\", \"aspect_ratio\", \"file_size\", \"pix_pb\", \"r_mean\", \"g_mean\", \"b_mean\", \"r_accum_err\", \"g_accum_err\", \"b_accum_err\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "split = 0\n",
    "for train_index, test_index in skf.split(all_x, all_y):\n",
    "    split += 1\n",
    "    data_dict[\"X_train_{:}\".format(split)] = all_x[train_index]\n",
    "    data_dict[\"y_train_{:}\".format(split)] = all_y[train_index]\n",
    "    data_dict[\"X_test_{:}\".format(split)] = all_x[test_index]\n",
    "    data_dict[\"y_test_{:}\".format(split)] = all_y[test_index]\n",
    "    \n",
    "# X_train, X_test = X[train_index], X[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136770 samples, validate on 15266 samples\n",
      "Epoch 1/250\n",
      " - 6s - loss: 4.5342 - acc: 0.0321 - val_loss: 4.4662 - val_acc: 0.0362\n",
      "Epoch 2/250\n",
      " - 2s - loss: 4.4522 - acc: 0.0371 - val_loss: 4.4332 - val_acc: 0.0426\n",
      "Epoch 3/250\n",
      " - 2s - loss: 4.4333 - acc: 0.0386 - val_loss: 4.4215 - val_acc: 0.0429\n",
      "Epoch 4/250\n",
      " - 2s - loss: 4.4243 - acc: 0.0398 - val_loss: 4.4135 - val_acc: 0.0391\n",
      "Epoch 5/250\n",
      " - 2s - loss: 4.4171 - acc: 0.0414 - val_loss: 4.4170 - val_acc: 0.0428\n",
      "Epoch 6/250\n",
      " - 2s - loss: 4.4122 - acc: 0.0425 - val_loss: 4.4076 - val_acc: 0.0452\n",
      "Epoch 7/250\n",
      " - 2s - loss: 4.4061 - acc: 0.0424 - val_loss: 4.4097 - val_acc: 0.0430\n",
      "Epoch 8/250\n",
      " - 2s - loss: 4.4021 - acc: 0.0432 - val_loss: 4.4276 - val_acc: 0.0427\n",
      "Epoch 9/250\n",
      " - 2s - loss: 4.3963 - acc: 0.0453 - val_loss: 4.4695 - val_acc: 0.0409\n",
      "Epoch 10/250\n",
      " - 2s - loss: 4.3786 - acc: 0.0488 - val_loss: 4.4646 - val_acc: 0.0381\n",
      "Epoch 11/250\n",
      " - 2s - loss: 4.3542 - acc: 0.0526 - val_loss: 4.4326 - val_acc: 0.0399\n",
      "Epoch 12/250\n",
      " - 2s - loss: 4.3379 - acc: 0.0535 - val_loss: 4.4042 - val_acc: 0.0447\n",
      "Epoch 13/250\n",
      " - 2s - loss: 4.3217 - acc: 0.0560 - val_loss: 4.3834 - val_acc: 0.0473\n",
      "Epoch 14/250\n",
      " - 2s - loss: 4.3143 - acc: 0.0576 - val_loss: 4.3872 - val_acc: 0.0494\n",
      "Epoch 15/250\n",
      " - 2s - loss: 4.3046 - acc: 0.0586 - val_loss: 4.4775 - val_acc: 0.0388\n",
      "Epoch 16/250\n",
      " - 2s - loss: 4.3018 - acc: 0.0580 - val_loss: 4.4394 - val_acc: 0.0403\n",
      "Epoch 17/250\n",
      " - 2s - loss: 4.2917 - acc: 0.0608 - val_loss: 4.3972 - val_acc: 0.0433\n",
      "Epoch 18/250\n",
      " - 2s - loss: 4.2837 - acc: 0.0616 - val_loss: 4.4495 - val_acc: 0.0416\n",
      "Epoch 19/250\n",
      " - 2s - loss: 4.2767 - acc: 0.0620 - val_loss: 4.4231 - val_acc: 0.0460\n",
      "Epoch 20/250\n",
      " - 2s - loss: 4.2699 - acc: 0.0640 - val_loss: 4.3611 - val_acc: 0.0486\n",
      "Epoch 21/250\n",
      " - 2s - loss: 4.2653 - acc: 0.0642 - val_loss: 4.3943 - val_acc: 0.0462\n",
      "Epoch 22/250\n",
      " - 2s - loss: 4.2598 - acc: 0.0641 - val_loss: 4.4031 - val_acc: 0.0504\n",
      "Epoch 23/250\n",
      " - 2s - loss: 4.2560 - acc: 0.0648 - val_loss: 4.3751 - val_acc: 0.0481\n",
      "Epoch 24/250\n",
      " - 2s - loss: 4.2485 - acc: 0.0667 - val_loss: 4.3199 - val_acc: 0.0555\n",
      "Epoch 25/250\n",
      " - 2s - loss: 4.2438 - acc: 0.0667 - val_loss: 4.4029 - val_acc: 0.0468\n",
      "Epoch 26/250\n",
      " - 2s - loss: 4.2354 - acc: 0.0685 - val_loss: 4.3662 - val_acc: 0.0498\n",
      "Epoch 27/250\n",
      " - 2s - loss: 4.2297 - acc: 0.0682 - val_loss: 4.3298 - val_acc: 0.0537\n",
      "Epoch 28/250\n",
      " - 2s - loss: 4.2256 - acc: 0.0694 - val_loss: 4.3929 - val_acc: 0.0500\n",
      "Epoch 29/250\n",
      " - 2s - loss: 4.2242 - acc: 0.0698 - val_loss: 4.3977 - val_acc: 0.0502\n",
      "Epoch 30/250\n",
      " - 2s - loss: 4.2194 - acc: 0.0694 - val_loss: 4.4286 - val_acc: 0.0459\n",
      "Epoch 31/250\n",
      " - 2s - loss: 4.2173 - acc: 0.0708 - val_loss: 4.2679 - val_acc: 0.0633\n",
      "Epoch 32/250\n",
      " - 2s - loss: 4.2151 - acc: 0.0703 - val_loss: 4.4066 - val_acc: 0.0493\n",
      "Epoch 33/250\n",
      " - 2s - loss: 4.2061 - acc: 0.0714 - val_loss: 4.3357 - val_acc: 0.0557\n",
      "Epoch 34/250\n",
      " - 2s - loss: 4.2045 - acc: 0.0718 - val_loss: 4.2744 - val_acc: 0.0617\n",
      "Epoch 35/250\n",
      " - 2s - loss: 4.2036 - acc: 0.0720 - val_loss: 4.3036 - val_acc: 0.0607\n",
      "Epoch 36/250\n",
      " - 2s - loss: 4.2034 - acc: 0.0719 - val_loss: 4.2516 - val_acc: 0.0642\n",
      "Epoch 37/250\n",
      " - 2s - loss: 4.2027 - acc: 0.0713 - val_loss: 4.3165 - val_acc: 0.0563\n",
      "Epoch 38/250\n",
      " - 2s - loss: 4.2000 - acc: 0.0721 - val_loss: 4.2605 - val_acc: 0.0630\n",
      "Epoch 39/250\n",
      " - 2s - loss: 4.1979 - acc: 0.0729 - val_loss: 4.3901 - val_acc: 0.0498\n",
      "Epoch 40/250\n",
      " - 2s - loss: 4.1971 - acc: 0.0728 - val_loss: 4.3046 - val_acc: 0.0577\n",
      "Epoch 41/250\n",
      " - 2s - loss: 4.1944 - acc: 0.0727 - val_loss: 4.3258 - val_acc: 0.0570\n",
      "Epoch 42/250\n",
      " - 2s - loss: 4.1874 - acc: 0.0731 - val_loss: 4.3229 - val_acc: 0.0560\n",
      "Epoch 43/250\n",
      " - 2s - loss: 4.1933 - acc: 0.0732 - val_loss: 4.4067 - val_acc: 0.0473\n",
      "Epoch 44/250\n",
      " - 2s - loss: 4.1904 - acc: 0.0734 - val_loss: 4.2676 - val_acc: 0.0616\n",
      "Epoch 45/250\n",
      " - 2s - loss: 4.1842 - acc: 0.0743 - val_loss: 4.2936 - val_acc: 0.0587\n",
      "Epoch 46/250\n",
      " - 2s - loss: 4.1789 - acc: 0.0748 - val_loss: 4.2819 - val_acc: 0.0602\n",
      "Epoch 47/250\n",
      " - 2s - loss: 4.1808 - acc: 0.0740 - val_loss: 4.2730 - val_acc: 0.0614\n",
      "Epoch 48/250\n",
      " - 2s - loss: 4.1794 - acc: 0.0739 - val_loss: 4.2763 - val_acc: 0.0607\n",
      "Epoch 49/250\n",
      " - 2s - loss: 4.1780 - acc: 0.0749 - val_loss: 4.3100 - val_acc: 0.0614\n",
      "Epoch 50/250\n",
      " - 2s - loss: 4.1759 - acc: 0.0743 - val_loss: 4.3041 - val_acc: 0.0593\n",
      "Epoch 51/250\n",
      " - 2s - loss: 4.1733 - acc: 0.0762 - val_loss: 4.3243 - val_acc: 0.0542\n",
      "Epoch 52/250\n",
      " - 2s - loss: 4.1753 - acc: 0.0749 - val_loss: 4.2963 - val_acc: 0.0598\n",
      "Epoch 53/250\n",
      " - 2s - loss: 4.1736 - acc: 0.0763 - val_loss: 4.3916 - val_acc: 0.0517\n",
      "Epoch 54/250\n",
      " - 2s - loss: 4.1712 - acc: 0.0764 - val_loss: 4.2725 - val_acc: 0.0654\n",
      "Epoch 55/250\n",
      " - 2s - loss: 4.1630 - acc: 0.0772 - val_loss: 4.3199 - val_acc: 0.0548\n",
      "Epoch 56/250\n",
      " - 2s - loss: 4.1602 - acc: 0.0767 - val_loss: 4.3314 - val_acc: 0.0554\n",
      "Epoch 57/250\n",
      " - 2s - loss: 4.1654 - acc: 0.0773 - val_loss: 4.2384 - val_acc: 0.0652\n",
      "Epoch 58/250\n",
      " - 2s - loss: 4.1572 - acc: 0.0784 - val_loss: 4.2533 - val_acc: 0.0635\n",
      "Epoch 59/250\n",
      " - 2s - loss: 4.1543 - acc: 0.0784 - val_loss: 4.2805 - val_acc: 0.0622\n",
      "Epoch 60/250\n",
      " - 2s - loss: 4.1541 - acc: 0.0791 - val_loss: 4.3464 - val_acc: 0.0566\n",
      "Epoch 61/250\n",
      " - 2s - loss: 4.1531 - acc: 0.0793 - val_loss: 4.2416 - val_acc: 0.0649\n",
      "Epoch 62/250\n",
      " - 2s - loss: 4.1539 - acc: 0.0790 - val_loss: 4.3168 - val_acc: 0.0610\n",
      "Epoch 63/250\n",
      " - 2s - loss: 4.1564 - acc: 0.0778 - val_loss: 4.3564 - val_acc: 0.0548\n",
      "Epoch 64/250\n",
      " - 2s - loss: 4.1465 - acc: 0.0797 - val_loss: 4.3832 - val_acc: 0.0504\n",
      "Epoch 65/250\n",
      " - 2s - loss: 4.1479 - acc: 0.0799 - val_loss: 4.2875 - val_acc: 0.0635\n",
      "Epoch 66/250\n",
      " - 2s - loss: 4.1456 - acc: 0.0790 - val_loss: 4.3428 - val_acc: 0.0577\n",
      "Epoch 67/250\n",
      " - 2s - loss: 4.1462 - acc: 0.0795 - val_loss: 4.3031 - val_acc: 0.0584\n",
      "Epoch 68/250\n",
      " - 2s - loss: 4.1419 - acc: 0.0807 - val_loss: 4.2987 - val_acc: 0.0656\n",
      "Epoch 69/250\n",
      " - 2s - loss: 4.1376 - acc: 0.0806 - val_loss: 4.3259 - val_acc: 0.0540\n",
      "Epoch 70/250\n",
      " - 2s - loss: 4.1399 - acc: 0.0813 - val_loss: 4.2484 - val_acc: 0.0616\n",
      "Epoch 71/250\n",
      " - 2s - loss: 4.1430 - acc: 0.0795 - val_loss: 4.3161 - val_acc: 0.0564\n",
      "Epoch 72/250\n",
      " - 2s - loss: 4.1394 - acc: 0.0812 - val_loss: 4.2642 - val_acc: 0.0647\n",
      "Epoch 73/250\n",
      " - 2s - loss: 4.1353 - acc: 0.0820 - val_loss: 4.2113 - val_acc: 0.0706\n",
      "Epoch 74/250\n",
      " - 2s - loss: 4.1357 - acc: 0.0817 - val_loss: 4.3497 - val_acc: 0.0539\n",
      "Epoch 75/250\n",
      " - 2s - loss: 4.1325 - acc: 0.0820 - val_loss: 4.2399 - val_acc: 0.0707\n",
      "Epoch 76/250\n",
      " - 2s - loss: 4.1333 - acc: 0.0817 - val_loss: 4.2578 - val_acc: 0.0657\n",
      "Epoch 77/250\n",
      " - 2s - loss: 4.1326 - acc: 0.0807 - val_loss: 4.3688 - val_acc: 0.0520\n",
      "Epoch 78/250\n",
      " - 2s - loss: 4.1376 - acc: 0.0805 - val_loss: 4.2512 - val_acc: 0.0697\n",
      "Epoch 79/250\n",
      " - 2s - loss: 4.1284 - acc: 0.0827 - val_loss: 4.3210 - val_acc: 0.0626\n",
      "Epoch 80/250\n",
      " - 2s - loss: 4.1285 - acc: 0.0832 - val_loss: 4.3087 - val_acc: 0.0554\n",
      "Epoch 81/250\n",
      " - 2s - loss: 4.1283 - acc: 0.0826 - val_loss: 4.2602 - val_acc: 0.0638\n",
      "Epoch 82/250\n",
      " - 2s - loss: 4.1247 - acc: 0.0831 - val_loss: 4.2467 - val_acc: 0.0614\n",
      "Epoch 83/250\n",
      " - 2s - loss: 4.1287 - acc: 0.0820 - val_loss: 4.2095 - val_acc: 0.0714\n",
      "Epoch 84/250\n",
      " - 2s - loss: 4.1277 - acc: 0.0823 - val_loss: 4.3316 - val_acc: 0.0547\n",
      "Epoch 85/250\n",
      " - 2s - loss: 4.1207 - acc: 0.0840 - val_loss: 4.3258 - val_acc: 0.0548\n",
      "Epoch 86/250\n",
      " - 2s - loss: 4.1228 - acc: 0.0832 - val_loss: 4.3367 - val_acc: 0.0557\n",
      "Epoch 87/250\n",
      " - 2s - loss: 4.1268 - acc: 0.0835 - val_loss: 4.2446 - val_acc: 0.0658\n",
      "Epoch 88/250\n",
      " - 2s - loss: 4.1246 - acc: 0.0829 - val_loss: 4.2912 - val_acc: 0.0622\n",
      "Epoch 89/250\n",
      " - 2s - loss: 4.1234 - acc: 0.0826 - val_loss: 4.2636 - val_acc: 0.0658\n",
      "Epoch 90/250\n",
      " - 2s - loss: 4.1216 - acc: 0.0829 - val_loss: 4.3055 - val_acc: 0.0604\n",
      "Epoch 91/250\n",
      " - 2s - loss: 4.1214 - acc: 0.0834 - val_loss: 4.2609 - val_acc: 0.0643\n",
      "Epoch 92/250\n",
      " - 2s - loss: 4.1160 - acc: 0.0841 - val_loss: 4.2471 - val_acc: 0.0638\n",
      "Epoch 93/250\n",
      " - 2s - loss: 4.1152 - acc: 0.0834 - val_loss: 4.2432 - val_acc: 0.0657\n",
      "Epoch 94/250\n",
      " - 2s - loss: 4.1166 - acc: 0.0845 - val_loss: 4.2271 - val_acc: 0.0683\n",
      "Epoch 95/250\n",
      " - 2s - loss: 4.1138 - acc: 0.0842 - val_loss: 4.2561 - val_acc: 0.0638\n",
      "Epoch 96/250\n",
      " - 2s - loss: 4.1155 - acc: 0.0837 - val_loss: 4.2420 - val_acc: 0.0677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/250\n",
      " - 2s - loss: 4.1155 - acc: 0.0842 - val_loss: 4.2362 - val_acc: 0.0690\n",
      "Epoch 98/250\n",
      " - 2s - loss: 4.1143 - acc: 0.0845 - val_loss: 4.2488 - val_acc: 0.0688\n",
      "Epoch 99/250\n",
      " - 2s - loss: 4.1118 - acc: 0.0850 - val_loss: 4.4884 - val_acc: 0.0486\n",
      "Epoch 100/250\n",
      " - 2s - loss: 4.1178 - acc: 0.0832 - val_loss: 4.2288 - val_acc: 0.0689\n",
      "Epoch 101/250\n",
      " - 2s - loss: 4.1168 - acc: 0.0841 - val_loss: 4.2409 - val_acc: 0.0672\n",
      "Epoch 102/250\n",
      " - 2s - loss: 4.1094 - acc: 0.0846 - val_loss: 4.3153 - val_acc: 0.0586\n",
      "Epoch 103/250\n",
      " - 2s - loss: 4.1051 - acc: 0.0857 - val_loss: 4.2408 - val_acc: 0.0679\n",
      "Epoch 104/250\n",
      " - 2s - loss: 4.1064 - acc: 0.0856 - val_loss: 4.2886 - val_acc: 0.0614\n",
      "Epoch 105/250\n",
      " - 2s - loss: 4.1082 - acc: 0.0858 - val_loss: 4.2705 - val_acc: 0.0607\n",
      "Epoch 106/250\n",
      " - 2s - loss: 4.1054 - acc: 0.0861 - val_loss: 4.2641 - val_acc: 0.0631\n",
      "Epoch 107/250\n",
      " - 2s - loss: 4.1035 - acc: 0.0854 - val_loss: 4.3137 - val_acc: 0.0565\n",
      "Epoch 108/250\n",
      " - 2s - loss: 4.1045 - acc: 0.0857 - val_loss: 4.2180 - val_acc: 0.0659\n",
      "Epoch 109/250\n",
      " - 2s - loss: 4.1023 - acc: 0.0859 - val_loss: 4.2099 - val_acc: 0.0707\n",
      "Epoch 110/250\n",
      " - 2s - loss: 4.1008 - acc: 0.0865 - val_loss: 4.2706 - val_acc: 0.0618\n",
      "Epoch 111/250\n",
      " - 2s - loss: 4.0973 - acc: 0.0872 - val_loss: 4.1963 - val_acc: 0.0734\n",
      "Epoch 112/250\n",
      " - 2s - loss: 4.0973 - acc: 0.0870 - val_loss: 4.3059 - val_acc: 0.0592\n",
      "Epoch 113/250\n",
      " - 2s - loss: 4.0989 - acc: 0.0860 - val_loss: 4.2791 - val_acc: 0.0667\n",
      "Epoch 114/250\n",
      " - 2s - loss: 4.0982 - acc: 0.0872 - val_loss: 4.2270 - val_acc: 0.0667\n",
      "Epoch 115/250\n",
      " - 2s - loss: 4.0967 - acc: 0.0863 - val_loss: 4.2734 - val_acc: 0.0642\n",
      "Epoch 116/250\n",
      " - 2s - loss: 4.0938 - acc: 0.0867 - val_loss: 4.2387 - val_acc: 0.0685\n",
      "Epoch 117/250\n",
      " - 2s - loss: 4.0975 - acc: 0.0864 - val_loss: 4.3190 - val_acc: 0.0547\n",
      "Epoch 118/250\n",
      " - 2s - loss: 4.0953 - acc: 0.0868 - val_loss: 4.3320 - val_acc: 0.0555\n",
      "Epoch 119/250\n",
      " - 2s - loss: 4.0990 - acc: 0.0862 - val_loss: 4.3797 - val_acc: 0.0515\n",
      "Epoch 120/250\n",
      " - 2s - loss: 4.0999 - acc: 0.0855 - val_loss: 4.2046 - val_acc: 0.0719\n",
      "Epoch 121/250\n",
      " - 2s - loss: 4.0995 - acc: 0.0860 - val_loss: 4.1797 - val_acc: 0.0762\n",
      "Epoch 122/250\n",
      " - 2s - loss: 4.0979 - acc: 0.0867 - val_loss: 4.2898 - val_acc: 0.0614\n",
      "Epoch 123/250\n",
      " - 2s - loss: 4.0929 - acc: 0.0871 - val_loss: 4.2268 - val_acc: 0.0689\n",
      "Epoch 124/250\n",
      " - 2s - loss: 4.0915 - acc: 0.0882 - val_loss: 4.2056 - val_acc: 0.0691\n",
      "Epoch 125/250\n",
      " - 2s - loss: 4.0947 - acc: 0.0880 - val_loss: 4.2458 - val_acc: 0.0657\n",
      "Epoch 126/250\n",
      " - 2s - loss: 4.0913 - acc: 0.0875 - val_loss: 4.1896 - val_acc: 0.0738\n",
      "Epoch 127/250\n",
      " - 2s - loss: 4.0915 - acc: 0.0871 - val_loss: 4.2622 - val_acc: 0.0637\n",
      "Epoch 128/250\n",
      " - 2s - loss: 4.0896 - acc: 0.0879 - val_loss: 4.3496 - val_acc: 0.0529\n",
      "Epoch 129/250\n",
      " - 2s - loss: 4.0893 - acc: 0.0873 - val_loss: 4.1896 - val_acc: 0.0744\n",
      "Epoch 130/250\n",
      " - 2s - loss: 4.0913 - acc: 0.0875 - val_loss: 4.2459 - val_acc: 0.0662\n",
      "Epoch 131/250\n",
      " - 2s - loss: 4.0888 - acc: 0.0873 - val_loss: 4.1537 - val_acc: 0.0774\n",
      "Epoch 132/250\n",
      " - 2s - loss: 4.0875 - acc: 0.0886 - val_loss: 4.1935 - val_acc: 0.0710\n",
      "Epoch 133/250\n",
      " - 2s - loss: 4.0814 - acc: 0.0887 - val_loss: 4.2671 - val_acc: 0.0631\n",
      "Epoch 134/250\n",
      " - 2s - loss: 4.0810 - acc: 0.0888 - val_loss: 4.1475 - val_acc: 0.0810\n",
      "Epoch 135/250\n",
      " - 2s - loss: 4.0769 - acc: 0.0889 - val_loss: 4.3000 - val_acc: 0.0595\n",
      "Epoch 136/250\n",
      " - 2s - loss: 4.0796 - acc: 0.0899 - val_loss: 4.2272 - val_acc: 0.0642\n",
      "Epoch 137/250\n",
      " - 2s - loss: 4.0808 - acc: 0.0891 - val_loss: 4.1574 - val_acc: 0.0778\n",
      "Epoch 138/250\n",
      " - 2s - loss: 4.0800 - acc: 0.0889 - val_loss: 4.3556 - val_acc: 0.0557\n",
      "Epoch 139/250\n",
      " - 2s - loss: 4.0781 - acc: 0.0893 - val_loss: 4.2237 - val_acc: 0.0711\n",
      "Epoch 140/250\n",
      " - 2s - loss: 4.0760 - acc: 0.0901 - val_loss: 4.3174 - val_acc: 0.0572\n",
      "Epoch 141/250\n",
      " - 2s - loss: 4.0766 - acc: 0.0902 - val_loss: 4.1948 - val_acc: 0.0730\n",
      "Epoch 142/250\n",
      " - 2s - loss: 4.0745 - acc: 0.0901 - val_loss: 4.1892 - val_acc: 0.0753\n",
      "Epoch 143/250\n",
      " - 2s - loss: 4.0716 - acc: 0.0905 - val_loss: 4.1508 - val_acc: 0.0783\n",
      "Epoch 144/250\n",
      " - 2s - loss: 4.0742 - acc: 0.0892 - val_loss: 4.2400 - val_acc: 0.0687\n",
      "Epoch 145/250\n",
      " - 2s - loss: 4.0733 - acc: 0.0896 - val_loss: 4.2559 - val_acc: 0.0670\n",
      "Epoch 146/250\n",
      " - 2s - loss: 4.0711 - acc: 0.0904 - val_loss: 4.1816 - val_acc: 0.0755\n",
      "Epoch 147/250\n",
      " - 2s - loss: 4.0745 - acc: 0.0903 - val_loss: 4.3678 - val_acc: 0.0536\n",
      "Epoch 148/250\n",
      " - 2s - loss: 4.0719 - acc: 0.0898 - val_loss: 4.4466 - val_acc: 0.0524\n",
      "Epoch 149/250\n",
      " - 2s - loss: 4.0729 - acc: 0.0900 - val_loss: 4.1937 - val_acc: 0.0735\n",
      "Epoch 150/250\n",
      " - 2s - loss: 4.0695 - acc: 0.0912 - val_loss: 4.2107 - val_acc: 0.0678\n",
      "Epoch 151/250\n",
      " - 2s - loss: 4.0711 - acc: 0.0901 - val_loss: 4.1445 - val_acc: 0.0803\n",
      "Epoch 152/250\n",
      " - 2s - loss: 4.0667 - acc: 0.0909 - val_loss: 4.2433 - val_acc: 0.0667\n",
      "Epoch 153/250\n",
      " - 2s - loss: 4.0691 - acc: 0.0903 - val_loss: 4.2457 - val_acc: 0.0644\n",
      "Epoch 154/250\n",
      " - 2s - loss: 4.0677 - acc: 0.0908 - val_loss: 4.3176 - val_acc: 0.0582\n",
      "Epoch 155/250\n",
      " - 2s - loss: 4.0698 - acc: 0.0901 - val_loss: 4.1410 - val_acc: 0.0797\n",
      "Epoch 156/250\n",
      " - 2s - loss: 4.0655 - acc: 0.0905 - val_loss: 4.3105 - val_acc: 0.0609\n",
      "Epoch 157/250\n",
      " - 2s - loss: 4.0655 - acc: 0.0912 - val_loss: 4.2162 - val_acc: 0.0681\n",
      "Epoch 158/250\n",
      " - 2s - loss: 4.0696 - acc: 0.0903 - val_loss: 4.1902 - val_acc: 0.0747\n",
      "Epoch 159/250\n",
      " - 2s - loss: 4.0664 - acc: 0.0906 - val_loss: 4.1762 - val_acc: 0.0755\n",
      "Epoch 160/250\n",
      " - 2s - loss: 4.0665 - acc: 0.0910 - val_loss: 4.1079 - val_acc: 0.0865\n",
      "Epoch 161/250\n",
      " - 2s - loss: 4.0654 - acc: 0.0907 - val_loss: 4.2361 - val_acc: 0.0699\n",
      "Epoch 162/250\n",
      " - 2s - loss: 4.0636 - acc: 0.0915 - val_loss: 4.2423 - val_acc: 0.0680\n",
      "Epoch 163/250\n",
      " - 2s - loss: 4.0613 - acc: 0.0914 - val_loss: 4.1596 - val_acc: 0.0764\n",
      "Epoch 164/250\n",
      " - 2s - loss: 4.0628 - acc: 0.0913 - val_loss: 4.2191 - val_acc: 0.0698\n",
      "Epoch 165/250\n",
      " - 2s - loss: 4.0639 - acc: 0.0914 - val_loss: 4.1755 - val_acc: 0.0735\n",
      "Epoch 166/250\n",
      " - 2s - loss: 4.0617 - acc: 0.0916 - val_loss: 4.3193 - val_acc: 0.0583\n",
      "Epoch 167/250\n",
      " - 2s - loss: 4.0653 - acc: 0.0911 - val_loss: 4.1534 - val_acc: 0.0780\n",
      "Epoch 168/250\n",
      " - 2s - loss: 4.0601 - acc: 0.0917 - val_loss: 4.1460 - val_acc: 0.0803\n",
      "Epoch 169/250\n",
      " - 2s - loss: 4.0620 - acc: 0.0913 - val_loss: 4.2086 - val_acc: 0.0719\n",
      "Epoch 170/250\n",
      " - 2s - loss: 4.0624 - acc: 0.0905 - val_loss: 4.2804 - val_acc: 0.0630\n",
      "Epoch 171/250\n",
      " - 2s - loss: 4.0609 - acc: 0.0920 - val_loss: 4.2240 - val_acc: 0.0673\n",
      "Epoch 172/250\n",
      " - 2s - loss: 4.0660 - acc: 0.0909 - val_loss: 4.2378 - val_acc: 0.0693\n",
      "Epoch 173/250\n",
      " - 2s - loss: 4.0587 - acc: 0.0917 - val_loss: 4.2594 - val_acc: 0.0647\n",
      "Epoch 174/250\n",
      " - 2s - loss: 4.0578 - acc: 0.0923 - val_loss: 4.1953 - val_acc: 0.0726\n",
      "Epoch 175/250\n",
      " - 2s - loss: 4.0574 - acc: 0.0922 - val_loss: 4.2504 - val_acc: 0.0654\n",
      "Epoch 176/250\n",
      " - 2s - loss: 4.0564 - acc: 0.0916 - val_loss: 4.2225 - val_acc: 0.0681\n",
      "Epoch 177/250\n",
      " - 2s - loss: 4.0596 - acc: 0.0928 - val_loss: 4.1680 - val_acc: 0.0757\n",
      "Epoch 178/250\n",
      " - 2s - loss: 4.0565 - acc: 0.0919 - val_loss: 4.2510 - val_acc: 0.0654\n",
      "Epoch 179/250\n",
      " - 2s - loss: 4.0591 - acc: 0.0920 - val_loss: 4.2828 - val_acc: 0.0619\n",
      "Epoch 180/250\n",
      " - 2s - loss: 4.0548 - acc: 0.0928 - val_loss: 4.1832 - val_acc: 0.0736\n",
      "Epoch 181/250\n",
      " - 2s - loss: 4.0571 - acc: 0.0926 - val_loss: 4.1735 - val_acc: 0.0787\n",
      "Epoch 182/250\n",
      " - 2s - loss: 4.0557 - acc: 0.0924 - val_loss: 4.2778 - val_acc: 0.0628\n",
      "Epoch 183/250\n",
      " - 2s - loss: 4.0576 - acc: 0.0925 - val_loss: 4.2325 - val_acc: 0.0704\n",
      "Epoch 184/250\n",
      " - 2s - loss: 4.0539 - acc: 0.0927 - val_loss: 4.1871 - val_acc: 0.0754\n",
      "Epoch 185/250\n",
      " - 2s - loss: 4.0523 - acc: 0.0938 - val_loss: 4.2362 - val_acc: 0.0655\n",
      "Epoch 186/250\n",
      " - 2s - loss: 4.0538 - acc: 0.0923 - val_loss: 4.1861 - val_acc: 0.0725\n",
      "Epoch 187/250\n",
      " - 2s - loss: 4.0505 - acc: 0.0927 - val_loss: 4.2155 - val_acc: 0.0709\n",
      "Epoch 188/250\n",
      " - 2s - loss: 4.0529 - acc: 0.0915 - val_loss: 4.2162 - val_acc: 0.0677\n",
      "Epoch 189/250\n",
      " - 2s - loss: 4.0513 - acc: 0.0932 - val_loss: 4.1584 - val_acc: 0.0762\n",
      "Epoch 190/250\n",
      " - 2s - loss: 4.0503 - acc: 0.0933 - val_loss: 4.2513 - val_acc: 0.0669\n",
      "Epoch 191/250\n",
      " - 2s - loss: 4.0483 - acc: 0.0929 - val_loss: 4.1308 - val_acc: 0.0816\n",
      "Epoch 192/250\n",
      " - 2s - loss: 4.0494 - acc: 0.0936 - val_loss: 4.2648 - val_acc: 0.0659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/250\n",
      " - 2s - loss: 4.0529 - acc: 0.0928 - val_loss: 4.1414 - val_acc: 0.0810\n",
      "Epoch 194/250\n",
      " - 2s - loss: 4.0514 - acc: 0.0930 - val_loss: 4.1859 - val_acc: 0.0739\n",
      "Epoch 195/250\n",
      " - 2s - loss: 4.0495 - acc: 0.0933 - val_loss: 4.2280 - val_acc: 0.0677\n",
      "Epoch 196/250\n",
      " - 2s - loss: 4.0501 - acc: 0.0926 - val_loss: 4.3063 - val_acc: 0.0606\n",
      "Epoch 197/250\n",
      " - 2s - loss: 4.0507 - acc: 0.0929 - val_loss: 4.2573 - val_acc: 0.0645\n",
      "Epoch 198/250\n",
      " - 2s - loss: 4.0507 - acc: 0.0931 - val_loss: 4.2534 - val_acc: 0.0652\n",
      "Epoch 199/250\n",
      " - 2s - loss: 4.0492 - acc: 0.0934 - val_loss: 4.1379 - val_acc: 0.0795\n",
      "Epoch 200/250\n",
      " - 2s - loss: 4.0467 - acc: 0.0938 - val_loss: 4.2043 - val_acc: 0.0716\n",
      "Epoch 201/250\n",
      " - 2s - loss: 4.0477 - acc: 0.0933 - val_loss: 4.1979 - val_acc: 0.0709\n",
      "Epoch 202/250\n",
      " - 2s - loss: 4.0487 - acc: 0.0936 - val_loss: 4.1317 - val_acc: 0.0833\n",
      "Epoch 203/250\n",
      " - 2s - loss: 4.0469 - acc: 0.0940 - val_loss: 4.1393 - val_acc: 0.0822\n",
      "Epoch 204/250\n",
      " - 2s - loss: 4.0476 - acc: 0.0928 - val_loss: 4.1691 - val_acc: 0.0766\n",
      "Epoch 205/250\n",
      " - 2s - loss: 4.0458 - acc: 0.0931 - val_loss: 4.1809 - val_acc: 0.0757\n",
      "Epoch 206/250\n",
      " - 2s - loss: 4.0482 - acc: 0.0936 - val_loss: 4.1268 - val_acc: 0.0821\n",
      "Epoch 207/250\n",
      " - 2s - loss: 4.0457 - acc: 0.0945 - val_loss: 4.3651 - val_acc: 0.0564\n",
      "Epoch 208/250\n",
      " - 2s - loss: 4.0466 - acc: 0.0939 - val_loss: 4.1928 - val_acc: 0.0743\n",
      "Epoch 209/250\n",
      " - 2s - loss: 4.0442 - acc: 0.0953 - val_loss: 4.2690 - val_acc: 0.0627\n",
      "Epoch 210/250\n",
      " - 2s - loss: 4.0461 - acc: 0.0937 - val_loss: 4.1743 - val_acc: 0.0774\n",
      "Epoch 211/250\n",
      " - 2s - loss: 4.0443 - acc: 0.0942 - val_loss: 4.1413 - val_acc: 0.0812\n",
      "Epoch 212/250\n",
      " - 2s - loss: 4.0451 - acc: 0.0945 - val_loss: 4.2051 - val_acc: 0.0725\n",
      "Epoch 213/250\n",
      " - 2s - loss: 4.0464 - acc: 0.0933 - val_loss: 4.1592 - val_acc: 0.0790\n",
      "Epoch 214/250\n",
      " - 2s - loss: 4.0446 - acc: 0.0939 - val_loss: 4.2046 - val_acc: 0.0723\n",
      "Epoch 215/250\n",
      " - 2s - loss: 4.0423 - acc: 0.0939 - val_loss: 4.1893 - val_acc: 0.0716\n",
      "Epoch 216/250\n",
      " - 2s - loss: 4.0418 - acc: 0.0933 - val_loss: 4.2260 - val_acc: 0.0693\n",
      "Epoch 217/250\n",
      " - 2s - loss: 4.0420 - acc: 0.0943 - val_loss: 4.1056 - val_acc: 0.0835\n",
      "Epoch 218/250\n",
      " - 2s - loss: 4.0425 - acc: 0.0948 - val_loss: 4.1499 - val_acc: 0.0794\n",
      "Epoch 219/250\n",
      " - 2s - loss: 4.0423 - acc: 0.0939 - val_loss: 4.2076 - val_acc: 0.0721\n",
      "Epoch 220/250\n",
      " - 2s - loss: 4.0446 - acc: 0.0939 - val_loss: 4.1513 - val_acc: 0.0786\n",
      "Epoch 221/250\n",
      " - 2s - loss: 4.0410 - acc: 0.0954 - val_loss: 4.1506 - val_acc: 0.0799\n",
      "Epoch 222/250\n",
      " - 2s - loss: 4.0416 - acc: 0.0949 - val_loss: 4.2405 - val_acc: 0.0667\n",
      "Epoch 223/250\n",
      " - 2s - loss: 4.0430 - acc: 0.0941 - val_loss: 4.1928 - val_acc: 0.0717\n",
      "Epoch 224/250\n",
      " - 2s - loss: 4.0402 - acc: 0.0951 - val_loss: 4.2016 - val_acc: 0.0732\n",
      "Epoch 225/250\n",
      " - 2s - loss: 4.0400 - acc: 0.0937 - val_loss: 4.1410 - val_acc: 0.0792\n",
      "Epoch 226/250\n",
      " - 2s - loss: 4.0394 - acc: 0.0947 - val_loss: 4.1528 - val_acc: 0.0774\n",
      "Epoch 227/250\n",
      " - 2s - loss: 4.0393 - acc: 0.0944 - val_loss: 4.1277 - val_acc: 0.0838\n",
      "Epoch 228/250\n",
      " - 2s - loss: 4.0378 - acc: 0.0951 - val_loss: 4.2337 - val_acc: 0.0686\n",
      "Epoch 229/250\n",
      " - 2s - loss: 4.0403 - acc: 0.0950 - val_loss: 4.2124 - val_acc: 0.0717\n",
      "Epoch 230/250\n",
      " - 2s - loss: 4.0365 - acc: 0.0956 - val_loss: 4.1419 - val_acc: 0.0807\n",
      "Epoch 231/250\n",
      " - 2s - loss: 4.0366 - acc: 0.0947 - val_loss: 4.1424 - val_acc: 0.0819\n",
      "Epoch 232/250\n",
      " - 2s - loss: 4.0401 - acc: 0.0956 - val_loss: 4.1404 - val_acc: 0.0804\n",
      "Epoch 233/250\n",
      " - 2s - loss: 4.0351 - acc: 0.0957 - val_loss: 4.1237 - val_acc: 0.0835\n",
      "Epoch 234/250\n",
      " - 2s - loss: 4.0379 - acc: 0.0946 - val_loss: 4.1831 - val_acc: 0.0736\n",
      "Epoch 235/250\n",
      " - 2s - loss: 4.0388 - acc: 0.0953 - val_loss: 4.1595 - val_acc: 0.0793\n",
      "Epoch 236/250\n",
      " - 2s - loss: 4.0375 - acc: 0.0942 - val_loss: 4.2065 - val_acc: 0.0732\n",
      "Epoch 237/250\n",
      " - 2s - loss: 4.0379 - acc: 0.0940 - val_loss: 4.1760 - val_acc: 0.0760\n",
      "Epoch 238/250\n",
      " - 2s - loss: 4.0403 - acc: 0.0949 - val_loss: 4.1540 - val_acc: 0.0802\n",
      "Epoch 239/250\n",
      " - 2s - loss: 4.0354 - acc: 0.0952 - val_loss: 4.1686 - val_acc: 0.0780\n",
      "Epoch 240/250\n",
      " - 2s - loss: 4.0349 - acc: 0.0950 - val_loss: 4.1829 - val_acc: 0.0760\n",
      "Epoch 241/250\n",
      " - 2s - loss: 4.0347 - acc: 0.0948 - val_loss: 4.2243 - val_acc: 0.0711\n",
      "Epoch 242/250\n",
      " - 2s - loss: 4.0374 - acc: 0.0943 - val_loss: 4.2003 - val_acc: 0.0743\n",
      "Epoch 243/250\n",
      " - 2s - loss: 4.0360 - acc: 0.0955 - val_loss: 4.2954 - val_acc: 0.0621\n",
      "Epoch 244/250\n",
      " - 2s - loss: 4.0362 - acc: 0.0949 - val_loss: 4.2737 - val_acc: 0.0659\n",
      "Epoch 245/250\n",
      " - 2s - loss: 4.0358 - acc: 0.0955 - val_loss: 4.2597 - val_acc: 0.0647\n",
      "Epoch 246/250\n",
      " - 2s - loss: 4.0371 - acc: 0.0950 - val_loss: 4.1452 - val_acc: 0.0806\n",
      "Epoch 247/250\n",
      " - 2s - loss: 4.0354 - acc: 0.0951 - val_loss: 4.1272 - val_acc: 0.0854\n",
      "Epoch 248/250\n",
      " - 2s - loss: 4.0326 - acc: 0.0953 - val_loss: 4.1658 - val_acc: 0.0787\n",
      "Epoch 249/250\n",
      " - 2s - loss: 4.0302 - acc: 0.0959 - val_loss: 4.2456 - val_acc: 0.0654\n",
      "Epoch 250/250\n",
      " - 2s - loss: 4.0307 - acc: 0.0961 - val_loss: 4.2099 - val_acc: 0.0721\n",
      "Mini-Train:   1 Test Accuracy: 7.21% Learning Rate: 0.0025000\n",
      "Train on 136770 samples, validate on 15266 samples\n",
      "Epoch 1/250\n",
      " - 2s - loss: 4.0276 - acc: 0.0968 - val_loss: 4.1128 - val_acc: 0.0846\n",
      "Epoch 2/250\n",
      " - 2s - loss: 4.0258 - acc: 0.0961 - val_loss: 4.1308 - val_acc: 0.0809\n",
      "Epoch 3/250\n",
      " - 2s - loss: 4.0272 - acc: 0.0965 - val_loss: 4.0996 - val_acc: 0.0888\n",
      "Epoch 4/250\n",
      " - 2s - loss: 4.0261 - acc: 0.0951 - val_loss: 4.2212 - val_acc: 0.0702\n",
      "Epoch 5/250\n",
      " - 2s - loss: 4.0247 - acc: 0.0966 - val_loss: 4.0991 - val_acc: 0.0871\n",
      "Epoch 6/250\n",
      " - 2s - loss: 4.0252 - acc: 0.0966 - val_loss: 4.1213 - val_acc: 0.0849\n",
      "Epoch 7/250\n",
      " - 2s - loss: 4.0242 - acc: 0.0959 - val_loss: 4.1112 - val_acc: 0.0852\n",
      "Epoch 8/250\n",
      " - 2s - loss: 4.0243 - acc: 0.0974 - val_loss: 4.1577 - val_acc: 0.0793\n",
      "Epoch 9/250\n",
      " - 2s - loss: 4.0257 - acc: 0.0967 - val_loss: 4.1245 - val_acc: 0.0831\n",
      "Epoch 10/250\n",
      " - 2s - loss: 4.0207 - acc: 0.0978 - val_loss: 4.1298 - val_acc: 0.0848\n",
      "Epoch 11/250\n",
      " - 2s - loss: 4.0232 - acc: 0.0968 - val_loss: 4.0754 - val_acc: 0.0912\n",
      "Epoch 12/250\n",
      " - 2s - loss: 4.0225 - acc: 0.0961 - val_loss: 4.1772 - val_acc: 0.0759\n",
      "Epoch 13/250\n",
      " - 2s - loss: 4.0226 - acc: 0.0964 - val_loss: 4.0862 - val_acc: 0.0875\n",
      "Epoch 14/250\n",
      " - 2s - loss: 4.0210 - acc: 0.0980 - val_loss: 4.1666 - val_acc: 0.0783\n",
      "Epoch 15/250\n",
      " - 2s - loss: 4.0235 - acc: 0.0967 - val_loss: 4.1129 - val_acc: 0.0861\n",
      "Epoch 16/250\n",
      " - 2s - loss: 4.0235 - acc: 0.0971 - val_loss: 4.1284 - val_acc: 0.0836\n",
      "Epoch 17/250\n",
      " - 2s - loss: 4.0222 - acc: 0.0973 - val_loss: 4.0932 - val_acc: 0.0876\n",
      "Epoch 18/250\n",
      " - 2s - loss: 4.0228 - acc: 0.0976 - val_loss: 4.1052 - val_acc: 0.0879\n",
      "Epoch 19/250\n",
      " - 2s - loss: 4.0222 - acc: 0.0976 - val_loss: 4.1582 - val_acc: 0.0796\n",
      "Epoch 20/250\n",
      " - 2s - loss: 4.0202 - acc: 0.0971 - val_loss: 4.0936 - val_acc: 0.0874\n",
      "Epoch 21/250\n",
      " - 2s - loss: 4.0214 - acc: 0.0972 - val_loss: 4.1506 - val_acc: 0.0818\n",
      "Epoch 22/250\n",
      " - 2s - loss: 4.0196 - acc: 0.0973 - val_loss: 4.1133 - val_acc: 0.0852\n",
      "Epoch 23/250\n",
      " - 2s - loss: 4.0205 - acc: 0.0975 - val_loss: 4.1407 - val_acc: 0.0828\n",
      "Epoch 24/250\n",
      " - 2s - loss: 4.0208 - acc: 0.0971 - val_loss: 4.1741 - val_acc: 0.0768\n",
      "Epoch 25/250\n",
      " - 2s - loss: 4.0211 - acc: 0.0969 - val_loss: 4.1252 - val_acc: 0.0836\n",
      "Epoch 26/250\n",
      " - 2s - loss: 4.0203 - acc: 0.0976 - val_loss: 4.1899 - val_acc: 0.0738\n",
      "Epoch 27/250\n",
      " - 2s - loss: 4.0201 - acc: 0.0987 - val_loss: 4.1551 - val_acc: 0.0795\n",
      "Epoch 28/250\n",
      " - 2s - loss: 4.0185 - acc: 0.0978 - val_loss: 4.0904 - val_acc: 0.0893\n",
      "Epoch 29/250\n",
      " - 2s - loss: 4.0217 - acc: 0.0981 - val_loss: 4.1410 - val_acc: 0.0812\n",
      "Epoch 30/250\n",
      " - 2s - loss: 4.0210 - acc: 0.0969 - val_loss: 4.1347 - val_acc: 0.0805\n",
      "Epoch 31/250\n",
      " - 2s - loss: 4.0214 - acc: 0.0967 - val_loss: 4.1217 - val_acc: 0.0835\n",
      "Epoch 32/250\n",
      " - 2s - loss: 4.0189 - acc: 0.0977 - val_loss: 4.0811 - val_acc: 0.0874\n",
      "Epoch 33/250\n",
      " - 2s - loss: 4.0184 - acc: 0.0982 - val_loss: 4.1308 - val_acc: 0.0842\n",
      "Epoch 34/250\n",
      " - 2s - loss: 4.0190 - acc: 0.0979 - val_loss: 4.1297 - val_acc: 0.0810\n",
      "Epoch 35/250\n",
      " - 2s - loss: 4.0178 - acc: 0.0975 - val_loss: 4.1105 - val_acc: 0.0867\n",
      "Epoch 36/250\n",
      " - 2s - loss: 4.0193 - acc: 0.0980 - val_loss: 4.0783 - val_acc: 0.0915\n",
      "Epoch 37/250\n",
      " - 2s - loss: 4.0183 - acc: 0.0989 - val_loss: 4.0796 - val_acc: 0.0886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/250\n",
      " - 2s - loss: 4.0192 - acc: 0.0972 - val_loss: 4.1049 - val_acc: 0.0856\n",
      "Epoch 39/250\n",
      " - 2s - loss: 4.0184 - acc: 0.0974 - val_loss: 4.1106 - val_acc: 0.0850\n",
      "Epoch 40/250\n",
      " - 2s - loss: 4.0208 - acc: 0.0962 - val_loss: 4.1074 - val_acc: 0.0855\n",
      "Epoch 41/250\n",
      " - 2s - loss: 4.0184 - acc: 0.0975 - val_loss: 4.0901 - val_acc: 0.0896\n",
      "Epoch 42/250\n",
      " - 2s - loss: 4.0189 - acc: 0.0981 - val_loss: 4.0869 - val_acc: 0.0872\n",
      "Epoch 43/250\n",
      " - 2s - loss: 4.0174 - acc: 0.0983 - val_loss: 4.1289 - val_acc: 0.0842\n",
      "Epoch 44/250\n",
      " - 2s - loss: 4.0196 - acc: 0.0983 - val_loss: 4.1288 - val_acc: 0.0846\n",
      "Epoch 45/250\n",
      " - 2s - loss: 4.0176 - acc: 0.0977 - val_loss: 4.0896 - val_acc: 0.0888\n",
      "Epoch 46/250\n",
      " - 2s - loss: 4.0178 - acc: 0.0984 - val_loss: 4.1044 - val_acc: 0.0865\n",
      "Epoch 47/250\n",
      " - 2s - loss: 4.0180 - acc: 0.0980 - val_loss: 4.0833 - val_acc: 0.0909\n",
      "Epoch 48/250\n",
      " - 2s - loss: 4.0168 - acc: 0.0967 - val_loss: 4.1547 - val_acc: 0.0804\n",
      "Epoch 49/250\n",
      " - 2s - loss: 4.0176 - acc: 0.0973 - val_loss: 4.1157 - val_acc: 0.0850\n",
      "Epoch 50/250\n",
      " - 2s - loss: 4.0189 - acc: 0.0984 - val_loss: 4.0985 - val_acc: 0.0874\n",
      "Epoch 51/250\n",
      " - 2s - loss: 4.0198 - acc: 0.0971 - val_loss: 4.1401 - val_acc: 0.0817\n",
      "Epoch 52/250\n",
      " - 2s - loss: 4.0180 - acc: 0.0987 - val_loss: 4.0970 - val_acc: 0.0895\n",
      "Epoch 53/250\n",
      " - 2s - loss: 4.0165 - acc: 0.0972 - val_loss: 4.1119 - val_acc: 0.0847\n",
      "Epoch 54/250\n",
      " - 2s - loss: 4.0181 - acc: 0.0974 - val_loss: 4.1549 - val_acc: 0.0785\n",
      "Epoch 55/250\n",
      " - 2s - loss: 4.0175 - acc: 0.0975 - val_loss: 4.1272 - val_acc: 0.0826\n",
      "Epoch 56/250\n",
      " - 2s - loss: 4.0181 - acc: 0.0977 - val_loss: 4.1255 - val_acc: 0.0844\n",
      "Epoch 57/250\n",
      " - 2s - loss: 4.0168 - acc: 0.0983 - val_loss: 4.1022 - val_acc: 0.0860\n",
      "Epoch 58/250\n",
      " - 2s - loss: 4.0160 - acc: 0.0976 - val_loss: 4.0912 - val_acc: 0.0886\n",
      "Epoch 59/250\n",
      " - 2s - loss: 4.0161 - acc: 0.0983 - val_loss: 4.2210 - val_acc: 0.0723\n",
      "Epoch 60/250\n",
      " - 2s - loss: 4.0178 - acc: 0.0980 - val_loss: 4.0983 - val_acc: 0.0875\n",
      "Epoch 61/250\n",
      " - 2s - loss: 4.0143 - acc: 0.0985 - val_loss: 4.0953 - val_acc: 0.0884\n",
      "Epoch 62/250\n",
      " - 2s - loss: 4.0152 - acc: 0.0984 - val_loss: 4.1021 - val_acc: 0.0887\n",
      "Epoch 63/250\n",
      " - 2s - loss: 4.0154 - acc: 0.0983 - val_loss: 4.1462 - val_acc: 0.0825\n",
      "Epoch 64/250\n",
      " - 2s - loss: 4.0173 - acc: 0.0980 - val_loss: 4.1142 - val_acc: 0.0869\n",
      "Epoch 65/250\n",
      " - 2s - loss: 4.0150 - acc: 0.0974 - val_loss: 4.1098 - val_acc: 0.0852\n",
      "Epoch 66/250\n",
      " - 2s - loss: 4.0150 - acc: 0.0987 - val_loss: 4.0919 - val_acc: 0.0910\n",
      "Epoch 67/250\n",
      " - 2s - loss: 4.0160 - acc: 0.0985 - val_loss: 4.1057 - val_acc: 0.0884\n",
      "Epoch 68/250\n",
      " - 2s - loss: 4.0166 - acc: 0.0977 - val_loss: 4.0829 - val_acc: 0.0892\n",
      "Epoch 69/250\n",
      " - 2s - loss: 4.0148 - acc: 0.0982 - val_loss: 4.0781 - val_acc: 0.0911\n",
      "Epoch 70/250\n",
      " - 2s - loss: 4.0154 - acc: 0.0989 - val_loss: 4.0881 - val_acc: 0.0903\n",
      "Epoch 71/250\n",
      " - 2s - loss: 4.0152 - acc: 0.0980 - val_loss: 4.1296 - val_acc: 0.0831\n",
      "Epoch 72/250\n",
      " - 2s - loss: 4.0156 - acc: 0.0978 - val_loss: 4.1048 - val_acc: 0.0876\n",
      "Epoch 73/250\n",
      " - 2s - loss: 4.0147 - acc: 0.0978 - val_loss: 4.0840 - val_acc: 0.0897\n",
      "Epoch 74/250\n",
      " - 2s - loss: 4.0154 - acc: 0.0977 - val_loss: 4.1009 - val_acc: 0.0878\n",
      "Epoch 75/250\n",
      " - 2s - loss: 4.0144 - acc: 0.0985 - val_loss: 4.1098 - val_acc: 0.0840\n",
      "Epoch 76/250\n",
      " - 2s - loss: 4.0148 - acc: 0.0980 - val_loss: 4.1364 - val_acc: 0.0824\n",
      "Epoch 77/250\n",
      " - 2s - loss: 4.0159 - acc: 0.0978 - val_loss: 4.1111 - val_acc: 0.0869\n",
      "Epoch 78/250\n",
      " - 2s - loss: 4.0141 - acc: 0.0976 - val_loss: 4.0719 - val_acc: 0.0923\n",
      "Epoch 79/250\n",
      " - 2s - loss: 4.0145 - acc: 0.0981 - val_loss: 4.1214 - val_acc: 0.0838\n",
      "Epoch 80/250\n",
      " - 2s - loss: 4.0147 - acc: 0.0978 - val_loss: 4.0889 - val_acc: 0.0904\n",
      "Epoch 81/250\n",
      " - 2s - loss: 4.0136 - acc: 0.0979 - val_loss: 4.0741 - val_acc: 0.0897\n",
      "Epoch 82/250\n",
      " - 2s - loss: 4.0146 - acc: 0.0983 - val_loss: 4.1126 - val_acc: 0.0857\n",
      "Epoch 83/250\n",
      " - 2s - loss: 4.0119 - acc: 0.0986 - val_loss: 4.1368 - val_acc: 0.0810\n",
      "Epoch 84/250\n",
      " - 2s - loss: 4.0160 - acc: 0.0979 - val_loss: 4.0863 - val_acc: 0.0883\n",
      "Epoch 85/250\n",
      " - 2s - loss: 4.0110 - acc: 0.0991 - val_loss: 4.0919 - val_acc: 0.0871\n",
      "Epoch 86/250\n",
      " - 2s - loss: 4.0114 - acc: 0.0985 - val_loss: 4.1195 - val_acc: 0.0836\n",
      "Epoch 87/250\n",
      " - 2s - loss: 4.0119 - acc: 0.0988 - val_loss: 4.1280 - val_acc: 0.0845\n",
      "Epoch 88/250\n",
      " - 2s - loss: 4.0129 - acc: 0.0985 - val_loss: 4.0758 - val_acc: 0.0915\n",
      "Epoch 89/250\n",
      " - 2s - loss: 4.0126 - acc: 0.0985 - val_loss: 4.1245 - val_acc: 0.0831\n",
      "Epoch 90/250\n",
      " - 2s - loss: 4.0130 - acc: 0.0985 - val_loss: 4.1064 - val_acc: 0.0872\n",
      "Epoch 91/250\n",
      " - 2s - loss: 4.0123 - acc: 0.0987 - val_loss: 4.0930 - val_acc: 0.0893\n",
      "Epoch 92/250\n",
      " - 2s - loss: 4.0120 - acc: 0.0981 - val_loss: 4.1637 - val_acc: 0.0787\n",
      "Epoch 93/250\n",
      " - 2s - loss: 4.0121 - acc: 0.0989 - val_loss: 4.1219 - val_acc: 0.0842\n",
      "Epoch 94/250\n",
      " - 2s - loss: 4.0122 - acc: 0.0986 - val_loss: 4.0861 - val_acc: 0.0879\n",
      "Epoch 95/250\n",
      " - 2s - loss: 4.0118 - acc: 0.0989 - val_loss: 4.0957 - val_acc: 0.0882\n",
      "Epoch 96/250\n",
      " - 2s - loss: 4.0115 - acc: 0.0987 - val_loss: 4.0830 - val_acc: 0.0909\n",
      "Epoch 97/250\n",
      " - 2s - loss: 4.0145 - acc: 0.0978 - val_loss: 4.1003 - val_acc: 0.0878\n",
      "Epoch 98/250\n",
      " - 2s - loss: 4.0114 - acc: 0.0988 - val_loss: 4.1301 - val_acc: 0.0827\n",
      "Epoch 99/250\n",
      " - 2s - loss: 4.0124 - acc: 0.0982 - val_loss: 4.1566 - val_acc: 0.0807\n",
      "Epoch 100/250\n",
      " - 2s - loss: 4.0115 - acc: 0.0993 - val_loss: 4.0842 - val_acc: 0.0907\n",
      "Epoch 101/250\n",
      " - 2s - loss: 4.0119 - acc: 0.0987 - val_loss: 4.1312 - val_acc: 0.0829\n",
      "Epoch 102/250\n",
      " - 2s - loss: 4.0123 - acc: 0.0988 - val_loss: 4.0742 - val_acc: 0.0897\n",
      "Epoch 103/250\n",
      " - 2s - loss: 4.0109 - acc: 0.0976 - val_loss: 4.0815 - val_acc: 0.0903\n",
      "Epoch 104/250\n",
      " - 2s - loss: 4.0092 - acc: 0.0988 - val_loss: 4.0872 - val_acc: 0.0896\n",
      "Epoch 105/250\n",
      " - 2s - loss: 4.0106 - acc: 0.0983 - val_loss: 4.1036 - val_acc: 0.0857\n",
      "Epoch 106/250\n",
      " - 2s - loss: 4.0127 - acc: 0.0977 - val_loss: 4.1910 - val_acc: 0.0745\n",
      "Epoch 107/250\n",
      " - 2s - loss: 4.0129 - acc: 0.0983 - val_loss: 4.1117 - val_acc: 0.0852\n",
      "Epoch 108/250\n",
      " - 2s - loss: 4.0110 - acc: 0.0989 - val_loss: 4.0849 - val_acc: 0.0890\n",
      "Epoch 109/250\n",
      " - 2s - loss: 4.0119 - acc: 0.0978 - val_loss: 4.1104 - val_acc: 0.0861\n",
      "Epoch 110/250\n",
      " - 2s - loss: 4.0112 - acc: 0.0992 - val_loss: 4.1090 - val_acc: 0.0858\n",
      "Epoch 111/250\n",
      " - 2s - loss: 4.0108 - acc: 0.0986 - val_loss: 4.0789 - val_acc: 0.0893\n",
      "Epoch 112/250\n",
      " - 2s - loss: 4.0109 - acc: 0.0989 - val_loss: 4.0894 - val_acc: 0.0896\n",
      "Epoch 113/250\n",
      " - 2s - loss: 4.0109 - acc: 0.0988 - val_loss: 4.1246 - val_acc: 0.0829\n",
      "Epoch 114/250\n",
      " - 2s - loss: 4.0118 - acc: 0.0987 - val_loss: 4.0721 - val_acc: 0.0907\n",
      "Epoch 115/250\n",
      " - 2s - loss: 4.0086 - acc: 0.0982 - val_loss: 4.1026 - val_acc: 0.0866\n",
      "Epoch 116/250\n",
      " - 2s - loss: 4.0093 - acc: 0.0990 - val_loss: 4.0884 - val_acc: 0.0895\n",
      "Epoch 117/250\n",
      " - 2s - loss: 4.0101 - acc: 0.0982 - val_loss: 4.1174 - val_acc: 0.0838\n",
      "Epoch 118/250\n",
      " - 2s - loss: 4.0107 - acc: 0.0999 - val_loss: 4.1358 - val_acc: 0.0834\n",
      "Epoch 119/250\n",
      " - 2s - loss: 4.0122 - acc: 0.0993 - val_loss: 4.1138 - val_acc: 0.0854\n",
      "Epoch 120/250\n",
      " - 2s - loss: 4.0057 - acc: 0.0991 - val_loss: 4.0879 - val_acc: 0.0891\n",
      "Epoch 121/250\n",
      " - 2s - loss: 4.0096 - acc: 0.0990 - val_loss: 4.0751 - val_acc: 0.0905\n",
      "Epoch 122/250\n",
      " - 2s - loss: 4.0110 - acc: 0.0985 - val_loss: 4.0711 - val_acc: 0.0902\n",
      "Epoch 123/250\n",
      " - 2s - loss: 4.0091 - acc: 0.0985 - val_loss: 4.0904 - val_acc: 0.0890\n",
      "Epoch 124/250\n",
      " - 2s - loss: 4.0121 - acc: 0.0990 - val_loss: 4.0736 - val_acc: 0.0906\n",
      "Epoch 125/250\n",
      " - 2s - loss: 4.0120 - acc: 0.0975 - val_loss: 4.1071 - val_acc: 0.0884\n",
      "Epoch 126/250\n",
      " - 2s - loss: 4.0109 - acc: 0.0998 - val_loss: 4.0887 - val_acc: 0.0880\n",
      "Epoch 127/250\n",
      " - 2s - loss: 4.0065 - acc: 0.0993 - val_loss: 4.0952 - val_acc: 0.0864\n",
      "Epoch 128/250\n",
      " - 2s - loss: 4.0087 - acc: 0.0990 - val_loss: 4.0956 - val_acc: 0.0886\n",
      "Epoch 129/250\n",
      " - 2s - loss: 4.0099 - acc: 0.0986 - val_loss: 4.0813 - val_acc: 0.0890\n",
      "Epoch 130/250\n",
      " - 2s - loss: 4.0079 - acc: 0.0985 - val_loss: 4.0729 - val_acc: 0.0892\n",
      "Epoch 131/250\n",
      " - 2s - loss: 4.0074 - acc: 0.0995 - val_loss: 4.0937 - val_acc: 0.0872\n",
      "Epoch 132/250\n",
      " - 2s - loss: 4.0109 - acc: 0.0986 - val_loss: 4.1501 - val_acc: 0.0802\n",
      "Epoch 133/250\n",
      " - 2s - loss: 4.0093 - acc: 0.0987 - val_loss: 4.1425 - val_acc: 0.0820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/250\n",
      " - 2s - loss: 4.0106 - acc: 0.0982 - val_loss: 4.0910 - val_acc: 0.0894\n",
      "Epoch 135/250\n",
      " - 2s - loss: 4.0052 - acc: 0.0994 - val_loss: 4.1140 - val_acc: 0.0851\n",
      "Epoch 136/250\n",
      " - 2s - loss: 4.0086 - acc: 0.0993 - val_loss: 4.0741 - val_acc: 0.0905\n",
      "Epoch 137/250\n",
      " - 2s - loss: 4.0100 - acc: 0.0990 - val_loss: 4.1020 - val_acc: 0.0884\n",
      "Epoch 138/250\n",
      " - 2s - loss: 4.0088 - acc: 0.0990 - val_loss: 4.0664 - val_acc: 0.0920\n",
      "Epoch 139/250\n",
      " - 2s - loss: 4.0108 - acc: 0.0991 - val_loss: 4.1162 - val_acc: 0.0851\n",
      "Epoch 140/250\n",
      " - 2s - loss: 4.0067 - acc: 0.0999 - val_loss: 4.0891 - val_acc: 0.0887\n",
      "Epoch 141/250\n",
      " - 2s - loss: 4.0079 - acc: 0.0984 - val_loss: 4.1002 - val_acc: 0.0876\n",
      "Epoch 142/250\n",
      " - 2s - loss: 4.0085 - acc: 0.0994 - val_loss: 4.0935 - val_acc: 0.0890\n",
      "Epoch 143/250\n",
      " - 2s - loss: 4.0069 - acc: 0.0991 - val_loss: 4.1217 - val_acc: 0.0846\n",
      "Epoch 144/250\n",
      " - 2s - loss: 4.0105 - acc: 0.0980 - val_loss: 4.0989 - val_acc: 0.0878\n",
      "Epoch 145/250\n",
      " - 2s - loss: 4.0065 - acc: 0.0991 - val_loss: 4.0730 - val_acc: 0.0906\n",
      "Epoch 146/250\n",
      " - 2s - loss: 4.0070 - acc: 0.0992 - val_loss: 4.0705 - val_acc: 0.0923\n",
      "Epoch 147/250\n",
      " - 2s - loss: 4.0078 - acc: 0.0995 - val_loss: 4.1146 - val_acc: 0.0847\n",
      "Epoch 148/250\n",
      " - 2s - loss: 4.0076 - acc: 0.0994 - val_loss: 4.1526 - val_acc: 0.0808\n",
      "Epoch 149/250\n",
      " - 2s - loss: 4.0073 - acc: 0.0996 - val_loss: 4.0809 - val_acc: 0.0874\n",
      "Epoch 150/250\n",
      " - 2s - loss: 4.0080 - acc: 0.0992 - val_loss: 4.0964 - val_acc: 0.0876\n",
      "Epoch 151/250\n",
      " - 2s - loss: 4.0097 - acc: 0.0991 - val_loss: 4.0896 - val_acc: 0.0884\n",
      "Epoch 152/250\n",
      " - 2s - loss: 4.0067 - acc: 0.0993 - val_loss: 4.0786 - val_acc: 0.0893\n",
      "Epoch 153/250\n",
      " - 2s - loss: 4.0079 - acc: 0.0997 - val_loss: 4.0869 - val_acc: 0.0885\n",
      "Epoch 154/250\n",
      " - 2s - loss: 4.0076 - acc: 0.0990 - val_loss: 4.0991 - val_acc: 0.0871\n",
      "Epoch 155/250\n",
      " - 2s - loss: 4.0062 - acc: 0.0992 - val_loss: 4.0870 - val_acc: 0.0898\n",
      "Epoch 156/250\n",
      " - 2s - loss: 4.0068 - acc: 0.0992 - val_loss: 4.0888 - val_acc: 0.0897\n",
      "Epoch 157/250\n",
      " - 2s - loss: 4.0063 - acc: 0.0994 - val_loss: 4.0879 - val_acc: 0.0901\n",
      "Epoch 158/250\n",
      " - 2s - loss: 4.0070 - acc: 0.0996 - val_loss: 4.0794 - val_acc: 0.0904\n",
      "Epoch 159/250\n",
      " - 2s - loss: 4.0074 - acc: 0.0996 - val_loss: 4.1524 - val_acc: 0.0808\n",
      "Epoch 160/250\n",
      " - 2s - loss: 4.0078 - acc: 0.0990 - val_loss: 4.0790 - val_acc: 0.0907\n",
      "Epoch 161/250\n",
      " - 2s - loss: 4.0075 - acc: 0.0990 - val_loss: 4.0811 - val_acc: 0.0910\n",
      "Epoch 162/250\n",
      " - 2s - loss: 4.0065 - acc: 0.0995 - val_loss: 4.0677 - val_acc: 0.0924\n",
      "Epoch 163/250\n",
      " - 2s - loss: 4.0075 - acc: 0.0983 - val_loss: 4.0896 - val_acc: 0.0886\n",
      "Epoch 164/250\n",
      " - 2s - loss: 4.0072 - acc: 0.0993 - val_loss: 4.0886 - val_acc: 0.0898\n",
      "Epoch 165/250\n",
      " - 2s - loss: 4.0085 - acc: 0.0986 - val_loss: 4.1387 - val_acc: 0.0837\n",
      "Epoch 166/250\n",
      " - 2s - loss: 4.0086 - acc: 0.0984 - val_loss: 4.0942 - val_acc: 0.0871\n",
      "Epoch 167/250\n",
      " - 2s - loss: 4.0044 - acc: 0.0993 - val_loss: 4.0681 - val_acc: 0.0901\n",
      "Epoch 168/250\n",
      " - 2s - loss: 4.0079 - acc: 0.0995 - val_loss: 4.0768 - val_acc: 0.0903\n",
      "Epoch 169/250\n",
      " - 2s - loss: 4.0065 - acc: 0.0999 - val_loss: 4.0945 - val_acc: 0.0865\n",
      "Epoch 170/250\n",
      " - 2s - loss: 4.0075 - acc: 0.0986 - val_loss: 4.0638 - val_acc: 0.0935\n",
      "Epoch 171/250\n",
      " - 2s - loss: 4.0058 - acc: 0.0996 - val_loss: 4.1388 - val_acc: 0.0819\n",
      "Epoch 172/250\n",
      " - 2s - loss: 4.0061 - acc: 0.0993 - val_loss: 4.0727 - val_acc: 0.0910\n",
      "Epoch 173/250\n",
      " - 2s - loss: 4.0071 - acc: 0.0997 - val_loss: 4.0795 - val_acc: 0.0909\n",
      "Epoch 174/250\n",
      " - 2s - loss: 4.0064 - acc: 0.0989 - val_loss: 4.1233 - val_acc: 0.0831\n",
      "Epoch 175/250\n",
      " - 2s - loss: 4.0044 - acc: 0.0991 - val_loss: 4.0871 - val_acc: 0.0886\n",
      "Epoch 176/250\n",
      " - 2s - loss: 4.0052 - acc: 0.1002 - val_loss: 4.0693 - val_acc: 0.0926\n",
      "Epoch 177/250\n",
      " - 2s - loss: 4.0051 - acc: 0.0993 - val_loss: 4.0779 - val_acc: 0.0907\n",
      "Epoch 178/250\n",
      " - 2s - loss: 4.0046 - acc: 0.0990 - val_loss: 4.0825 - val_acc: 0.0895\n",
      "Epoch 179/250\n",
      " - 2s - loss: 4.0060 - acc: 0.1002 - val_loss: 4.0759 - val_acc: 0.0903\n",
      "Epoch 180/250\n",
      " - 2s - loss: 4.0032 - acc: 0.0995 - val_loss: 4.0727 - val_acc: 0.0905\n",
      "Epoch 181/250\n",
      " - 2s - loss: 4.0048 - acc: 0.0993 - val_loss: 4.0645 - val_acc: 0.0933\n",
      "Epoch 182/250\n",
      " - 2s - loss: 4.0030 - acc: 0.0994 - val_loss: 4.1221 - val_acc: 0.0840\n",
      "Epoch 183/250\n",
      " - 2s - loss: 4.0069 - acc: 0.0987 - val_loss: 4.0709 - val_acc: 0.0922\n",
      "Epoch 184/250\n",
      " - 2s - loss: 4.0066 - acc: 0.0994 - val_loss: 4.0892 - val_acc: 0.0905\n",
      "Epoch 185/250\n",
      " - 2s - loss: 4.0048 - acc: 0.1001 - val_loss: 4.0804 - val_acc: 0.0905\n",
      "Epoch 186/250\n",
      " - 2s - loss: 4.0044 - acc: 0.1001 - val_loss: 4.1043 - val_acc: 0.0871\n",
      "Epoch 187/250\n",
      " - 2s - loss: 4.0062 - acc: 0.0985 - val_loss: 4.0768 - val_acc: 0.0898\n",
      "Epoch 188/250\n",
      " - 2s - loss: 4.0049 - acc: 0.0994 - val_loss: 4.1373 - val_acc: 0.0799\n",
      "Epoch 189/250\n",
      " - 2s - loss: 4.0047 - acc: 0.0996 - val_loss: 4.0951 - val_acc: 0.0879\n",
      "Epoch 190/250\n",
      " - 2s - loss: 4.0042 - acc: 0.1000 - val_loss: 4.1116 - val_acc: 0.0870\n",
      "Epoch 191/250\n",
      " - 2s - loss: 4.0055 - acc: 0.0991 - val_loss: 4.0822 - val_acc: 0.0890\n",
      "Epoch 192/250\n",
      " - 2s - loss: 4.0055 - acc: 0.0991 - val_loss: 4.1244 - val_acc: 0.0852\n",
      "Epoch 193/250\n",
      " - 2s - loss: 4.0038 - acc: 0.1005 - val_loss: 4.0624 - val_acc: 0.0940\n",
      "Epoch 194/250\n",
      " - 2s - loss: 4.0051 - acc: 0.1001 - val_loss: 4.0853 - val_acc: 0.0911\n",
      "Epoch 195/250\n",
      " - 2s - loss: 4.0030 - acc: 0.1004 - val_loss: 4.0823 - val_acc: 0.0895\n",
      "Epoch 196/250\n",
      " - 2s - loss: 4.0022 - acc: 0.1000 - val_loss: 4.0639 - val_acc: 0.0907\n",
      "Epoch 197/250\n",
      " - 2s - loss: 4.0033 - acc: 0.1003 - val_loss: 4.1196 - val_acc: 0.0836\n",
      "Epoch 198/250\n",
      " - 2s - loss: 4.0062 - acc: 0.0988 - val_loss: 4.0978 - val_acc: 0.0860\n",
      "Epoch 199/250\n",
      " - 2s - loss: 4.0036 - acc: 0.1003 - val_loss: 4.0816 - val_acc: 0.0890\n",
      "Epoch 200/250\n",
      " - 2s - loss: 4.0047 - acc: 0.0991 - val_loss: 4.0818 - val_acc: 0.0913\n",
      "Epoch 201/250\n",
      " - 2s - loss: 4.0023 - acc: 0.0996 - val_loss: 4.0760 - val_acc: 0.0904\n",
      "Epoch 202/250\n",
      " - 2s - loss: 4.0036 - acc: 0.0994 - val_loss: 4.1157 - val_acc: 0.0857\n",
      "Epoch 203/250\n",
      " - 2s - loss: 4.0046 - acc: 0.1000 - val_loss: 4.1058 - val_acc: 0.0852\n",
      "Epoch 204/250\n",
      " - 2s - loss: 4.0027 - acc: 0.0999 - val_loss: 4.1013 - val_acc: 0.0879\n",
      "Epoch 205/250\n",
      " - 2s - loss: 4.0020 - acc: 0.0997 - val_loss: 4.0783 - val_acc: 0.0910\n",
      "Epoch 206/250\n",
      " - 2s - loss: 4.0023 - acc: 0.1002 - val_loss: 4.1132 - val_acc: 0.0857\n",
      "Epoch 207/250\n",
      " - 2s - loss: 4.0040 - acc: 0.0994 - val_loss: 4.0729 - val_acc: 0.0926\n",
      "Epoch 208/250\n",
      " - 2s - loss: 4.0050 - acc: 0.0997 - val_loss: 4.0719 - val_acc: 0.0915\n",
      "Epoch 209/250\n",
      " - 2s - loss: 4.0029 - acc: 0.0992 - val_loss: 4.0886 - val_acc: 0.0901\n",
      "Epoch 210/250\n",
      " - 2s - loss: 4.0049 - acc: 0.0993 - val_loss: 4.1047 - val_acc: 0.0871\n",
      "Epoch 211/250\n",
      " - 2s - loss: 4.0051 - acc: 0.1000 - val_loss: 4.0895 - val_acc: 0.0888\n",
      "Epoch 212/250\n",
      " - 2s - loss: 4.0047 - acc: 0.0999 - val_loss: 4.1004 - val_acc: 0.0859\n",
      "Epoch 213/250\n",
      " - 2s - loss: 4.0012 - acc: 0.0998 - val_loss: 4.1015 - val_acc: 0.0869\n",
      "Epoch 214/250\n",
      " - 2s - loss: 4.0031 - acc: 0.0996 - val_loss: 4.0901 - val_acc: 0.0888\n",
      "Epoch 215/250\n",
      " - 2s - loss: 4.0016 - acc: 0.0999 - val_loss: 4.0745 - val_acc: 0.0921\n",
      "Epoch 216/250\n",
      " - 2s - loss: 4.0039 - acc: 0.0999 - val_loss: 4.0609 - val_acc: 0.0933\n",
      "Epoch 217/250\n",
      " - 2s - loss: 4.0016 - acc: 0.1002 - val_loss: 4.0596 - val_acc: 0.0932\n",
      "Epoch 218/250\n",
      " - 2s - loss: 4.0016 - acc: 0.1002 - val_loss: 4.0725 - val_acc: 0.0907\n",
      "Epoch 219/250\n",
      " - 2s - loss: 4.0039 - acc: 0.0995 - val_loss: 4.1063 - val_acc: 0.0885\n",
      "Epoch 220/250\n",
      " - 2s - loss: 4.0040 - acc: 0.0996 - val_loss: 4.0834 - val_acc: 0.0899\n",
      "Epoch 221/250\n",
      " - 2s - loss: 4.0038 - acc: 0.0993 - val_loss: 4.0891 - val_acc: 0.0879\n",
      "Epoch 222/250\n",
      " - 2s - loss: 4.0009 - acc: 0.0997 - val_loss: 4.0716 - val_acc: 0.0926\n",
      "Epoch 223/250\n",
      " - 2s - loss: 4.0005 - acc: 0.0995 - val_loss: 4.0762 - val_acc: 0.0907\n",
      "Epoch 224/250\n",
      " - 2s - loss: 4.0009 - acc: 0.0992 - val_loss: 4.0619 - val_acc: 0.0927\n",
      "Epoch 225/250\n",
      " - 2s - loss: 4.0006 - acc: 0.1008 - val_loss: 4.0749 - val_acc: 0.0926\n",
      "Epoch 226/250\n",
      " - 2s - loss: 4.0020 - acc: 0.1001 - val_loss: 4.1092 - val_acc: 0.0867\n",
      "Epoch 227/250\n",
      " - 2s - loss: 4.0006 - acc: 0.1001 - val_loss: 4.0830 - val_acc: 0.0905\n",
      "Epoch 228/250\n",
      " - 2s - loss: 4.0045 - acc: 0.1001 - val_loss: 4.0764 - val_acc: 0.0911\n",
      "Epoch 229/250\n",
      " - 2s - loss: 3.9993 - acc: 0.0998 - val_loss: 4.0737 - val_acc: 0.0910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/250\n",
      " - 2s - loss: 4.0011 - acc: 0.1002 - val_loss: 4.0742 - val_acc: 0.0916\n",
      "Epoch 231/250\n",
      " - 2s - loss: 4.0028 - acc: 0.1000 - val_loss: 4.0782 - val_acc: 0.0912\n",
      "Epoch 232/250\n",
      " - 2s - loss: 4.0027 - acc: 0.1006 - val_loss: 4.0851 - val_acc: 0.0893\n",
      "Epoch 233/250\n",
      " - 2s - loss: 4.0025 - acc: 0.1002 - val_loss: 4.1082 - val_acc: 0.0836\n",
      "Epoch 234/250\n",
      " - 2s - loss: 4.0000 - acc: 0.1003 - val_loss: 4.1046 - val_acc: 0.0864\n",
      "Epoch 235/250\n",
      " - 2s - loss: 4.0007 - acc: 0.0994 - val_loss: 4.0744 - val_acc: 0.0915\n",
      "Epoch 236/250\n",
      " - 2s - loss: 3.9983 - acc: 0.1005 - val_loss: 4.0692 - val_acc: 0.0912\n",
      "Epoch 237/250\n",
      " - 2s - loss: 4.0030 - acc: 0.0999 - val_loss: 4.0759 - val_acc: 0.0901\n",
      "Epoch 238/250\n",
      " - 2s - loss: 4.0018 - acc: 0.0995 - val_loss: 4.0837 - val_acc: 0.0904\n",
      "Epoch 239/250\n",
      " - 2s - loss: 4.0021 - acc: 0.0997 - val_loss: 4.0658 - val_acc: 0.0918\n",
      "Epoch 240/250\n",
      " - 2s - loss: 4.0028 - acc: 0.0988 - val_loss: 4.1008 - val_acc: 0.0860\n",
      "Epoch 241/250\n",
      " - 2s - loss: 4.0030 - acc: 0.0988 - val_loss: 4.0585 - val_acc: 0.0946\n",
      "Epoch 242/250\n",
      " - 2s - loss: 3.9993 - acc: 0.1001 - val_loss: 4.0607 - val_acc: 0.0941\n",
      "Epoch 243/250\n",
      " - 2s - loss: 3.9999 - acc: 0.1007 - val_loss: 4.0817 - val_acc: 0.0901\n",
      "Epoch 244/250\n",
      " - 2s - loss: 3.9979 - acc: 0.1004 - val_loss: 4.1136 - val_acc: 0.0879\n",
      "Epoch 245/250\n",
      " - 2s - loss: 4.0014 - acc: 0.0997 - val_loss: 4.0854 - val_acc: 0.0899\n",
      "Epoch 246/250\n",
      " - 2s - loss: 4.0017 - acc: 0.1005 - val_loss: 4.0959 - val_acc: 0.0869\n",
      "Epoch 247/250\n",
      " - 2s - loss: 4.0021 - acc: 0.1004 - val_loss: 4.0703 - val_acc: 0.0912\n",
      "Epoch 248/250\n",
      " - 2s - loss: 4.0030 - acc: 0.0998 - val_loss: 4.0758 - val_acc: 0.0914\n",
      "Epoch 249/250\n",
      " - 2s - loss: 4.0012 - acc: 0.1001 - val_loss: 4.1038 - val_acc: 0.0869\n",
      "Epoch 250/250\n",
      " - 2s - loss: 4.0013 - acc: 0.0998 - val_loss: 4.0749 - val_acc: 0.0911\n",
      "Mini-Train:   2 Test Accuracy: 9.11% Learning Rate: 0.0012500\n",
      "Train on 136770 samples, validate on 15266 samples\n",
      "Epoch 1/250\n",
      " - 2s - loss: 3.9997 - acc: 0.1002 - val_loss: 4.0836 - val_acc: 0.0897\n",
      "Epoch 2/250\n",
      " - 2s - loss: 3.9970 - acc: 0.1007 - val_loss: 4.0600 - val_acc: 0.0939\n",
      "Epoch 3/250\n",
      " - 2s - loss: 3.9980 - acc: 0.1003 - val_loss: 4.0803 - val_acc: 0.0903\n",
      "Epoch 4/250\n",
      " - 2s - loss: 3.9995 - acc: 0.1004 - val_loss: 4.0651 - val_acc: 0.0931\n",
      "Epoch 5/250\n",
      " - 2s - loss: 3.9970 - acc: 0.1004 - val_loss: 4.0653 - val_acc: 0.0919\n",
      "Epoch 6/250\n",
      " - 2s - loss: 3.9985 - acc: 0.1002 - val_loss: 4.0622 - val_acc: 0.0934\n",
      "Epoch 7/250\n",
      " - 2s - loss: 3.9958 - acc: 0.0993 - val_loss: 4.0554 - val_acc: 0.0949\n",
      "Epoch 8/250\n",
      " - 2s - loss: 3.9976 - acc: 0.1011 - val_loss: 4.0553 - val_acc: 0.0945\n",
      "Epoch 9/250\n",
      " - 2s - loss: 3.9933 - acc: 0.1008 - val_loss: 4.0570 - val_acc: 0.0941\n",
      "Epoch 10/250\n",
      " - 2s - loss: 3.9960 - acc: 0.1010 - val_loss: 4.0747 - val_acc: 0.0918\n",
      "Epoch 11/250\n",
      " - 2s - loss: 3.9985 - acc: 0.1002 - val_loss: 4.0591 - val_acc: 0.0938\n",
      "Epoch 12/250\n",
      " - 2s - loss: 3.9982 - acc: 0.1001 - val_loss: 4.0672 - val_acc: 0.0939\n",
      "Epoch 13/250\n",
      " - 2s - loss: 3.9968 - acc: 0.1006 - val_loss: 4.0669 - val_acc: 0.0918\n",
      "Epoch 14/250\n",
      " - 2s - loss: 3.9993 - acc: 0.1000 - val_loss: 4.0603 - val_acc: 0.0939\n",
      "Epoch 15/250\n",
      " - 2s - loss: 3.9968 - acc: 0.1001 - val_loss: 4.0636 - val_acc: 0.0922\n",
      "Epoch 16/250\n",
      " - 2s - loss: 3.9995 - acc: 0.1005 - val_loss: 4.0700 - val_acc: 0.0910\n",
      "Epoch 17/250\n",
      " - 2s - loss: 3.9965 - acc: 0.1006 - val_loss: 4.0749 - val_acc: 0.0907\n",
      "Epoch 18/250\n",
      " - 2s - loss: 3.9963 - acc: 0.1008 - val_loss: 4.0786 - val_acc: 0.0916\n",
      "Epoch 19/250\n",
      " - 2s - loss: 3.9976 - acc: 0.1009 - val_loss: 4.0691 - val_acc: 0.0916\n",
      "Epoch 20/250\n",
      " - 2s - loss: 3.9960 - acc: 0.1014 - val_loss: 4.0732 - val_acc: 0.0915\n",
      "Epoch 21/250\n",
      " - 2s - loss: 3.9962 - acc: 0.1007 - val_loss: 4.0569 - val_acc: 0.0943\n",
      "Epoch 22/250\n",
      " - 2s - loss: 3.9968 - acc: 0.1007 - val_loss: 4.0638 - val_acc: 0.0930\n",
      "Epoch 23/250\n",
      " - 2s - loss: 3.9979 - acc: 0.1010 - val_loss: 4.0836 - val_acc: 0.0902\n",
      "Epoch 24/250\n",
      " - 2s - loss: 3.9981 - acc: 0.1003 - val_loss: 4.0704 - val_acc: 0.0918\n",
      "Epoch 25/250\n",
      " - 2s - loss: 3.9947 - acc: 0.1013 - val_loss: 4.0526 - val_acc: 0.0946\n",
      "Epoch 26/250\n",
      " - 2s - loss: 3.9968 - acc: 0.1005 - val_loss: 4.0669 - val_acc: 0.0935\n",
      "Epoch 27/250\n",
      " - 2s - loss: 3.9985 - acc: 0.1007 - val_loss: 4.0591 - val_acc: 0.0935\n",
      "Epoch 28/250\n",
      " - 2s - loss: 3.9967 - acc: 0.1006 - val_loss: 4.0758 - val_acc: 0.0908\n",
      "Epoch 29/250\n",
      " - 2s - loss: 3.9985 - acc: 0.1000 - val_loss: 4.0547 - val_acc: 0.0941\n",
      "Epoch 30/250\n",
      " - 2s - loss: 3.9976 - acc: 0.1001 - val_loss: 4.0524 - val_acc: 0.0957\n",
      "Epoch 31/250\n",
      " - 2s - loss: 4.0005 - acc: 0.0994 - val_loss: 4.0615 - val_acc: 0.0931\n",
      "Epoch 32/250\n",
      " - 2s - loss: 3.9957 - acc: 0.1017 - val_loss: 4.0664 - val_acc: 0.0933\n",
      "Epoch 33/250\n",
      " - 2s - loss: 3.9961 - acc: 0.1007 - val_loss: 4.0598 - val_acc: 0.0929\n",
      "Epoch 34/250\n",
      " - 2s - loss: 3.9979 - acc: 0.1006 - val_loss: 4.0646 - val_acc: 0.0944\n",
      "Epoch 35/250\n",
      " - 2s - loss: 3.9969 - acc: 0.1007 - val_loss: 4.0617 - val_acc: 0.0937\n",
      "Epoch 36/250\n",
      " - 2s - loss: 3.9964 - acc: 0.1005 - val_loss: 4.0563 - val_acc: 0.0935\n",
      "Epoch 37/250\n",
      " - 2s - loss: 3.9999 - acc: 0.1001 - val_loss: 4.0740 - val_acc: 0.0916\n",
      "Epoch 38/250\n",
      " - 2s - loss: 3.9959 - acc: 0.1016 - val_loss: 4.0644 - val_acc: 0.0923\n",
      "Epoch 39/250\n",
      " - 2s - loss: 3.9961 - acc: 0.1008 - val_loss: 4.0777 - val_acc: 0.0928\n",
      "Epoch 40/250\n",
      " - 2s - loss: 3.9975 - acc: 0.1006 - val_loss: 4.0789 - val_acc: 0.0920\n",
      "Epoch 41/250\n",
      " - 2s - loss: 3.9981 - acc: 0.1002 - val_loss: 4.0739 - val_acc: 0.0910\n",
      "Epoch 42/250\n",
      " - 2s - loss: 3.9961 - acc: 0.1006 - val_loss: 4.0704 - val_acc: 0.0939\n",
      "Epoch 43/250\n",
      " - 2s - loss: 3.9957 - acc: 0.1013 - val_loss: 4.0584 - val_acc: 0.0935\n",
      "Epoch 44/250\n",
      " - 2s - loss: 3.9957 - acc: 0.1008 - val_loss: 4.0890 - val_acc: 0.0896\n",
      "Epoch 45/250\n",
      " - 2s - loss: 3.9964 - acc: 0.0995 - val_loss: 4.0716 - val_acc: 0.0936\n",
      "Epoch 46/250\n",
      " - 2s - loss: 3.9955 - acc: 0.1013 - val_loss: 4.0629 - val_acc: 0.0938\n",
      "Epoch 47/250\n",
      " - 2s - loss: 3.9968 - acc: 0.1004 - val_loss: 4.0658 - val_acc: 0.0935\n",
      "Epoch 48/250\n",
      " - 2s - loss: 3.9984 - acc: 0.1008 - val_loss: 4.0975 - val_acc: 0.0867\n",
      "Epoch 49/250\n",
      " - 2s - loss: 3.9970 - acc: 0.1010 - val_loss: 4.0603 - val_acc: 0.0942\n",
      "Epoch 50/250\n",
      " - 2s - loss: 3.9965 - acc: 0.1005 - val_loss: 4.0623 - val_acc: 0.0939\n",
      "Epoch 51/250\n",
      " - 2s - loss: 3.9971 - acc: 0.1002 - val_loss: 4.0645 - val_acc: 0.0924\n",
      "Epoch 52/250\n",
      " - 2s - loss: 3.9959 - acc: 0.1011 - val_loss: 4.0922 - val_acc: 0.0901\n",
      "Epoch 53/250\n",
      " - 2s - loss: 3.9949 - acc: 0.1008 - val_loss: 4.0634 - val_acc: 0.0931\n",
      "Epoch 54/250\n",
      " - 2s - loss: 3.9954 - acc: 0.1013 - val_loss: 4.0668 - val_acc: 0.0945\n",
      "Epoch 55/250\n",
      " - 2s - loss: 3.9937 - acc: 0.1007 - val_loss: 4.0732 - val_acc: 0.0932\n",
      "Epoch 56/250\n",
      " - 2s - loss: 3.9977 - acc: 0.1003 - val_loss: 4.0691 - val_acc: 0.0935\n",
      "Epoch 57/250\n",
      " - 2s - loss: 3.9960 - acc: 0.1002 - val_loss: 4.0675 - val_acc: 0.0919\n",
      "Epoch 58/250\n",
      " - 2s - loss: 3.9926 - acc: 0.1016 - val_loss: 4.0713 - val_acc: 0.0920\n",
      "Epoch 59/250\n",
      " - 2s - loss: 3.9958 - acc: 0.1001 - val_loss: 4.0717 - val_acc: 0.0922\n",
      "Epoch 60/250\n",
      " - 2s - loss: 3.9952 - acc: 0.1009 - val_loss: 4.0587 - val_acc: 0.0946\n",
      "Epoch 61/250\n",
      " - 2s - loss: 3.9959 - acc: 0.1004 - val_loss: 4.0695 - val_acc: 0.0914\n",
      "Epoch 62/250\n",
      " - 2s - loss: 3.9939 - acc: 0.1017 - val_loss: 4.0653 - val_acc: 0.0926\n",
      "Epoch 63/250\n",
      " - 2s - loss: 3.9969 - acc: 0.1015 - val_loss: 4.0726 - val_acc: 0.0937\n",
      "Epoch 64/250\n",
      " - 2s - loss: 3.9944 - acc: 0.1013 - val_loss: 4.0691 - val_acc: 0.0937\n",
      "Epoch 65/250\n",
      " - 2s - loss: 3.9955 - acc: 0.1014 - val_loss: 4.0631 - val_acc: 0.0925\n",
      "Epoch 66/250\n",
      " - 2s - loss: 3.9947 - acc: 0.1006 - val_loss: 4.0823 - val_acc: 0.0915\n",
      "Epoch 67/250\n",
      " - 2s - loss: 3.9960 - acc: 0.1011 - val_loss: 4.0690 - val_acc: 0.0928\n",
      "Epoch 68/250\n",
      " - 2s - loss: 3.9950 - acc: 0.1012 - val_loss: 4.0684 - val_acc: 0.0936\n",
      "Epoch 69/250\n",
      " - 2s - loss: 3.9966 - acc: 0.1005 - val_loss: 4.0560 - val_acc: 0.0945\n",
      "Epoch 70/250\n",
      " - 2s - loss: 3.9947 - acc: 0.1002 - val_loss: 4.0770 - val_acc: 0.0924\n",
      "Epoch 71/250\n",
      " - 2s - loss: 3.9965 - acc: 0.1005 - val_loss: 4.0582 - val_acc: 0.0934\n",
      "Epoch 72/250\n",
      " - 2s - loss: 3.9949 - acc: 0.1009 - val_loss: 4.0587 - val_acc: 0.0954\n",
      "Epoch 73/250\n",
      " - 2s - loss: 3.9945 - acc: 0.1008 - val_loss: 4.0570 - val_acc: 0.0942\n",
      "Epoch 74/250\n",
      " - 2s - loss: 3.9959 - acc: 0.1005 - val_loss: 4.0749 - val_acc: 0.0921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/250\n",
      " - 2s - loss: 3.9947 - acc: 0.1014 - val_loss: 4.0691 - val_acc: 0.0911\n",
      "Epoch 76/250\n",
      " - 2s - loss: 3.9936 - acc: 0.1009 - val_loss: 4.0612 - val_acc: 0.0931\n",
      "Epoch 77/250\n",
      " - 2s - loss: 3.9925 - acc: 0.1017 - val_loss: 4.0599 - val_acc: 0.0937\n",
      "Epoch 78/250\n",
      " - 2s - loss: 3.9950 - acc: 0.1002 - val_loss: 4.0626 - val_acc: 0.0933\n",
      "Epoch 79/250\n",
      " - 2s - loss: 3.9950 - acc: 0.1009 - val_loss: 4.0765 - val_acc: 0.0918\n",
      "Epoch 80/250\n",
      " - 2s - loss: 3.9965 - acc: 0.1013 - val_loss: 4.0832 - val_acc: 0.0921\n",
      "Epoch 81/250\n",
      " - 2s - loss: 3.9941 - acc: 0.1011 - val_loss: 4.0524 - val_acc: 0.0940\n",
      "Epoch 82/250\n",
      " - 2s - loss: 3.9952 - acc: 0.1008 - val_loss: 4.0540 - val_acc: 0.0946\n",
      "Epoch 83/250\n",
      " - 2s - loss: 3.9946 - acc: 0.1005 - val_loss: 4.0528 - val_acc: 0.0950\n",
      "Epoch 84/250\n",
      " - 2s - loss: 3.9945 - acc: 0.1012 - val_loss: 4.0552 - val_acc: 0.0950\n",
      "Epoch 85/250\n",
      " - 2s - loss: 3.9924 - acc: 0.1011 - val_loss: 4.0690 - val_acc: 0.0926\n",
      "Epoch 86/250\n",
      " - 2s - loss: 3.9946 - acc: 0.1009 - val_loss: 4.0715 - val_acc: 0.0916\n",
      "Epoch 87/250\n",
      " - 2s - loss: 3.9928 - acc: 0.1014 - val_loss: 4.0623 - val_acc: 0.0930\n",
      "Epoch 88/250\n",
      " - 2s - loss: 3.9976 - acc: 0.1014 - val_loss: 4.0818 - val_acc: 0.0901\n",
      "Epoch 89/250\n",
      " - 2s - loss: 3.9933 - acc: 0.1018 - val_loss: 4.0615 - val_acc: 0.0942\n",
      "Epoch 90/250\n",
      " - 2s - loss: 3.9957 - acc: 0.1012 - val_loss: 4.0675 - val_acc: 0.0932\n",
      "Epoch 91/250\n",
      " - 2s - loss: 3.9947 - acc: 0.1009 - val_loss: 4.0599 - val_acc: 0.0933\n",
      "Epoch 92/250\n",
      " - 2s - loss: 3.9936 - acc: 0.1015 - val_loss: 4.0749 - val_acc: 0.0921\n",
      "Epoch 93/250\n",
      " - 2s - loss: 3.9944 - acc: 0.1014 - val_loss: 4.0661 - val_acc: 0.0931\n",
      "Epoch 94/250\n",
      " - 2s - loss: 3.9940 - acc: 0.0999 - val_loss: 4.0624 - val_acc: 0.0916\n",
      "Epoch 95/250\n",
      " - 2s - loss: 3.9944 - acc: 0.1011 - val_loss: 4.0696 - val_acc: 0.0918\n",
      "Epoch 96/250\n",
      " - 2s - loss: 3.9944 - acc: 0.1014 - val_loss: 4.0593 - val_acc: 0.0924\n",
      "Epoch 97/250\n",
      " - 2s - loss: 3.9924 - acc: 0.1003 - val_loss: 4.0520 - val_acc: 0.0952\n",
      "Epoch 98/250\n",
      " - 2s - loss: 3.9938 - acc: 0.1012 - val_loss: 4.0819 - val_acc: 0.0900\n",
      "Epoch 99/250\n",
      " - 2s - loss: 3.9916 - acc: 0.1013 - val_loss: 4.0555 - val_acc: 0.0941\n",
      "Epoch 100/250\n",
      " - 2s - loss: 3.9935 - acc: 0.1016 - val_loss: 4.0509 - val_acc: 0.0945\n",
      "Epoch 101/250\n",
      " - 2s - loss: 3.9963 - acc: 0.1001 - val_loss: 4.0612 - val_acc: 0.0926\n",
      "Epoch 102/250\n",
      " - 2s - loss: 3.9951 - acc: 0.1006 - val_loss: 4.0630 - val_acc: 0.0937\n",
      "Epoch 103/250\n",
      " - 2s - loss: 3.9951 - acc: 0.1014 - val_loss: 4.0596 - val_acc: 0.0938\n",
      "Epoch 104/250\n",
      " - 2s - loss: 3.9930 - acc: 0.1014 - val_loss: 4.0615 - val_acc: 0.0943\n",
      "Epoch 105/250\n",
      " - 2s - loss: 3.9917 - acc: 0.1013 - val_loss: 4.0589 - val_acc: 0.0943\n",
      "Epoch 106/250\n",
      " - 2s - loss: 3.9938 - acc: 0.1004 - val_loss: 4.0622 - val_acc: 0.0934\n",
      "Epoch 107/250\n",
      " - 2s - loss: 3.9950 - acc: 0.1009 - val_loss: 4.0585 - val_acc: 0.0937\n",
      "Epoch 108/250\n",
      " - 2s - loss: 3.9933 - acc: 0.1011 - val_loss: 4.0630 - val_acc: 0.0926\n",
      "Epoch 109/250\n",
      " - 2s - loss: 3.9939 - acc: 0.1010 - val_loss: 4.0608 - val_acc: 0.0937\n",
      "Epoch 110/250\n",
      " - 2s - loss: 3.9937 - acc: 0.1009 - val_loss: 4.0858 - val_acc: 0.0899\n",
      "Epoch 111/250\n",
      " - 2s - loss: 3.9917 - acc: 0.1000 - val_loss: 4.0599 - val_acc: 0.0942\n",
      "Epoch 112/250\n",
      " - 2s - loss: 3.9907 - acc: 0.1016 - val_loss: 4.0695 - val_acc: 0.0931\n",
      "Epoch 113/250\n",
      " - 2s - loss: 3.9940 - acc: 0.1004 - val_loss: 4.0557 - val_acc: 0.0945\n",
      "Epoch 114/250\n",
      " - 2s - loss: 3.9908 - acc: 0.1015 - val_loss: 4.0586 - val_acc: 0.0937\n",
      "Epoch 115/250\n",
      " - 2s - loss: 3.9934 - acc: 0.1010 - val_loss: 4.0645 - val_acc: 0.0943\n",
      "Epoch 116/250\n",
      " - 2s - loss: 3.9956 - acc: 0.1011 - val_loss: 4.0638 - val_acc: 0.0933\n",
      "Epoch 117/250\n",
      " - 2s - loss: 3.9930 - acc: 0.1009 - val_loss: 4.0642 - val_acc: 0.0936\n",
      "Epoch 118/250\n",
      " - 2s - loss: 3.9949 - acc: 0.1010 - val_loss: 4.0683 - val_acc: 0.0916\n",
      "Epoch 119/250\n",
      " - 2s - loss: 3.9936 - acc: 0.1008 - val_loss: 4.0593 - val_acc: 0.0938\n",
      "Epoch 120/250\n",
      " - 2s - loss: 3.9918 - acc: 0.1007 - val_loss: 4.0569 - val_acc: 0.0937\n",
      "Epoch 121/250\n",
      " - 2s - loss: 3.9964 - acc: 0.1013 - val_loss: 4.0566 - val_acc: 0.0938\n",
      "Epoch 122/250\n",
      " - 2s - loss: 3.9932 - acc: 0.1011 - val_loss: 4.0532 - val_acc: 0.0931\n",
      "Epoch 123/250\n",
      " - 2s - loss: 3.9929 - acc: 0.1011 - val_loss: 4.0576 - val_acc: 0.0939\n",
      "Epoch 124/250\n",
      " - 2s - loss: 3.9923 - acc: 0.1020 - val_loss: 4.0626 - val_acc: 0.0945\n",
      "Epoch 125/250\n",
      " - 2s - loss: 3.9917 - acc: 0.1015 - val_loss: 4.0532 - val_acc: 0.0943\n",
      "Epoch 126/250\n",
      " - 2s - loss: 3.9933 - acc: 0.1022 - val_loss: 4.0723 - val_acc: 0.0947\n",
      "Epoch 127/250\n",
      " - 2s - loss: 3.9908 - acc: 0.1018 - val_loss: 4.0700 - val_acc: 0.0916\n",
      "Epoch 128/250\n",
      " - 2s - loss: 3.9916 - acc: 0.1005 - val_loss: 4.0607 - val_acc: 0.0930\n",
      "Epoch 129/250\n",
      " - 2s - loss: 3.9939 - acc: 0.1018 - val_loss: 4.0618 - val_acc: 0.0931\n",
      "Epoch 130/250\n",
      " - 2s - loss: 3.9927 - acc: 0.1009 - val_loss: 4.0585 - val_acc: 0.0946\n",
      "Epoch 131/250\n",
      " - 2s - loss: 3.9938 - acc: 0.1010 - val_loss: 4.0751 - val_acc: 0.0914\n",
      "Epoch 132/250\n",
      " - 2s - loss: 3.9925 - acc: 0.1020 - val_loss: 4.0758 - val_acc: 0.0924\n",
      "Epoch 133/250\n",
      " - 2s - loss: 3.9932 - acc: 0.1018 - val_loss: 4.0575 - val_acc: 0.0961\n",
      "Epoch 134/250\n",
      " - 2s - loss: 3.9929 - acc: 0.1008 - val_loss: 4.0595 - val_acc: 0.0950\n",
      "Epoch 135/250\n",
      " - 2s - loss: 3.9927 - acc: 0.1019 - val_loss: 4.0571 - val_acc: 0.0939\n",
      "Epoch 136/250\n",
      " - 2s - loss: 3.9922 - acc: 0.1014 - val_loss: 4.0531 - val_acc: 0.0952\n",
      "Epoch 137/250\n",
      " - 2s - loss: 3.9938 - acc: 0.1010 - val_loss: 4.0644 - val_acc: 0.0928\n",
      "Epoch 138/250\n",
      " - 2s - loss: 3.9918 - acc: 0.1014 - val_loss: 4.0523 - val_acc: 0.0958\n",
      "Epoch 139/250\n",
      " - 2s - loss: 3.9924 - acc: 0.1006 - val_loss: 4.0513 - val_acc: 0.0944\n",
      "Epoch 140/250\n",
      " - 2s - loss: 3.9923 - acc: 0.1009 - val_loss: 4.0568 - val_acc: 0.0955\n",
      "Epoch 141/250\n",
      " - 2s - loss: 3.9936 - acc: 0.1021 - val_loss: 4.0935 - val_acc: 0.0895\n",
      "Epoch 142/250\n",
      " - 2s - loss: 3.9931 - acc: 0.1008 - val_loss: 4.0593 - val_acc: 0.0937\n",
      "Epoch 143/250\n",
      " - 2s - loss: 3.9915 - acc: 0.1014 - val_loss: 4.0614 - val_acc: 0.0939\n",
      "Epoch 144/250\n",
      " - 2s - loss: 3.9931 - acc: 0.1001 - val_loss: 4.0626 - val_acc: 0.0943\n",
      "Epoch 145/250\n",
      " - 2s - loss: 3.9945 - acc: 0.1005 - val_loss: 4.0607 - val_acc: 0.0935\n",
      "Epoch 146/250\n",
      " - 2s - loss: 3.9908 - acc: 0.1017 - val_loss: 4.0528 - val_acc: 0.0947\n",
      "Epoch 147/250\n",
      " - 2s - loss: 3.9922 - acc: 0.1016 - val_loss: 4.0730 - val_acc: 0.0916\n",
      "Epoch 148/250\n",
      " - 2s - loss: 3.9920 - acc: 0.1014 - val_loss: 4.0592 - val_acc: 0.0949\n",
      "Epoch 149/250\n",
      " - 2s - loss: 3.9916 - acc: 0.1019 - val_loss: 4.0658 - val_acc: 0.0929\n",
      "Epoch 150/250\n",
      " - 2s - loss: 3.9911 - acc: 0.1015 - val_loss: 4.0531 - val_acc: 0.0950\n",
      "Epoch 151/250\n",
      " - 2s - loss: 3.9930 - acc: 0.1014 - val_loss: 4.0542 - val_acc: 0.0961\n",
      "Epoch 152/250\n",
      " - 2s - loss: 3.9922 - acc: 0.1013 - val_loss: 4.0506 - val_acc: 0.0949\n",
      "Epoch 153/250\n",
      " - 2s - loss: 3.9926 - acc: 0.1017 - val_loss: 4.0706 - val_acc: 0.0937\n",
      "Epoch 154/250\n",
      " - 2s - loss: 3.9925 - acc: 0.1014 - val_loss: 4.0560 - val_acc: 0.0935\n",
      "Epoch 155/250\n",
      " - 2s - loss: 3.9908 - acc: 0.1007 - val_loss: 4.0571 - val_acc: 0.0935\n",
      "Epoch 156/250\n",
      " - 2s - loss: 3.9930 - acc: 0.1011 - val_loss: 4.0674 - val_acc: 0.0919\n",
      "Epoch 157/250\n",
      " - 2s - loss: 3.9914 - acc: 0.1025 - val_loss: 4.0570 - val_acc: 0.0934\n",
      "Epoch 158/250\n",
      " - 2s - loss: 3.9924 - acc: 0.1013 - val_loss: 4.0582 - val_acc: 0.0935\n",
      "Epoch 159/250\n",
      " - 2s - loss: 3.9930 - acc: 0.1007 - val_loss: 4.0617 - val_acc: 0.0927\n",
      "Epoch 160/250\n",
      " - 2s - loss: 3.9924 - acc: 0.1012 - val_loss: 4.0669 - val_acc: 0.0935\n",
      "Epoch 161/250\n",
      " - 2s - loss: 3.9891 - acc: 0.1017 - val_loss: 4.0647 - val_acc: 0.0922\n",
      "Epoch 162/250\n",
      " - 2s - loss: 3.9899 - acc: 0.1020 - val_loss: 4.0511 - val_acc: 0.0954\n",
      "Epoch 163/250\n",
      " - 2s - loss: 3.9929 - acc: 0.1024 - val_loss: 4.0574 - val_acc: 0.0957\n",
      "Epoch 164/250\n",
      " - 2s - loss: 3.9915 - acc: 0.1016 - val_loss: 4.0555 - val_acc: 0.0939\n",
      "Epoch 165/250\n",
      " - 2s - loss: 3.9922 - acc: 0.1004 - val_loss: 4.0549 - val_acc: 0.0937\n",
      "Epoch 166/250\n",
      " - 2s - loss: 3.9917 - acc: 0.1017 - val_loss: 4.0581 - val_acc: 0.0929\n",
      "Epoch 167/250\n",
      " - 2s - loss: 3.9939 - acc: 0.1013 - val_loss: 4.0585 - val_acc: 0.0939\n",
      "Epoch 168/250\n",
      " - 2s - loss: 3.9919 - acc: 0.1006 - val_loss: 4.0592 - val_acc: 0.0926\n",
      "Epoch 169/250\n",
      " - 2s - loss: 3.9906 - acc: 0.1015 - val_loss: 4.0613 - val_acc: 0.0941\n",
      "Epoch 170/250\n",
      " - 2s - loss: 3.9924 - acc: 0.1019 - val_loss: 4.0564 - val_acc: 0.0943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/250\n",
      " - 2s - loss: 3.9911 - acc: 0.1009 - val_loss: 4.0600 - val_acc: 0.0940\n",
      "Epoch 172/250\n",
      " - 2s - loss: 3.9931 - acc: 0.1010 - val_loss: 4.0628 - val_acc: 0.0924\n",
      "Epoch 173/250\n",
      " - 2s - loss: 3.9931 - acc: 0.1010 - val_loss: 4.0749 - val_acc: 0.0916\n",
      "Epoch 174/250\n",
      " - 2s - loss: 3.9916 - acc: 0.1018 - val_loss: 4.0490 - val_acc: 0.0957\n",
      "Epoch 175/250\n",
      " - 2s - loss: 3.9940 - acc: 0.1013 - val_loss: 4.0695 - val_acc: 0.0920\n",
      "Epoch 176/250\n",
      " - 2s - loss: 3.9921 - acc: 0.1014 - val_loss: 4.0624 - val_acc: 0.0938\n",
      "Epoch 177/250\n",
      " - 2s - loss: 3.9894 - acc: 0.1016 - val_loss: 4.0585 - val_acc: 0.0931\n",
      "Epoch 178/250\n",
      " - 2s - loss: 3.9940 - acc: 0.1011 - val_loss: 4.0557 - val_acc: 0.0947\n",
      "Epoch 179/250\n",
      " - 2s - loss: 3.9927 - acc: 0.1001 - val_loss: 4.0625 - val_acc: 0.0919\n",
      "Epoch 180/250\n",
      " - 2s - loss: 3.9934 - acc: 0.1013 - val_loss: 4.0836 - val_acc: 0.0897\n",
      "Epoch 181/250\n",
      " - 2s - loss: 3.9916 - acc: 0.1017 - val_loss: 4.0655 - val_acc: 0.0931\n",
      "Epoch 182/250\n",
      " - 2s - loss: 3.9945 - acc: 0.1012 - val_loss: 4.0558 - val_acc: 0.0960\n",
      "Epoch 183/250\n",
      " - 2s - loss: 3.9904 - acc: 0.1020 - val_loss: 4.0521 - val_acc: 0.0954\n",
      "Epoch 184/250\n",
      " - 2s - loss: 3.9929 - acc: 0.1017 - val_loss: 4.0557 - val_acc: 0.0938\n",
      "Epoch 185/250\n",
      " - 2s - loss: 3.9897 - acc: 0.1016 - val_loss: 4.0639 - val_acc: 0.0933\n",
      "Epoch 186/250\n",
      " - 2s - loss: 3.9906 - acc: 0.1016 - val_loss: 4.0536 - val_acc: 0.0949\n",
      "Epoch 187/250\n",
      " - 2s - loss: 3.9937 - acc: 0.1008 - val_loss: 4.0818 - val_acc: 0.0897\n",
      "Epoch 188/250\n",
      " - 2s - loss: 3.9928 - acc: 0.1014 - val_loss: 4.0583 - val_acc: 0.0952\n",
      "Epoch 189/250\n",
      " - 2s - loss: 3.9909 - acc: 0.1020 - val_loss: 4.0683 - val_acc: 0.0923\n",
      "Epoch 190/250\n",
      " - 2s - loss: 3.9905 - acc: 0.1022 - val_loss: 4.0663 - val_acc: 0.0926\n",
      "Epoch 191/250\n",
      " - 2s - loss: 3.9917 - acc: 0.1008 - val_loss: 4.0669 - val_acc: 0.0933\n",
      "Epoch 192/250\n",
      " - 2s - loss: 3.9894 - acc: 0.1017 - val_loss: 4.0664 - val_acc: 0.0919\n",
      "Epoch 193/250\n",
      " - 2s - loss: 3.9914 - acc: 0.1007 - val_loss: 4.0542 - val_acc: 0.0949\n",
      "Epoch 194/250\n",
      " - 2s - loss: 3.9908 - acc: 0.1013 - val_loss: 4.0570 - val_acc: 0.0944\n",
      "Epoch 195/250\n",
      " - 2s - loss: 3.9907 - acc: 0.1019 - val_loss: 4.0492 - val_acc: 0.0964\n",
      "Epoch 196/250\n",
      " - 2s - loss: 3.9916 - acc: 0.1019 - val_loss: 4.0511 - val_acc: 0.0944\n",
      "Epoch 197/250\n",
      " - 2s - loss: 3.9915 - acc: 0.1019 - val_loss: 4.0715 - val_acc: 0.0914\n",
      "Epoch 198/250\n",
      " - 2s - loss: 3.9912 - acc: 0.1020 - val_loss: 4.0763 - val_acc: 0.0911\n",
      "Epoch 199/250\n",
      " - 2s - loss: 3.9916 - acc: 0.1018 - val_loss: 4.0625 - val_acc: 0.0935\n",
      "Epoch 200/250\n",
      " - 2s - loss: 3.9922 - acc: 0.1011 - val_loss: 4.0545 - val_acc: 0.0956\n",
      "Epoch 201/250\n",
      " - 2s - loss: 3.9921 - acc: 0.1015 - val_loss: 4.0720 - val_acc: 0.0923\n",
      "Epoch 202/250\n",
      " - 2s - loss: 3.9912 - acc: 0.1013 - val_loss: 4.0576 - val_acc: 0.0946\n",
      "Epoch 203/250\n",
      " - 2s - loss: 3.9898 - acc: 0.1022 - val_loss: 4.0591 - val_acc: 0.0935\n",
      "Epoch 204/250\n",
      " - 2s - loss: 3.9886 - acc: 0.1021 - val_loss: 4.0594 - val_acc: 0.0939\n",
      "Epoch 205/250\n",
      " - 2s - loss: 3.9890 - acc: 0.1011 - val_loss: 4.0728 - val_acc: 0.0918\n",
      "Epoch 206/250\n",
      " - 2s - loss: 3.9906 - acc: 0.1019 - val_loss: 4.0495 - val_acc: 0.0954\n",
      "Epoch 207/250\n",
      " - 2s - loss: 3.9909 - acc: 0.1011 - val_loss: 4.0475 - val_acc: 0.0959\n",
      "Epoch 208/250\n",
      " - 2s - loss: 3.9911 - acc: 0.1009 - val_loss: 4.0537 - val_acc: 0.0946\n",
      "Epoch 209/250\n",
      " - 2s - loss: 3.9895 - acc: 0.1014 - val_loss: 4.0510 - val_acc: 0.0963\n",
      "Epoch 210/250\n",
      " - 2s - loss: 3.9910 - acc: 0.1019 - val_loss: 4.0515 - val_acc: 0.0947\n",
      "Epoch 211/250\n",
      " - 2s - loss: 3.9899 - acc: 0.1012 - val_loss: 4.0632 - val_acc: 0.0941\n",
      "Epoch 212/250\n",
      " - 2s - loss: 3.9915 - acc: 0.1004 - val_loss: 4.0648 - val_acc: 0.0930\n",
      "Epoch 213/250\n",
      " - 2s - loss: 3.9897 - acc: 0.1015 - val_loss: 4.0586 - val_acc: 0.0940\n",
      "Epoch 214/250\n",
      " - 2s - loss: 3.9918 - acc: 0.1018 - val_loss: 4.0587 - val_acc: 0.0931\n",
      "Epoch 215/250\n",
      " - 2s - loss: 3.9904 - acc: 0.1020 - val_loss: 4.0507 - val_acc: 0.0939\n",
      "Epoch 216/250\n",
      " - 2s - loss: 3.9894 - acc: 0.1019 - val_loss: 4.0774 - val_acc: 0.0915\n",
      "Epoch 217/250\n",
      " - 2s - loss: 3.9906 - acc: 0.1021 - val_loss: 4.0611 - val_acc: 0.0932\n",
      "Epoch 218/250\n",
      " - 2s - loss: 3.9900 - acc: 0.1017 - val_loss: 4.0627 - val_acc: 0.0936\n",
      "Epoch 219/250\n",
      " - 2s - loss: 3.9911 - acc: 0.1020 - val_loss: 4.0571 - val_acc: 0.0960\n",
      "Epoch 220/250\n",
      " - 2s - loss: 3.9900 - acc: 0.1024 - val_loss: 4.0522 - val_acc: 0.0937\n",
      "Epoch 221/250\n",
      " - 2s - loss: 3.9898 - acc: 0.1010 - val_loss: 4.0648 - val_acc: 0.0943\n",
      "Epoch 222/250\n",
      " - 2s - loss: 3.9895 - acc: 0.1032 - val_loss: 4.0548 - val_acc: 0.0942\n",
      "Epoch 223/250\n",
      " - 2s - loss: 3.9904 - acc: 0.1013 - val_loss: 4.0590 - val_acc: 0.0928\n",
      "Epoch 224/250\n",
      " - 2s - loss: 3.9889 - acc: 0.1025 - val_loss: 4.0622 - val_acc: 0.0943\n",
      "Epoch 225/250\n",
      " - 2s - loss: 3.9909 - acc: 0.1016 - val_loss: 4.0855 - val_acc: 0.0924\n",
      "Epoch 226/250\n",
      " - 2s - loss: 3.9886 - acc: 0.1012 - val_loss: 4.0725 - val_acc: 0.0913\n",
      "Epoch 227/250\n",
      " - 2s - loss: 3.9900 - acc: 0.1009 - val_loss: 4.0545 - val_acc: 0.0947\n",
      "Epoch 228/250\n",
      " - 2s - loss: 3.9899 - acc: 0.1016 - val_loss: 4.0599 - val_acc: 0.0933\n",
      "Epoch 229/250\n",
      " - 2s - loss: 3.9896 - acc: 0.1007 - val_loss: 4.0555 - val_acc: 0.0943\n",
      "Epoch 230/250\n",
      " - 2s - loss: 3.9899 - acc: 0.1018 - val_loss: 4.0657 - val_acc: 0.0932\n",
      "Epoch 231/250\n",
      " - 2s - loss: 3.9904 - acc: 0.1013 - val_loss: 4.0534 - val_acc: 0.0950\n",
      "Epoch 232/250\n",
      " - 2s - loss: 3.9918 - acc: 0.1014 - val_loss: 4.0542 - val_acc: 0.0946\n",
      "Epoch 233/250\n",
      " - 2s - loss: 3.9875 - acc: 0.1020 - val_loss: 4.0482 - val_acc: 0.0959\n",
      "Epoch 234/250\n",
      " - 2s - loss: 3.9905 - acc: 0.1018 - val_loss: 4.0482 - val_acc: 0.0945\n",
      "Epoch 235/250\n",
      " - 2s - loss: 3.9896 - acc: 0.1019 - val_loss: 4.0628 - val_acc: 0.0932\n",
      "Epoch 236/250\n",
      " - 2s - loss: 3.9891 - acc: 0.1014 - val_loss: 4.0620 - val_acc: 0.0933\n",
      "Epoch 237/250\n",
      " - 2s - loss: 3.9893 - acc: 0.1011 - val_loss: 4.0897 - val_acc: 0.0899\n",
      "Epoch 238/250\n",
      " - 2s - loss: 3.9882 - acc: 0.1011 - val_loss: 4.0564 - val_acc: 0.0949\n",
      "Epoch 239/250\n",
      " - 2s - loss: 3.9901 - acc: 0.1017 - val_loss: 4.0614 - val_acc: 0.0940\n",
      "Epoch 240/250\n",
      " - 2s - loss: 3.9883 - acc: 0.1025 - val_loss: 4.0477 - val_acc: 0.0953\n",
      "Epoch 241/250\n",
      " - 2s - loss: 3.9907 - acc: 0.1019 - val_loss: 4.0677 - val_acc: 0.0937\n",
      "Epoch 242/250\n",
      " - 2s - loss: 3.9892 - acc: 0.1012 - val_loss: 4.0626 - val_acc: 0.0930\n",
      "Epoch 243/250\n",
      " - 2s - loss: 3.9895 - acc: 0.1022 - val_loss: 4.0539 - val_acc: 0.0944\n",
      "Epoch 244/250\n",
      " - 2s - loss: 3.9896 - acc: 0.1016 - val_loss: 4.0745 - val_acc: 0.0919\n",
      "Epoch 245/250\n",
      " - 2s - loss: 3.9896 - acc: 0.1024 - val_loss: 4.0556 - val_acc: 0.0943\n",
      "Epoch 246/250\n",
      " - 2s - loss: 3.9895 - acc: 0.1011 - val_loss: 4.0744 - val_acc: 0.0912\n",
      "Epoch 247/250\n",
      " - 2s - loss: 3.9886 - acc: 0.1016 - val_loss: 4.0702 - val_acc: 0.0910\n",
      "Epoch 248/250\n",
      " - 2s - loss: 3.9889 - acc: 0.1018 - val_loss: 4.0562 - val_acc: 0.0928\n",
      "Epoch 249/250\n",
      " - 2s - loss: 3.9903 - acc: 0.1015 - val_loss: 4.0591 - val_acc: 0.0940\n",
      "Epoch 250/250\n",
      " - 2s - loss: 3.9884 - acc: 0.1024 - val_loss: 4.0574 - val_acc: 0.0928\n",
      "Mini-Train:   3 Test Accuracy: 9.28% Learning Rate: 0.0008333\n",
      "Train on 136770 samples, validate on 15266 samples\n",
      "Epoch 1/250\n",
      " - 2s - loss: 3.9884 - acc: 0.1018 - val_loss: 4.0501 - val_acc: 0.0947\n",
      "Epoch 2/250\n",
      " - 2s - loss: 3.9865 - acc: 0.1010 - val_loss: 4.0553 - val_acc: 0.0938\n",
      "Epoch 3/250\n",
      " - 2s - loss: 3.9892 - acc: 0.1015 - val_loss: 4.0554 - val_acc: 0.0947\n",
      "Epoch 4/250\n",
      " - 2s - loss: 3.9888 - acc: 0.1022 - val_loss: 4.0537 - val_acc: 0.0938\n",
      "Epoch 5/250\n",
      " - 2s - loss: 3.9877 - acc: 0.1015 - val_loss: 4.0768 - val_acc: 0.0902\n",
      "Epoch 6/250\n",
      " - 2s - loss: 3.9870 - acc: 0.1019 - val_loss: 4.0512 - val_acc: 0.0933\n",
      "Epoch 7/250\n",
      " - 2s - loss: 3.9894 - acc: 0.1008 - val_loss: 4.0524 - val_acc: 0.0941\n",
      "Epoch 8/250\n",
      " - 2s - loss: 3.9874 - acc: 0.1009 - val_loss: 4.0526 - val_acc: 0.0939\n",
      "Epoch 9/250\n",
      " - 2s - loss: 3.9880 - acc: 0.1014 - val_loss: 4.0664 - val_acc: 0.0937\n",
      "Epoch 10/250\n",
      " - 2s - loss: 3.9861 - acc: 0.1024 - val_loss: 4.0559 - val_acc: 0.0956\n",
      "Epoch 11/250\n",
      " - 2s - loss: 3.9864 - acc: 0.1026 - val_loss: 4.0538 - val_acc: 0.0947\n",
      "Epoch 12/250\n",
      " - 2s - loss: 3.9877 - acc: 0.1026 - val_loss: 4.0544 - val_acc: 0.0947\n",
      "Epoch 13/250\n",
      " - 2s - loss: 3.9894 - acc: 0.1015 - val_loss: 4.0673 - val_acc: 0.0950\n",
      "Epoch 14/250\n",
      " - 2s - loss: 3.9879 - acc: 0.1014 - val_loss: 4.0548 - val_acc: 0.0951\n",
      "Epoch 15/250\n",
      " - 2s - loss: 3.9879 - acc: 0.1016 - val_loss: 4.0606 - val_acc: 0.0936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/250\n",
      " - 2s - loss: 3.9880 - acc: 0.1026 - val_loss: 4.0517 - val_acc: 0.0947\n",
      "Epoch 17/250\n",
      " - 2s - loss: 3.9876 - acc: 0.1015 - val_loss: 4.0550 - val_acc: 0.0943\n",
      "Epoch 18/250\n",
      " - 2s - loss: 3.9865 - acc: 0.1008 - val_loss: 4.0621 - val_acc: 0.0942\n",
      "Epoch 19/250\n",
      " - 2s - loss: 3.9875 - acc: 0.1017 - val_loss: 4.0596 - val_acc: 0.0942\n",
      "Epoch 20/250\n",
      " - 2s - loss: 3.9891 - acc: 0.1027 - val_loss: 4.0523 - val_acc: 0.0944\n",
      "Epoch 21/250\n",
      " - 2s - loss: 3.9874 - acc: 0.1021 - val_loss: 4.0556 - val_acc: 0.0943\n",
      "Epoch 22/250\n",
      " - 2s - loss: 3.9881 - acc: 0.1013 - val_loss: 4.0543 - val_acc: 0.0943\n",
      "Epoch 23/250\n",
      " - 2s - loss: 3.9857 - acc: 0.1023 - val_loss: 4.0617 - val_acc: 0.0935\n",
      "Epoch 24/250\n",
      " - 2s - loss: 3.9860 - acc: 0.1022 - val_loss: 4.0607 - val_acc: 0.0955\n",
      "Epoch 25/250\n",
      " - 2s - loss: 3.9893 - acc: 0.1026 - val_loss: 4.0574 - val_acc: 0.0952\n",
      "Epoch 26/250\n",
      " - 2s - loss: 3.9872 - acc: 0.1022 - val_loss: 4.0575 - val_acc: 0.0943\n",
      "Epoch 27/250\n",
      " - 2s - loss: 3.9893 - acc: 0.1023 - val_loss: 4.0606 - val_acc: 0.0940\n",
      "Epoch 28/250\n",
      " - 2s - loss: 3.9871 - acc: 0.1019 - val_loss: 4.0591 - val_acc: 0.0938\n",
      "Epoch 29/250\n",
      " - 2s - loss: 3.9883 - acc: 0.1014 - val_loss: 4.0468 - val_acc: 0.0956\n",
      "Epoch 30/250\n",
      " - 2s - loss: 3.9881 - acc: 0.1019 - val_loss: 4.0591 - val_acc: 0.0931\n",
      "Epoch 31/250\n",
      " - 2s - loss: 3.9863 - acc: 0.1020 - val_loss: 4.0480 - val_acc: 0.0954\n",
      "Epoch 32/250\n",
      " - 2s - loss: 3.9890 - acc: 0.1028 - val_loss: 4.0527 - val_acc: 0.0944\n",
      "Epoch 33/250\n",
      " - 2s - loss: 3.9869 - acc: 0.1009 - val_loss: 4.0588 - val_acc: 0.0935\n",
      "Epoch 34/250\n",
      " - 2s - loss: 3.9892 - acc: 0.1005 - val_loss: 4.0653 - val_acc: 0.0921\n",
      "Epoch 35/250\n",
      " - 2s - loss: 3.9880 - acc: 0.1020 - val_loss: 4.0607 - val_acc: 0.0954\n",
      "Epoch 36/250\n",
      " - 2s - loss: 3.9874 - acc: 0.1021 - val_loss: 4.0547 - val_acc: 0.0949\n",
      "Epoch 37/250\n",
      " - 2s - loss: 3.9874 - acc: 0.1018 - val_loss: 4.0601 - val_acc: 0.0948\n",
      "Epoch 38/250\n",
      " - 2s - loss: 3.9874 - acc: 0.1024 - val_loss: 4.0665 - val_acc: 0.0934\n",
      "Epoch 39/250\n",
      " - 2s - loss: 3.9883 - acc: 0.1027 - val_loss: 4.0488 - val_acc: 0.0953\n",
      "Epoch 40/250\n",
      " - 2s - loss: 3.9867 - acc: 0.1017 - val_loss: 4.0530 - val_acc: 0.0956\n",
      "Epoch 41/250\n",
      " - 2s - loss: 3.9881 - acc: 0.1020 - val_loss: 4.0515 - val_acc: 0.0952\n",
      "Epoch 42/250\n",
      " - 2s - loss: 3.9866 - acc: 0.1018 - val_loss: 4.0670 - val_acc: 0.0927\n",
      "Epoch 43/250\n",
      " - 2s - loss: 3.9889 - acc: 0.1019 - val_loss: 4.0598 - val_acc: 0.0945\n",
      "Epoch 44/250\n",
      " - 2s - loss: 3.9868 - acc: 0.1021 - val_loss: 4.0502 - val_acc: 0.0949\n",
      "Epoch 45/250\n",
      " - 2s - loss: 3.9888 - acc: 0.1027 - val_loss: 4.0523 - val_acc: 0.0945\n",
      "Epoch 46/250\n",
      " - 2s - loss: 3.9883 - acc: 0.1024 - val_loss: 4.0508 - val_acc: 0.0956\n",
      "Epoch 47/250\n",
      " - 2s - loss: 3.9872 - acc: 0.1014 - val_loss: 4.0563 - val_acc: 0.0932\n",
      "Epoch 48/250\n",
      " - 2s - loss: 3.9895 - acc: 0.1016 - val_loss: 4.0686 - val_acc: 0.0937\n",
      "Epoch 49/250\n",
      " - 2s - loss: 3.9881 - acc: 0.1022 - val_loss: 4.0692 - val_acc: 0.0915\n",
      "Epoch 50/250\n",
      " - 2s - loss: 3.9877 - acc: 0.1012 - val_loss: 4.0511 - val_acc: 0.0956\n",
      "Epoch 51/250\n",
      " - 2s - loss: 3.9880 - acc: 0.1018 - val_loss: 4.0471 - val_acc: 0.0956\n",
      "Epoch 52/250\n",
      " - 2s - loss: 3.9874 - acc: 0.1014 - val_loss: 4.0532 - val_acc: 0.0950\n",
      "Epoch 53/250\n",
      " - 2s - loss: 3.9872 - acc: 0.1014 - val_loss: 4.0536 - val_acc: 0.0954\n",
      "Epoch 54/250\n",
      " - 2s - loss: 3.9866 - acc: 0.1019 - val_loss: 4.0551 - val_acc: 0.0952\n",
      "Epoch 55/250\n",
      " - 2s - loss: 3.9896 - acc: 0.1016 - val_loss: 4.0555 - val_acc: 0.0947\n",
      "Epoch 56/250\n",
      " - 2s - loss: 3.9867 - acc: 0.1014 - val_loss: 4.0602 - val_acc: 0.0937\n",
      "Epoch 57/250\n",
      " - 2s - loss: 3.9880 - acc: 0.1025 - val_loss: 4.0604 - val_acc: 0.0941\n",
      "Epoch 58/250\n",
      " - 2s - loss: 3.9875 - acc: 0.1022 - val_loss: 4.0567 - val_acc: 0.0951\n",
      "Epoch 59/250\n",
      " - 2s - loss: 3.9867 - acc: 0.1024 - val_loss: 4.0712 - val_acc: 0.0918\n",
      "Epoch 60/250\n",
      " - 2s - loss: 3.9866 - acc: 0.1019 - val_loss: 4.0504 - val_acc: 0.0962\n",
      "Epoch 61/250\n",
      " - 2s - loss: 3.9866 - acc: 0.1025 - val_loss: 4.0558 - val_acc: 0.0943\n",
      "Epoch 62/250\n",
      " - 2s - loss: 3.9871 - acc: 0.1022 - val_loss: 4.0507 - val_acc: 0.0951\n",
      "Epoch 63/250\n",
      " - 2s - loss: 3.9848 - acc: 0.1022 - val_loss: 4.0552 - val_acc: 0.0955\n",
      "Epoch 64/250\n",
      " - 2s - loss: 3.9869 - acc: 0.1013 - val_loss: 4.0519 - val_acc: 0.0948\n",
      "Epoch 65/250\n",
      " - 2s - loss: 3.9875 - acc: 0.1023 - val_loss: 4.0604 - val_acc: 0.0922\n",
      "Epoch 66/250\n",
      " - 2s - loss: 3.9854 - acc: 0.1015 - val_loss: 4.0583 - val_acc: 0.0943\n",
      "Epoch 67/250\n",
      " - 2s - loss: 3.9880 - acc: 0.1019 - val_loss: 4.0498 - val_acc: 0.0947\n",
      "Epoch 68/250\n",
      " - 2s - loss: 3.9882 - acc: 0.1011 - val_loss: 4.0561 - val_acc: 0.0947\n",
      "Epoch 69/250\n",
      " - 2s - loss: 3.9887 - acc: 0.1019 - val_loss: 4.0693 - val_acc: 0.0926\n",
      "Epoch 70/250\n",
      " - 2s - loss: 3.9874 - acc: 0.1021 - val_loss: 4.0646 - val_acc: 0.0934\n",
      "Epoch 71/250\n",
      " - 2s - loss: 3.9856 - acc: 0.1025 - val_loss: 4.0514 - val_acc: 0.0952\n",
      "Epoch 72/250\n",
      " - 2s - loss: 3.9865 - acc: 0.1020 - val_loss: 4.0602 - val_acc: 0.0939\n",
      "Epoch 73/250\n",
      " - 2s - loss: 3.9863 - acc: 0.1016 - val_loss: 4.0606 - val_acc: 0.0941\n",
      "Epoch 74/250\n",
      " - 2s - loss: 3.9865 - acc: 0.1022 - val_loss: 4.0519 - val_acc: 0.0958\n",
      "Epoch 75/250\n",
      " - 2s - loss: 3.9858 - acc: 0.1013 - val_loss: 4.0579 - val_acc: 0.0949\n",
      "Epoch 76/250\n",
      " - 2s - loss: 3.9856 - acc: 0.1021 - val_loss: 4.0537 - val_acc: 0.0946\n",
      "Epoch 77/250\n",
      " - 2s - loss: 3.9876 - acc: 0.1014 - val_loss: 4.0555 - val_acc: 0.0950\n",
      "Epoch 78/250\n",
      " - 2s - loss: 3.9862 - acc: 0.1027 - val_loss: 4.0634 - val_acc: 0.0941\n",
      "Epoch 79/250\n",
      " - 2s - loss: 3.9857 - acc: 0.1026 - val_loss: 4.0539 - val_acc: 0.0956\n",
      "Epoch 80/250\n",
      " - 2s - loss: 3.9875 - acc: 0.1023 - val_loss: 4.0491 - val_acc: 0.0956\n",
      "Epoch 81/250\n",
      " - 2s - loss: 3.9888 - acc: 0.1012 - val_loss: 4.0450 - val_acc: 0.0958\n",
      "Epoch 82/250\n",
      " - 2s - loss: 3.9877 - acc: 0.1018 - val_loss: 4.0508 - val_acc: 0.0950\n",
      "Epoch 83/250\n",
      " - 2s - loss: 3.9897 - acc: 0.1023 - val_loss: 4.0575 - val_acc: 0.0934\n",
      "Epoch 84/250\n",
      " - 2s - loss: 3.9858 - acc: 0.1025 - val_loss: 4.0535 - val_acc: 0.0955\n",
      "Epoch 85/250\n",
      " - 2s - loss: 3.9874 - acc: 0.1013 - val_loss: 4.0533 - val_acc: 0.0952\n",
      "Epoch 86/250\n",
      " - 2s - loss: 3.9881 - acc: 0.1011 - val_loss: 4.0662 - val_acc: 0.0920\n",
      "Epoch 87/250\n",
      " - 2s - loss: 3.9875 - acc: 0.1026 - val_loss: 4.0571 - val_acc: 0.0936\n",
      "Epoch 88/250\n",
      " - 2s - loss: 3.9885 - acc: 0.1021 - val_loss: 4.0576 - val_acc: 0.0931\n",
      "Epoch 89/250\n",
      " - 2s - loss: 3.9863 - acc: 0.1025 - val_loss: 4.0626 - val_acc: 0.0938\n",
      "Epoch 90/250\n",
      " - 2s - loss: 3.9878 - acc: 0.1025 - val_loss: 4.0562 - val_acc: 0.0947\n",
      "Epoch 91/250\n",
      " - 2s - loss: 3.9863 - acc: 0.1023 - val_loss: 4.0616 - val_acc: 0.0940\n",
      "Epoch 92/250\n",
      " - 2s - loss: 3.9877 - acc: 0.1013 - val_loss: 4.0536 - val_acc: 0.0945\n",
      "Epoch 93/250\n",
      " - 2s - loss: 3.9876 - acc: 0.1022 - val_loss: 4.0494 - val_acc: 0.0947\n",
      "Epoch 94/250\n",
      " - 2s - loss: 3.9869 - acc: 0.1018 - val_loss: 4.0625 - val_acc: 0.0928\n",
      "Epoch 95/250\n",
      " - 2s - loss: 3.9864 - acc: 0.1020 - val_loss: 4.0531 - val_acc: 0.0945\n",
      "Epoch 96/250\n",
      " - 2s - loss: 3.9865 - acc: 0.1020 - val_loss: 4.0554 - val_acc: 0.0945\n",
      "Epoch 97/250\n",
      " - 2s - loss: 3.9868 - acc: 0.1021 - val_loss: 4.0464 - val_acc: 0.0958\n",
      "Epoch 98/250\n",
      " - 2s - loss: 3.9893 - acc: 0.1018 - val_loss: 4.0528 - val_acc: 0.0953\n",
      "Epoch 99/250\n",
      " - 2s - loss: 3.9868 - acc: 0.1011 - val_loss: 4.0501 - val_acc: 0.0948\n",
      "Epoch 100/250\n",
      " - 2s - loss: 3.9871 - acc: 0.1021 - val_loss: 4.0560 - val_acc: 0.0960\n",
      "Epoch 101/250\n",
      " - 2s - loss: 3.9879 - acc: 0.1028 - val_loss: 4.0477 - val_acc: 0.0960\n",
      "Epoch 102/250\n",
      " - 2s - loss: 3.9864 - acc: 0.1019 - val_loss: 4.0558 - val_acc: 0.0950\n",
      "Epoch 103/250\n",
      " - 2s - loss: 3.9849 - acc: 0.1029 - val_loss: 4.0486 - val_acc: 0.0953\n",
      "Epoch 104/250\n",
      " - 2s - loss: 3.9863 - acc: 0.1029 - val_loss: 4.0521 - val_acc: 0.0944\n",
      "Epoch 105/250\n",
      " - 2s - loss: 3.9857 - acc: 0.1022 - val_loss: 4.0506 - val_acc: 0.0944\n",
      "Epoch 106/250\n",
      " - 2s - loss: 3.9828 - acc: 0.1023 - val_loss: 4.0472 - val_acc: 0.0945\n",
      "Epoch 107/250\n",
      " - 2s - loss: 3.9852 - acc: 0.1010 - val_loss: 4.0511 - val_acc: 0.0942\n",
      "Epoch 108/250\n",
      " - 2s - loss: 3.9865 - acc: 0.1014 - val_loss: 4.0532 - val_acc: 0.0941\n",
      "Epoch 109/250\n",
      " - 2s - loss: 3.9863 - acc: 0.1020 - val_loss: 4.0493 - val_acc: 0.0933\n",
      "Epoch 110/250\n",
      " - 2s - loss: 3.9847 - acc: 0.1011 - val_loss: 4.0495 - val_acc: 0.0950\n",
      "Epoch 111/250\n",
      " - 2s - loss: 3.9861 - acc: 0.1021 - val_loss: 4.0533 - val_acc: 0.0946\n",
      "Epoch 112/250\n",
      " - 2s - loss: 3.9858 - acc: 0.1021 - val_loss: 4.0553 - val_acc: 0.0941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/250\n",
      " - 2s - loss: 3.9860 - acc: 0.1025 - val_loss: 4.0546 - val_acc: 0.0943\n",
      "Epoch 114/250\n",
      " - 2s - loss: 3.9850 - acc: 0.1019 - val_loss: 4.0469 - val_acc: 0.0956\n",
      "Epoch 115/250\n",
      " - 2s - loss: 3.9836 - acc: 0.1023 - val_loss: 4.0542 - val_acc: 0.0943\n",
      "Epoch 116/250\n",
      " - 2s - loss: 3.9872 - acc: 0.1016 - val_loss: 4.0503 - val_acc: 0.0949\n",
      "Epoch 117/250\n",
      " - 2s - loss: 3.9838 - acc: 0.1023 - val_loss: 4.0530 - val_acc: 0.0943\n",
      "Epoch 118/250\n",
      " - 2s - loss: 3.9869 - acc: 0.1028 - val_loss: 4.0530 - val_acc: 0.0945\n",
      "Epoch 119/250\n",
      " - 2s - loss: 3.9848 - acc: 0.1027 - val_loss: 4.0516 - val_acc: 0.0944\n",
      "Epoch 120/250\n",
      " - 2s - loss: 3.9841 - acc: 0.1022 - val_loss: 4.0464 - val_acc: 0.0966\n",
      "Epoch 121/250\n",
      " - 2s - loss: 3.9846 - acc: 0.1036 - val_loss: 4.0716 - val_acc: 0.0912\n",
      "Epoch 122/250\n",
      " - 2s - loss: 3.9858 - acc: 0.1021 - val_loss: 4.0554 - val_acc: 0.0948\n",
      "Epoch 123/250\n",
      " - 2s - loss: 3.9879 - acc: 0.1021 - val_loss: 4.0480 - val_acc: 0.0958\n",
      "Epoch 124/250\n",
      " - 2s - loss: 3.9865 - acc: 0.1024 - val_loss: 4.0523 - val_acc: 0.0950\n",
      "Epoch 125/250\n",
      " - 2s - loss: 3.9855 - acc: 0.1037 - val_loss: 4.0482 - val_acc: 0.0952\n",
      "Epoch 126/250\n",
      " - 2s - loss: 3.9856 - acc: 0.1014 - val_loss: 4.0523 - val_acc: 0.0962\n",
      "Epoch 127/250\n",
      " - 2s - loss: 3.9852 - acc: 0.1016 - val_loss: 4.0596 - val_acc: 0.0943\n",
      "Epoch 128/250\n",
      " - 2s - loss: 3.9867 - acc: 0.1014 - val_loss: 4.0557 - val_acc: 0.0937\n",
      "Epoch 129/250\n",
      " - 2s - loss: 3.9854 - acc: 0.1026 - val_loss: 4.0534 - val_acc: 0.0966\n",
      "Epoch 130/250\n",
      " - 2s - loss: 3.9854 - acc: 0.1018 - val_loss: 4.0568 - val_acc: 0.0925\n",
      "Epoch 131/250\n",
      " - 2s - loss: 3.9859 - acc: 0.1016 - val_loss: 4.0557 - val_acc: 0.0938\n",
      "Epoch 132/250\n",
      " - 2s - loss: 3.9856 - acc: 0.1007 - val_loss: 4.0492 - val_acc: 0.0954\n",
      "Epoch 133/250\n",
      " - 2s - loss: 3.9856 - acc: 0.1024 - val_loss: 4.0517 - val_acc: 0.0952\n",
      "Epoch 134/250\n",
      " - 2s - loss: 3.9872 - acc: 0.1013 - val_loss: 4.0554 - val_acc: 0.0956\n",
      "Epoch 135/250\n",
      " - 2s - loss: 3.9842 - acc: 0.1021 - val_loss: 4.0490 - val_acc: 0.0961\n",
      "Epoch 136/250\n",
      " - 2s - loss: 3.9855 - acc: 0.1024 - val_loss: 4.0549 - val_acc: 0.0947\n",
      "Epoch 137/250\n",
      " - 2s - loss: 3.9852 - acc: 0.1018 - val_loss: 4.0538 - val_acc: 0.0954\n",
      "Epoch 138/250\n",
      " - 2s - loss: 3.9855 - acc: 0.1016 - val_loss: 4.0621 - val_acc: 0.0940\n",
      "Epoch 139/250\n",
      " - 2s - loss: 3.9851 - acc: 0.1028 - val_loss: 4.0584 - val_acc: 0.0950\n",
      "Epoch 140/250\n",
      " - 2s - loss: 3.9862 - acc: 0.1011 - val_loss: 4.0483 - val_acc: 0.0962\n",
      "Epoch 141/250\n",
      " - 2s - loss: 3.9852 - acc: 0.1018 - val_loss: 4.0503 - val_acc: 0.0945\n",
      "Epoch 142/250\n",
      " - 2s - loss: 3.9844 - acc: 0.1021 - val_loss: 4.0553 - val_acc: 0.0946\n",
      "Epoch 143/250\n",
      " - 2s - loss: 3.9861 - acc: 0.1021 - val_loss: 4.0561 - val_acc: 0.0948\n",
      "Epoch 144/250\n",
      " - 2s - loss: 3.9868 - acc: 0.1015 - val_loss: 4.0470 - val_acc: 0.0970\n",
      "Epoch 145/250\n",
      " - 2s - loss: 3.9866 - acc: 0.1018 - val_loss: 4.0533 - val_acc: 0.0946\n",
      "Epoch 146/250\n",
      " - 2s - loss: 3.9839 - acc: 0.1027 - val_loss: 4.0524 - val_acc: 0.0947\n",
      "Epoch 147/250\n",
      " - 2s - loss: 3.9846 - acc: 0.1021 - val_loss: 4.0515 - val_acc: 0.0949\n",
      "Epoch 148/250\n",
      " - 2s - loss: 3.9829 - acc: 0.1019 - val_loss: 4.0558 - val_acc: 0.0950\n",
      "Epoch 149/250\n",
      " - 2s - loss: 3.9848 - acc: 0.1032 - val_loss: 4.0502 - val_acc: 0.0950\n",
      "Epoch 150/250\n",
      " - 2s - loss: 3.9839 - acc: 0.1024 - val_loss: 4.0412 - val_acc: 0.0962\n",
      "Epoch 151/250\n",
      " - 2s - loss: 3.9854 - acc: 0.1026 - val_loss: 4.0472 - val_acc: 0.0956\n",
      "Epoch 152/250\n",
      " - 2s - loss: 3.9854 - acc: 0.1024 - val_loss: 4.0617 - val_acc: 0.0945\n",
      "Epoch 153/250\n",
      " - 2s - loss: 3.9849 - acc: 0.1029 - val_loss: 4.0529 - val_acc: 0.0934\n",
      "Epoch 154/250\n",
      " - 2s - loss: 3.9846 - acc: 0.1028 - val_loss: 4.0470 - val_acc: 0.0960\n",
      "Epoch 155/250\n",
      " - 2s - loss: 3.9865 - acc: 0.1019 - val_loss: 4.0563 - val_acc: 0.0950\n",
      "Epoch 156/250\n",
      " - 2s - loss: 3.9849 - acc: 0.1024 - val_loss: 4.0524 - val_acc: 0.0943\n",
      "Epoch 157/250\n",
      " - 2s - loss: 3.9850 - acc: 0.1016 - val_loss: 4.0517 - val_acc: 0.0950\n",
      "Epoch 158/250\n",
      " - 2s - loss: 3.9855 - acc: 0.1025 - val_loss: 4.0507 - val_acc: 0.0953\n",
      "Epoch 159/250\n",
      " - 2s - loss: 3.9858 - acc: 0.1018 - val_loss: 4.0486 - val_acc: 0.0967\n",
      "Epoch 160/250\n",
      " - 2s - loss: 3.9854 - acc: 0.1017 - val_loss: 4.0581 - val_acc: 0.0943\n",
      "Epoch 161/250\n",
      " - 2s - loss: 3.9843 - acc: 0.1020 - val_loss: 4.0663 - val_acc: 0.0925\n",
      "Epoch 162/250\n",
      " - 2s - loss: 3.9854 - acc: 0.1025 - val_loss: 4.0469 - val_acc: 0.0964\n",
      "Epoch 163/250\n",
      " - 2s - loss: 3.9847 - acc: 0.1022 - val_loss: 4.0488 - val_acc: 0.0963\n",
      "Epoch 164/250\n",
      " - 2s - loss: 3.9858 - acc: 0.1020 - val_loss: 4.0576 - val_acc: 0.0950\n",
      "Epoch 165/250\n",
      " - 2s - loss: 3.9836 - acc: 0.1023 - val_loss: 4.0571 - val_acc: 0.0940\n",
      "Epoch 166/250\n",
      " - 2s - loss: 3.9849 - acc: 0.1024 - val_loss: 4.0488 - val_acc: 0.0950\n",
      "Epoch 167/250\n",
      " - 2s - loss: 3.9863 - acc: 0.1023 - val_loss: 4.0615 - val_acc: 0.0934\n",
      "Epoch 168/250\n",
      " - 2s - loss: 3.9841 - acc: 0.1026 - val_loss: 4.0496 - val_acc: 0.0952\n",
      "Epoch 169/250\n",
      " - 2s - loss: 3.9836 - acc: 0.1024 - val_loss: 4.0597 - val_acc: 0.0950\n",
      "Epoch 170/250\n",
      " - 2s - loss: 3.9819 - acc: 0.1033 - val_loss: 4.0575 - val_acc: 0.0939\n",
      "Epoch 171/250\n",
      " - 2s - loss: 3.9848 - acc: 0.1027 - val_loss: 4.0481 - val_acc: 0.0957\n",
      "Epoch 172/250\n",
      " - 2s - loss: 3.9870 - acc: 0.1020 - val_loss: 4.0537 - val_acc: 0.0948\n",
      "Epoch 173/250\n",
      " - 2s - loss: 3.9861 - acc: 0.1019 - val_loss: 4.0526 - val_acc: 0.0951\n",
      "Epoch 174/250\n",
      " - 2s - loss: 3.9846 - acc: 0.1013 - val_loss: 4.0535 - val_acc: 0.0940\n",
      "Epoch 175/250\n",
      " - 2s - loss: 3.9858 - acc: 0.1015 - val_loss: 4.0499 - val_acc: 0.0944\n",
      "Epoch 176/250\n",
      " - 2s - loss: 3.9850 - acc: 0.1025 - val_loss: 4.0518 - val_acc: 0.0947\n",
      "Epoch 177/250\n",
      " - 2s - loss: 3.9882 - acc: 0.1018 - val_loss: 4.0511 - val_acc: 0.0949\n",
      "Epoch 178/250\n",
      " - 2s - loss: 3.9833 - acc: 0.1024 - val_loss: 4.0514 - val_acc: 0.0962\n",
      "Epoch 179/250\n",
      " - 2s - loss: 3.9849 - acc: 0.1020 - val_loss: 4.0513 - val_acc: 0.0943\n",
      "Epoch 180/250\n",
      " - 2s - loss: 3.9858 - acc: 0.1021 - val_loss: 4.0472 - val_acc: 0.0958\n",
      "Epoch 181/250\n",
      " - 2s - loss: 3.9855 - acc: 0.1008 - val_loss: 4.0487 - val_acc: 0.0939\n",
      "Epoch 182/250\n",
      " - 2s - loss: 3.9827 - acc: 0.1029 - val_loss: 4.0461 - val_acc: 0.0971\n",
      "Epoch 183/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1018 - val_loss: 4.0487 - val_acc: 0.0953\n",
      "Epoch 184/250\n",
      " - 2s - loss: 3.9869 - acc: 0.1024 - val_loss: 4.0630 - val_acc: 0.0940\n",
      "Epoch 185/250\n",
      " - 2s - loss: 3.9849 - acc: 0.1027 - val_loss: 4.0552 - val_acc: 0.0948\n",
      "Epoch 186/250\n",
      " - 2s - loss: 3.9832 - acc: 0.1028 - val_loss: 4.0475 - val_acc: 0.0964\n",
      "Epoch 187/250\n",
      " - 2s - loss: 3.9830 - acc: 0.1033 - val_loss: 4.0510 - val_acc: 0.0945\n",
      "Epoch 188/250\n",
      " - 2s - loss: 3.9847 - acc: 0.1025 - val_loss: 4.0505 - val_acc: 0.0956\n",
      "Epoch 189/250\n",
      " - 2s - loss: 3.9849 - acc: 0.1024 - val_loss: 4.0538 - val_acc: 0.0948\n",
      "Epoch 190/250\n",
      " - 2s - loss: 3.9839 - acc: 0.1025 - val_loss: 4.0512 - val_acc: 0.0960\n",
      "Epoch 191/250\n",
      " - 2s - loss: 3.9832 - acc: 0.1030 - val_loss: 4.0552 - val_acc: 0.0952\n",
      "Epoch 192/250\n",
      " - 2s - loss: 3.9842 - acc: 0.1020 - val_loss: 4.0498 - val_acc: 0.0954\n",
      "Epoch 193/250\n",
      " - 2s - loss: 3.9848 - acc: 0.1024 - val_loss: 4.0503 - val_acc: 0.0949\n",
      "Epoch 194/250\n",
      " - 2s - loss: 3.9850 - acc: 0.1022 - val_loss: 4.0557 - val_acc: 0.0947\n",
      "Epoch 195/250\n",
      " - 2s - loss: 3.9831 - acc: 0.1026 - val_loss: 4.0529 - val_acc: 0.0954\n",
      "Epoch 196/250\n",
      " - 2s - loss: 3.9845 - acc: 0.1029 - val_loss: 4.0548 - val_acc: 0.0950\n",
      "Epoch 197/250\n",
      " - 2s - loss: 3.9831 - acc: 0.1028 - val_loss: 4.0567 - val_acc: 0.0951\n",
      "Epoch 198/250\n",
      " - 2s - loss: 3.9857 - acc: 0.1022 - val_loss: 4.0570 - val_acc: 0.0941\n",
      "Epoch 199/250\n",
      " - 2s - loss: 3.9842 - acc: 0.1023 - val_loss: 4.0568 - val_acc: 0.0933\n",
      "Epoch 200/250\n",
      " - 2s - loss: 3.9846 - acc: 0.1025 - val_loss: 4.0494 - val_acc: 0.0952\n",
      "Epoch 201/250\n",
      " - 2s - loss: 3.9825 - acc: 0.1022 - val_loss: 4.0473 - val_acc: 0.0946\n",
      "Epoch 202/250\n",
      " - 2s - loss: 3.9858 - acc: 0.1014 - val_loss: 4.0532 - val_acc: 0.0936\n",
      "Epoch 203/250\n",
      " - 2s - loss: 3.9841 - acc: 0.1024 - val_loss: 4.0572 - val_acc: 0.0937\n",
      "Epoch 204/250\n",
      " - 2s - loss: 3.9828 - acc: 0.1024 - val_loss: 4.0555 - val_acc: 0.0948\n",
      "Epoch 205/250\n",
      " - 2s - loss: 3.9855 - acc: 0.1016 - val_loss: 4.0560 - val_acc: 0.0946\n",
      "Epoch 206/250\n",
      " - 2s - loss: 3.9845 - acc: 0.1019 - val_loss: 4.0568 - val_acc: 0.0947\n",
      "Epoch 207/250\n",
      " - 2s - loss: 3.9851 - acc: 0.1031 - val_loss: 4.0683 - val_acc: 0.0923\n",
      "Epoch 208/250\n",
      " - 2s - loss: 3.9842 - acc: 0.1024 - val_loss: 4.0499 - val_acc: 0.0956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/250\n",
      " - 2s - loss: 3.9872 - acc: 0.1012 - val_loss: 4.0489 - val_acc: 0.0945\n",
      "Epoch 210/250\n",
      " - 2s - loss: 3.9863 - acc: 0.1017 - val_loss: 4.0500 - val_acc: 0.0952\n",
      "Epoch 211/250\n",
      " - 2s - loss: 3.9859 - acc: 0.1020 - val_loss: 4.0533 - val_acc: 0.0945\n",
      "Epoch 212/250\n",
      " - 2s - loss: 3.9832 - acc: 0.1020 - val_loss: 4.0531 - val_acc: 0.0946\n",
      "Epoch 213/250\n",
      " - 2s - loss: 3.9872 - acc: 0.1024 - val_loss: 4.0572 - val_acc: 0.0950\n",
      "Epoch 214/250\n",
      " - 2s - loss: 3.9844 - acc: 0.1018 - val_loss: 4.0542 - val_acc: 0.0949\n",
      "Epoch 215/250\n",
      " - 2s - loss: 3.9842 - acc: 0.1028 - val_loss: 4.0544 - val_acc: 0.0962\n",
      "Epoch 216/250\n",
      " - 2s - loss: 3.9844 - acc: 0.1020 - val_loss: 4.0490 - val_acc: 0.0957\n",
      "Epoch 217/250\n",
      " - 2s - loss: 3.9843 - acc: 0.1022 - val_loss: 4.0564 - val_acc: 0.0943\n",
      "Epoch 218/250\n",
      " - 2s - loss: 3.9834 - acc: 0.1031 - val_loss: 4.0530 - val_acc: 0.0947\n",
      "Epoch 219/250\n",
      " - 2s - loss: 3.9837 - acc: 0.1030 - val_loss: 4.0510 - val_acc: 0.0947\n",
      "Epoch 220/250\n",
      " - 2s - loss: 3.9835 - acc: 0.1028 - val_loss: 4.0564 - val_acc: 0.0945\n",
      "Epoch 221/250\n",
      " - 2s - loss: 3.9856 - acc: 0.1020 - val_loss: 4.0566 - val_acc: 0.0941\n",
      "Epoch 222/250\n",
      " - 2s - loss: 3.9852 - acc: 0.1018 - val_loss: 4.0596 - val_acc: 0.0936\n",
      "Epoch 223/250\n",
      " - 2s - loss: 3.9832 - acc: 0.1027 - val_loss: 4.0599 - val_acc: 0.0947\n",
      "Epoch 224/250\n",
      " - 2s - loss: 3.9852 - acc: 0.1030 - val_loss: 4.0530 - val_acc: 0.0946\n",
      "Epoch 225/250\n",
      " - 2s - loss: 3.9857 - acc: 0.1017 - val_loss: 4.0492 - val_acc: 0.0956\n",
      "Epoch 226/250\n",
      " - 2s - loss: 3.9856 - acc: 0.1023 - val_loss: 4.0542 - val_acc: 0.0942\n",
      "Epoch 227/250\n",
      " - 2s - loss: 3.9832 - acc: 0.1016 - val_loss: 4.0516 - val_acc: 0.0954\n",
      "Epoch 228/250\n",
      " - 2s - loss: 3.9866 - acc: 0.1015 - val_loss: 4.0518 - val_acc: 0.0953\n",
      "Epoch 229/250\n",
      " - 2s - loss: 3.9833 - acc: 0.1023 - val_loss: 4.0582 - val_acc: 0.0941\n",
      "Epoch 230/250\n",
      " - 2s - loss: 3.9839 - acc: 0.1033 - val_loss: 4.0467 - val_acc: 0.0965\n",
      "Epoch 231/250\n",
      " - 2s - loss: 3.9830 - acc: 0.1027 - val_loss: 4.0483 - val_acc: 0.0952\n",
      "Epoch 232/250\n",
      " - 2s - loss: 3.9839 - acc: 0.1025 - val_loss: 4.0502 - val_acc: 0.0952\n",
      "Epoch 233/250\n",
      " - 2s - loss: 3.9852 - acc: 0.1027 - val_loss: 4.0515 - val_acc: 0.0949\n",
      "Epoch 234/250\n",
      " - 2s - loss: 3.9842 - acc: 0.1029 - val_loss: 4.0487 - val_acc: 0.0948\n",
      "Epoch 235/250\n",
      " - 2s - loss: 3.9835 - acc: 0.1028 - val_loss: 4.0531 - val_acc: 0.0957\n",
      "Epoch 236/250\n",
      " - 2s - loss: 3.9832 - acc: 0.1025 - val_loss: 4.0434 - val_acc: 0.0961\n",
      "Epoch 237/250\n",
      " - 2s - loss: 3.9874 - acc: 0.1018 - val_loss: 4.0657 - val_acc: 0.0941\n",
      "Epoch 238/250\n",
      " - 2s - loss: 3.9853 - acc: 0.1025 - val_loss: 4.0499 - val_acc: 0.0950\n",
      "Epoch 239/250\n",
      " - 2s - loss: 3.9849 - acc: 0.1020 - val_loss: 4.0534 - val_acc: 0.0943\n",
      "Epoch 240/250\n",
      " - 2s - loss: 3.9845 - acc: 0.1016 - val_loss: 4.0514 - val_acc: 0.0949\n",
      "Epoch 241/250\n",
      " - 2s - loss: 3.9842 - acc: 0.1020 - val_loss: 4.0511 - val_acc: 0.0958\n",
      "Epoch 242/250\n",
      " - 2s - loss: 3.9852 - acc: 0.1024 - val_loss: 4.0548 - val_acc: 0.0950\n",
      "Epoch 243/250\n",
      " - 2s - loss: 3.9843 - acc: 0.1030 - val_loss: 4.0504 - val_acc: 0.0950\n",
      "Epoch 244/250\n",
      " - 2s - loss: 3.9854 - acc: 0.1020 - val_loss: 4.0500 - val_acc: 0.0953\n",
      "Epoch 245/250\n",
      " - 2s - loss: 3.9838 - acc: 0.1018 - val_loss: 4.0533 - val_acc: 0.0955\n",
      "Epoch 246/250\n",
      " - 2s - loss: 3.9846 - acc: 0.1025 - val_loss: 4.0520 - val_acc: 0.0957\n",
      "Epoch 247/250\n",
      " - 2s - loss: 3.9827 - acc: 0.1021 - val_loss: 4.0501 - val_acc: 0.0945\n",
      "Epoch 248/250\n",
      " - 2s - loss: 3.9843 - acc: 0.1020 - val_loss: 4.0519 - val_acc: 0.0947\n",
      "Epoch 249/250\n",
      " - 2s - loss: 3.9838 - acc: 0.1029 - val_loss: 4.0475 - val_acc: 0.0962\n",
      "Epoch 250/250\n",
      " - 2s - loss: 3.9855 - acc: 0.1018 - val_loss: 4.0486 - val_acc: 0.0965\n",
      "Mini-Train:   4 Test Accuracy: 9.65% Learning Rate: 0.0006250\n",
      "Train on 136770 samples, validate on 15266 samples\n",
      "Epoch 1/250\n",
      " - 2s - loss: 3.9845 - acc: 0.1022 - val_loss: 4.0531 - val_acc: 0.0950\n",
      "Epoch 2/250\n",
      " - 2s - loss: 3.9854 - acc: 0.1023 - val_loss: 4.0537 - val_acc: 0.0958\n",
      "Epoch 3/250\n",
      " - 2s - loss: 3.9819 - acc: 0.1026 - val_loss: 4.0542 - val_acc: 0.0941\n",
      "Epoch 4/250\n",
      " - 2s - loss: 3.9849 - acc: 0.1034 - val_loss: 4.0440 - val_acc: 0.0959\n",
      "Epoch 5/250\n",
      " - 2s - loss: 3.9840 - acc: 0.1020 - val_loss: 4.0475 - val_acc: 0.0954\n",
      "Epoch 6/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1028 - val_loss: 4.0500 - val_acc: 0.0960\n",
      "Epoch 7/250\n",
      " - 2s - loss: 3.9834 - acc: 0.1030 - val_loss: 4.0573 - val_acc: 0.0937\n",
      "Epoch 8/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1018 - val_loss: 4.0469 - val_acc: 0.0954\n",
      "Epoch 9/250\n",
      " - 2s - loss: 3.9824 - acc: 0.1032 - val_loss: 4.0501 - val_acc: 0.0953\n",
      "Epoch 10/250\n",
      " - 2s - loss: 3.9815 - acc: 0.1023 - val_loss: 4.0475 - val_acc: 0.0952\n",
      "Epoch 11/250\n",
      " - 2s - loss: 3.9823 - acc: 0.1021 - val_loss: 4.0468 - val_acc: 0.0950\n",
      "Epoch 12/250\n",
      " - 2s - loss: 3.9835 - acc: 0.1023 - val_loss: 4.0436 - val_acc: 0.0965\n",
      "Epoch 13/250\n",
      " - 2s - loss: 3.9854 - acc: 0.1023 - val_loss: 4.0461 - val_acc: 0.0956\n",
      "Epoch 14/250\n",
      " - 2s - loss: 3.9832 - acc: 0.1019 - val_loss: 4.0529 - val_acc: 0.0950\n",
      "Epoch 15/250\n",
      " - 2s - loss: 3.9836 - acc: 0.1027 - val_loss: 4.0581 - val_acc: 0.0945\n",
      "Epoch 16/250\n",
      " - 2s - loss: 3.9866 - acc: 0.1023 - val_loss: 4.0513 - val_acc: 0.0950\n",
      "Epoch 17/250\n",
      " - 2s - loss: 3.9834 - acc: 0.1025 - val_loss: 4.0487 - val_acc: 0.0952\n",
      "Epoch 18/250\n",
      " - 2s - loss: 3.9836 - acc: 0.1029 - val_loss: 4.0493 - val_acc: 0.0952\n",
      "Epoch 19/250\n",
      " - 2s - loss: 3.9838 - acc: 0.1022 - val_loss: 4.0471 - val_acc: 0.0957\n",
      "Epoch 20/250\n",
      " - 2s - loss: 3.9837 - acc: 0.1023 - val_loss: 4.0488 - val_acc: 0.0952\n",
      "Epoch 21/250\n",
      " - 2s - loss: 3.9824 - acc: 0.1019 - val_loss: 4.0564 - val_acc: 0.0950\n",
      "Epoch 22/250\n",
      " - 2s - loss: 3.9833 - acc: 0.1022 - val_loss: 4.0484 - val_acc: 0.0956\n",
      "Epoch 23/250\n",
      " - 2s - loss: 3.9821 - acc: 0.1025 - val_loss: 4.0482 - val_acc: 0.0947\n",
      "Epoch 24/250\n",
      " - 2s - loss: 3.9815 - acc: 0.1024 - val_loss: 4.0512 - val_acc: 0.0956\n",
      "Epoch 25/250\n",
      " - 2s - loss: 3.9827 - acc: 0.1029 - val_loss: 4.0586 - val_acc: 0.0950\n",
      "Epoch 26/250\n",
      " - 2s - loss: 3.9836 - acc: 0.1037 - val_loss: 4.0506 - val_acc: 0.0960\n",
      "Epoch 27/250\n",
      " - 2s - loss: 3.9833 - acc: 0.1025 - val_loss: 4.0489 - val_acc: 0.0953\n",
      "Epoch 28/250\n",
      " - 2s - loss: 3.9841 - acc: 0.1025 - val_loss: 4.0496 - val_acc: 0.0951\n",
      "Epoch 29/250\n",
      " - 2s - loss: 3.9834 - acc: 0.1027 - val_loss: 4.0497 - val_acc: 0.0960\n",
      "Epoch 30/250\n",
      " - 2s - loss: 3.9829 - acc: 0.1029 - val_loss: 4.0581 - val_acc: 0.0946\n",
      "Epoch 31/250\n",
      " - 2s - loss: 3.9854 - acc: 0.1027 - val_loss: 4.0566 - val_acc: 0.0946\n",
      "Epoch 32/250\n",
      " - 2s - loss: 3.9823 - acc: 0.1027 - val_loss: 4.0510 - val_acc: 0.0963\n",
      "Epoch 33/250\n",
      " - 2s - loss: 3.9820 - acc: 0.1023 - val_loss: 4.0501 - val_acc: 0.0945\n",
      "Epoch 34/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1029 - val_loss: 4.0546 - val_acc: 0.0945\n",
      "Epoch 35/250\n",
      " - 2s - loss: 3.9835 - acc: 0.1031 - val_loss: 4.0477 - val_acc: 0.0965\n",
      "Epoch 36/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1022 - val_loss: 4.0427 - val_acc: 0.0967\n",
      "Epoch 37/250\n",
      " - 2s - loss: 3.9847 - acc: 0.1026 - val_loss: 4.0490 - val_acc: 0.0970\n",
      "Epoch 38/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1026 - val_loss: 4.0540 - val_acc: 0.0960\n",
      "Epoch 39/250\n",
      " - 2s - loss: 3.9808 - acc: 0.1022 - val_loss: 4.0516 - val_acc: 0.0950\n",
      "Epoch 40/250\n",
      " - 2s - loss: 3.9852 - acc: 0.1016 - val_loss: 4.0507 - val_acc: 0.0952\n",
      "Epoch 41/250\n",
      " - 2s - loss: 3.9825 - acc: 0.1028 - val_loss: 4.0465 - val_acc: 0.0958\n",
      "Epoch 42/250\n",
      " - 2s - loss: 3.9827 - acc: 0.1017 - val_loss: 4.0466 - val_acc: 0.0969\n",
      "Epoch 43/250\n",
      " - 2s - loss: 3.9819 - acc: 0.1026 - val_loss: 4.0504 - val_acc: 0.0967\n",
      "Epoch 44/250\n",
      " - 2s - loss: 3.9822 - acc: 0.1022 - val_loss: 4.0497 - val_acc: 0.0958\n",
      "Epoch 45/250\n",
      " - 2s - loss: 3.9818 - acc: 0.1026 - val_loss: 4.0544 - val_acc: 0.0952\n",
      "Epoch 46/250\n",
      " - 2s - loss: 3.9827 - acc: 0.1033 - val_loss: 4.0480 - val_acc: 0.0962\n",
      "Epoch 47/250\n",
      " - 2s - loss: 3.9834 - acc: 0.1024 - val_loss: 4.0539 - val_acc: 0.0950\n",
      "Epoch 48/250\n",
      " - 2s - loss: 3.9831 - acc: 0.1026 - val_loss: 4.0502 - val_acc: 0.0953\n",
      "Epoch 49/250\n",
      " - 2s - loss: 3.9824 - acc: 0.1024 - val_loss: 4.0440 - val_acc: 0.0963\n",
      "Epoch 50/250\n",
      " - 2s - loss: 3.9818 - acc: 0.1033 - val_loss: 4.0483 - val_acc: 0.0960\n",
      "Epoch 51/250\n",
      " - 2s - loss: 3.9819 - acc: 0.1032 - val_loss: 4.0421 - val_acc: 0.0966\n",
      "Epoch 52/250\n",
      " - 2s - loss: 3.9820 - acc: 0.1028 - val_loss: 4.0523 - val_acc: 0.0939\n",
      "Epoch 53/250\n",
      " - 2s - loss: 3.9833 - acc: 0.1029 - val_loss: 4.0474 - val_acc: 0.0952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/250\n",
      " - 2s - loss: 3.9834 - acc: 0.1025 - val_loss: 4.0507 - val_acc: 0.0954\n",
      "Epoch 55/250\n",
      " - 2s - loss: 3.9840 - acc: 0.1024 - val_loss: 4.0455 - val_acc: 0.0952\n",
      "Epoch 56/250\n",
      " - 2s - loss: 3.9842 - acc: 0.1023 - val_loss: 4.0531 - val_acc: 0.0943\n",
      "Epoch 57/250\n",
      " - 2s - loss: 3.9842 - acc: 0.1019 - val_loss: 4.0515 - val_acc: 0.0942\n",
      "Epoch 58/250\n",
      " - 2s - loss: 3.9834 - acc: 0.1027 - val_loss: 4.0482 - val_acc: 0.0963\n",
      "Epoch 59/250\n",
      " - 2s - loss: 3.9829 - acc: 0.1033 - val_loss: 4.0456 - val_acc: 0.0947\n",
      "Epoch 60/250\n",
      " - 2s - loss: 3.9821 - acc: 0.1026 - val_loss: 4.0525 - val_acc: 0.0952\n",
      "Epoch 61/250\n",
      " - 2s - loss: 3.9823 - acc: 0.1029 - val_loss: 4.0572 - val_acc: 0.0950\n",
      "Epoch 62/250\n",
      " - 2s - loss: 3.9827 - acc: 0.1023 - val_loss: 4.0438 - val_acc: 0.0967\n",
      "Epoch 63/250\n",
      " - 2s - loss: 3.9829 - acc: 0.1021 - val_loss: 4.0499 - val_acc: 0.0957\n",
      "Epoch 64/250\n",
      " - 2s - loss: 3.9810 - acc: 0.1024 - val_loss: 4.0488 - val_acc: 0.0956\n",
      "Epoch 65/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1020 - val_loss: 4.0474 - val_acc: 0.0950\n",
      "Epoch 66/250\n",
      " - 2s - loss: 3.9794 - acc: 0.1035 - val_loss: 4.0478 - val_acc: 0.0955\n",
      "Epoch 67/250\n",
      " - 2s - loss: 3.9800 - acc: 0.1034 - val_loss: 4.0521 - val_acc: 0.0957\n",
      "Epoch 68/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1018 - val_loss: 4.0523 - val_acc: 0.0958\n",
      "Epoch 69/250\n",
      " - 2s - loss: 3.9842 - acc: 0.1026 - val_loss: 4.0530 - val_acc: 0.0959\n",
      "Epoch 70/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1024 - val_loss: 4.0481 - val_acc: 0.0951\n",
      "Epoch 71/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1024 - val_loss: 4.0500 - val_acc: 0.0956\n",
      "Epoch 72/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1022 - val_loss: 4.0448 - val_acc: 0.0954\n",
      "Epoch 73/250\n",
      " - 2s - loss: 3.9843 - acc: 0.1021 - val_loss: 4.0578 - val_acc: 0.0938\n",
      "Epoch 74/250\n",
      " - 2s - loss: 3.9830 - acc: 0.1017 - val_loss: 4.0517 - val_acc: 0.0935\n",
      "Epoch 75/250\n",
      " - 2s - loss: 3.9829 - acc: 0.1027 - val_loss: 4.0471 - val_acc: 0.0962\n",
      "Epoch 76/250\n",
      " - 2s - loss: 3.9835 - acc: 0.1029 - val_loss: 4.0610 - val_acc: 0.0931\n",
      "Epoch 77/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1029 - val_loss: 4.0510 - val_acc: 0.0956\n",
      "Epoch 78/250\n",
      " - 2s - loss: 3.9816 - acc: 0.1016 - val_loss: 4.0500 - val_acc: 0.0958\n",
      "Epoch 79/250\n",
      " - 2s - loss: 3.9823 - acc: 0.1014 - val_loss: 4.0453 - val_acc: 0.0956\n",
      "Epoch 80/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1021 - val_loss: 4.0476 - val_acc: 0.0975\n",
      "Epoch 81/250\n",
      " - 2s - loss: 3.9850 - acc: 0.1026 - val_loss: 4.0504 - val_acc: 0.0952\n",
      "Epoch 82/250\n",
      " - 2s - loss: 3.9823 - acc: 0.1032 - val_loss: 4.0500 - val_acc: 0.0952\n",
      "Epoch 83/250\n",
      " - 2s - loss: 3.9831 - acc: 0.1029 - val_loss: 4.0474 - val_acc: 0.0954\n",
      "Epoch 84/250\n",
      " - 2s - loss: 3.9818 - acc: 0.1022 - val_loss: 4.0468 - val_acc: 0.0962\n",
      "Epoch 85/250\n",
      " - 2s - loss: 3.9853 - acc: 0.1024 - val_loss: 4.0533 - val_acc: 0.0947\n",
      "Epoch 86/250\n",
      " - 2s - loss: 3.9830 - acc: 0.1024 - val_loss: 4.0519 - val_acc: 0.0944\n",
      "Epoch 87/250\n",
      " - 2s - loss: 3.9833 - acc: 0.1014 - val_loss: 4.0471 - val_acc: 0.0964\n",
      "Epoch 88/250\n",
      " - 2s - loss: 3.9849 - acc: 0.1024 - val_loss: 4.0530 - val_acc: 0.0943\n",
      "Epoch 89/250\n",
      " - 2s - loss: 3.9831 - acc: 0.1026 - val_loss: 4.0492 - val_acc: 0.0953\n",
      "Epoch 90/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1025 - val_loss: 4.0483 - val_acc: 0.0961\n",
      "Epoch 91/250\n",
      " - 2s - loss: 3.9823 - acc: 0.1035 - val_loss: 4.0471 - val_acc: 0.0956\n",
      "Epoch 92/250\n",
      " - 2s - loss: 3.9828 - acc: 0.1023 - val_loss: 4.0447 - val_acc: 0.0949\n",
      "Epoch 93/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1028 - val_loss: 4.0528 - val_acc: 0.0942\n",
      "Epoch 94/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1027 - val_loss: 4.0513 - val_acc: 0.0950\n",
      "Epoch 95/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1037 - val_loss: 4.0415 - val_acc: 0.0964\n",
      "Epoch 96/250\n",
      " - 2s - loss: 3.9816 - acc: 0.1040 - val_loss: 4.0489 - val_acc: 0.0967\n",
      "Epoch 97/250\n",
      " - 2s - loss: 3.9813 - acc: 0.1020 - val_loss: 4.0503 - val_acc: 0.0947\n",
      "Epoch 98/250\n",
      " - 2s - loss: 3.9821 - acc: 0.1031 - val_loss: 4.0530 - val_acc: 0.0951\n",
      "Epoch 99/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1025 - val_loss: 4.0481 - val_acc: 0.0947\n",
      "Epoch 100/250\n",
      " - 2s - loss: 3.9816 - acc: 0.1024 - val_loss: 4.0459 - val_acc: 0.0956\n",
      "Epoch 101/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1025 - val_loss: 4.0501 - val_acc: 0.0964\n",
      "Epoch 102/250\n",
      " - 2s - loss: 3.9835 - acc: 0.1026 - val_loss: 4.0468 - val_acc: 0.0964\n",
      "Epoch 103/250\n",
      " - 2s - loss: 3.9837 - acc: 0.1023 - val_loss: 4.0470 - val_acc: 0.0958\n",
      "Epoch 104/250\n",
      " - 2s - loss: 3.9827 - acc: 0.1030 - val_loss: 4.0564 - val_acc: 0.0949\n",
      "Epoch 105/250\n",
      " - 2s - loss: 3.9813 - acc: 0.1029 - val_loss: 4.0483 - val_acc: 0.0951\n",
      "Epoch 106/250\n",
      " - 2s - loss: 3.9810 - acc: 0.1030 - val_loss: 4.0509 - val_acc: 0.0947\n",
      "Epoch 107/250\n",
      " - 2s - loss: 3.9819 - acc: 0.1029 - val_loss: 4.0452 - val_acc: 0.0965\n",
      "Epoch 108/250\n",
      " - 2s - loss: 3.9824 - acc: 0.1031 - val_loss: 4.0463 - val_acc: 0.0956\n",
      "Epoch 109/250\n",
      " - 2s - loss: 3.9828 - acc: 0.1023 - val_loss: 4.0466 - val_acc: 0.0960\n",
      "Epoch 110/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1029 - val_loss: 4.0510 - val_acc: 0.0942\n",
      "Epoch 111/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1023 - val_loss: 4.0521 - val_acc: 0.0952\n",
      "Epoch 112/250\n",
      " - 2s - loss: 3.9827 - acc: 0.1026 - val_loss: 4.0583 - val_acc: 0.0942\n",
      "Epoch 113/250\n",
      " - 2s - loss: 3.9822 - acc: 0.1035 - val_loss: 4.0475 - val_acc: 0.0956\n",
      "Epoch 114/250\n",
      " - 2s - loss: 3.9813 - acc: 0.1029 - val_loss: 4.0515 - val_acc: 0.0947\n",
      "Epoch 115/250\n",
      " - 2s - loss: 3.9820 - acc: 0.1022 - val_loss: 4.0511 - val_acc: 0.0958\n",
      "Epoch 116/250\n",
      " - 2s - loss: 3.9837 - acc: 0.1022 - val_loss: 4.0519 - val_acc: 0.0947\n",
      "Epoch 117/250\n",
      " - 2s - loss: 3.9824 - acc: 0.1023 - val_loss: 4.0501 - val_acc: 0.0951\n",
      "Epoch 118/250\n",
      " - 2s - loss: 3.9828 - acc: 0.1024 - val_loss: 4.0485 - val_acc: 0.0954\n",
      "Epoch 119/250\n",
      " - 2s - loss: 3.9831 - acc: 0.1025 - val_loss: 4.0554 - val_acc: 0.0952\n",
      "Epoch 120/250\n",
      " - 2s - loss: 3.9823 - acc: 0.1025 - val_loss: 4.0565 - val_acc: 0.0945\n",
      "Epoch 121/250\n",
      " - 2s - loss: 3.9841 - acc: 0.1026 - val_loss: 4.0515 - val_acc: 0.0946\n",
      "Epoch 122/250\n",
      " - 2s - loss: 3.9794 - acc: 0.1025 - val_loss: 4.0517 - val_acc: 0.0954\n",
      "Epoch 123/250\n",
      " - 2s - loss: 3.9840 - acc: 0.1023 - val_loss: 4.0450 - val_acc: 0.0959\n",
      "Epoch 124/250\n",
      " - 2s - loss: 3.9819 - acc: 0.1028 - val_loss: 4.0480 - val_acc: 0.0962\n",
      "Epoch 125/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1023 - val_loss: 4.0457 - val_acc: 0.0959\n",
      "Epoch 126/250\n",
      " - 2s - loss: 3.9828 - acc: 0.1022 - val_loss: 4.0509 - val_acc: 0.0949\n",
      "Epoch 127/250\n",
      " - 2s - loss: 3.9839 - acc: 0.1026 - val_loss: 4.0477 - val_acc: 0.0956\n",
      "Epoch 128/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1034 - val_loss: 4.0546 - val_acc: 0.0945\n",
      "Epoch 129/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1038 - val_loss: 4.0470 - val_acc: 0.0960\n",
      "Epoch 130/250\n",
      " - 2s - loss: 3.9828 - acc: 0.1027 - val_loss: 4.0591 - val_acc: 0.0944\n",
      "Epoch 131/250\n",
      " - 2s - loss: 3.9821 - acc: 0.1030 - val_loss: 4.0496 - val_acc: 0.0947\n",
      "Epoch 132/250\n",
      " - 2s - loss: 3.9820 - acc: 0.1037 - val_loss: 4.0518 - val_acc: 0.0955\n",
      "Epoch 133/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1023 - val_loss: 4.0489 - val_acc: 0.0960\n",
      "Epoch 134/250\n",
      " - 2s - loss: 3.9822 - acc: 0.1020 - val_loss: 4.0570 - val_acc: 0.0947\n",
      "Epoch 135/250\n",
      " - 2s - loss: 3.9830 - acc: 0.1026 - val_loss: 4.0471 - val_acc: 0.0941\n",
      "Epoch 136/250\n",
      " - 2s - loss: 3.9815 - acc: 0.1026 - val_loss: 4.0435 - val_acc: 0.0960\n",
      "Epoch 137/250\n",
      " - 2s - loss: 3.9813 - acc: 0.1022 - val_loss: 4.0482 - val_acc: 0.0953\n",
      "Epoch 138/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1043 - val_loss: 4.0493 - val_acc: 0.0948\n",
      "Epoch 139/250\n",
      " - 2s - loss: 3.9820 - acc: 0.1024 - val_loss: 4.0495 - val_acc: 0.0956\n",
      "Epoch 140/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1028 - val_loss: 4.0519 - val_acc: 0.0947\n",
      "Epoch 141/250\n",
      " - 2s - loss: 3.9829 - acc: 0.1030 - val_loss: 4.0484 - val_acc: 0.0943\n",
      "Epoch 142/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1034 - val_loss: 4.0475 - val_acc: 0.0958\n",
      "Epoch 143/250\n",
      " - 2s - loss: 3.9831 - acc: 0.1036 - val_loss: 4.0508 - val_acc: 0.0955\n",
      "Epoch 144/250\n",
      " - 2s - loss: 3.9830 - acc: 0.1021 - val_loss: 4.0552 - val_acc: 0.0943\n",
      "Epoch 145/250\n",
      " - 2s - loss: 3.9818 - acc: 0.1035 - val_loss: 4.0518 - val_acc: 0.0964\n",
      "Epoch 146/250\n",
      " - 2s - loss: 3.9836 - acc: 0.1032 - val_loss: 4.0558 - val_acc: 0.0947\n",
      "Epoch 147/250\n",
      " - 2s - loss: 3.9842 - acc: 0.1033 - val_loss: 4.0460 - val_acc: 0.0964\n",
      "Epoch 148/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1025 - val_loss: 4.0508 - val_acc: 0.0952\n",
      "Epoch 149/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1028 - val_loss: 4.0470 - val_acc: 0.0950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1039 - val_loss: 4.0475 - val_acc: 0.0958\n",
      "Epoch 151/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1025 - val_loss: 4.0498 - val_acc: 0.0942\n",
      "Epoch 152/250\n",
      " - 2s - loss: 3.9838 - acc: 0.1023 - val_loss: 4.0462 - val_acc: 0.0962\n",
      "Epoch 153/250\n",
      " - 2s - loss: 3.9825 - acc: 0.1031 - val_loss: 4.0433 - val_acc: 0.0949\n",
      "Epoch 154/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1018 - val_loss: 4.0479 - val_acc: 0.0947\n",
      "Epoch 155/250\n",
      " - 2s - loss: 3.9835 - acc: 0.1032 - val_loss: 4.0495 - val_acc: 0.0954\n",
      "Epoch 156/250\n",
      " - 2s - loss: 3.9830 - acc: 0.1025 - val_loss: 4.0488 - val_acc: 0.0944\n",
      "Epoch 157/250\n",
      " - 2s - loss: 3.9810 - acc: 0.1026 - val_loss: 4.0522 - val_acc: 0.0941\n",
      "Epoch 158/250\n",
      " - 2s - loss: 3.9810 - acc: 0.1029 - val_loss: 4.0478 - val_acc: 0.0963\n",
      "Epoch 159/250\n",
      " - 2s - loss: 3.9835 - acc: 0.1022 - val_loss: 4.0627 - val_acc: 0.0930\n",
      "Epoch 160/250\n",
      " - 2s - loss: 3.9827 - acc: 0.1020 - val_loss: 4.0543 - val_acc: 0.0941\n",
      "Epoch 161/250\n",
      " - 2s - loss: 3.9820 - acc: 0.1018 - val_loss: 4.0483 - val_acc: 0.0950\n",
      "Epoch 162/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1029 - val_loss: 4.0498 - val_acc: 0.0962\n",
      "Epoch 163/250\n",
      " - 2s - loss: 3.9833 - acc: 0.1009 - val_loss: 4.0505 - val_acc: 0.0954\n",
      "Epoch 164/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1029 - val_loss: 4.0443 - val_acc: 0.0961\n",
      "Epoch 165/250\n",
      " - 2s - loss: 3.9832 - acc: 0.1028 - val_loss: 4.0484 - val_acc: 0.0964\n",
      "Epoch 166/250\n",
      " - 2s - loss: 3.9840 - acc: 0.1021 - val_loss: 4.0493 - val_acc: 0.0955\n",
      "Epoch 167/250\n",
      " - 2s - loss: 3.9819 - acc: 0.1026 - val_loss: 4.0471 - val_acc: 0.0962\n",
      "Epoch 168/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1031 - val_loss: 4.0486 - val_acc: 0.0952\n",
      "Epoch 169/250\n",
      " - 2s - loss: 3.9843 - acc: 0.1027 - val_loss: 4.0500 - val_acc: 0.0952\n",
      "Epoch 170/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1034 - val_loss: 4.0470 - val_acc: 0.0957\n",
      "Epoch 171/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1027 - val_loss: 4.0485 - val_acc: 0.0950\n",
      "Epoch 172/250\n",
      " - 2s - loss: 3.9813 - acc: 0.1035 - val_loss: 4.0450 - val_acc: 0.0958\n",
      "Epoch 173/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1024 - val_loss: 4.0445 - val_acc: 0.0954\n",
      "Epoch 174/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1032 - val_loss: 4.0480 - val_acc: 0.0946\n",
      "Epoch 175/250\n",
      " - 2s - loss: 3.9829 - acc: 0.1032 - val_loss: 4.0475 - val_acc: 0.0961\n",
      "Epoch 176/250\n",
      " - 2s - loss: 3.9818 - acc: 0.1018 - val_loss: 4.0517 - val_acc: 0.0952\n",
      "Epoch 177/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1026 - val_loss: 4.0538 - val_acc: 0.0950\n",
      "Epoch 178/250\n",
      " - 2s - loss: 3.9839 - acc: 0.1021 - val_loss: 4.0613 - val_acc: 0.0939\n",
      "Epoch 179/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1030 - val_loss: 4.0482 - val_acc: 0.0952\n",
      "Epoch 180/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1020 - val_loss: 4.0571 - val_acc: 0.0943\n",
      "Epoch 181/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1030 - val_loss: 4.0460 - val_acc: 0.0958\n",
      "Epoch 182/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1021 - val_loss: 4.0524 - val_acc: 0.0958\n",
      "Epoch 183/250\n",
      " - 2s - loss: 3.9834 - acc: 0.1024 - val_loss: 4.0475 - val_acc: 0.0959\n",
      "Epoch 184/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1023 - val_loss: 4.0454 - val_acc: 0.0953\n",
      "Epoch 185/250\n",
      " - 2s - loss: 3.9836 - acc: 0.1034 - val_loss: 4.0518 - val_acc: 0.0944\n",
      "Epoch 186/250\n",
      " - 2s - loss: 3.9830 - acc: 0.1032 - val_loss: 4.0476 - val_acc: 0.0957\n",
      "Epoch 187/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1033 - val_loss: 4.0443 - val_acc: 0.0956\n",
      "Epoch 188/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1033 - val_loss: 4.0459 - val_acc: 0.0955\n",
      "Epoch 189/250\n",
      " - 2s - loss: 3.9851 - acc: 0.1020 - val_loss: 4.0481 - val_acc: 0.0967\n",
      "Epoch 190/250\n",
      " - 2s - loss: 3.9813 - acc: 0.1022 - val_loss: 4.0543 - val_acc: 0.0950\n",
      "Epoch 191/250\n",
      " - 2s - loss: 3.9825 - acc: 0.1019 - val_loss: 4.0565 - val_acc: 0.0958\n",
      "Epoch 192/250\n",
      " - 2s - loss: 3.9820 - acc: 0.1036 - val_loss: 4.0483 - val_acc: 0.0954\n",
      "Epoch 193/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1026 - val_loss: 4.0455 - val_acc: 0.0960\n",
      "Epoch 194/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1033 - val_loss: 4.0452 - val_acc: 0.0961\n",
      "Epoch 195/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1031 - val_loss: 4.0481 - val_acc: 0.0955\n",
      "Epoch 196/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1028 - val_loss: 4.0472 - val_acc: 0.0956\n",
      "Epoch 197/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1033 - val_loss: 4.0578 - val_acc: 0.0937\n",
      "Epoch 198/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1030 - val_loss: 4.0491 - val_acc: 0.0954\n",
      "Epoch 199/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1024 - val_loss: 4.0461 - val_acc: 0.0962\n",
      "Epoch 200/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1027 - val_loss: 4.0503 - val_acc: 0.0960\n",
      "Epoch 201/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1033 - val_loss: 4.0499 - val_acc: 0.0960\n",
      "Epoch 202/250\n",
      " - 2s - loss: 3.9832 - acc: 0.1026 - val_loss: 4.0454 - val_acc: 0.0959\n",
      "Epoch 203/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1033 - val_loss: 4.0478 - val_acc: 0.0961\n",
      "Epoch 204/250\n",
      " - 2s - loss: 3.9832 - acc: 0.1024 - val_loss: 4.0517 - val_acc: 0.0943\n",
      "Epoch 205/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1041 - val_loss: 4.0434 - val_acc: 0.0968\n",
      "Epoch 206/250\n",
      " - 2s - loss: 3.9821 - acc: 0.1022 - val_loss: 4.0467 - val_acc: 0.0956\n",
      "Epoch 207/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1039 - val_loss: 4.0494 - val_acc: 0.0958\n",
      "Epoch 208/250\n",
      " - 2s - loss: 3.9808 - acc: 0.1032 - val_loss: 4.0539 - val_acc: 0.0950\n",
      "Epoch 209/250\n",
      " - 2s - loss: 3.9828 - acc: 0.1017 - val_loss: 4.0475 - val_acc: 0.0962\n",
      "Epoch 210/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1022 - val_loss: 4.0513 - val_acc: 0.0953\n",
      "Epoch 211/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1026 - val_loss: 4.0492 - val_acc: 0.0949\n",
      "Epoch 212/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1026 - val_loss: 4.0491 - val_acc: 0.0945\n",
      "Epoch 213/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1025 - val_loss: 4.0474 - val_acc: 0.0956\n",
      "Epoch 214/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1020 - val_loss: 4.0552 - val_acc: 0.0941\n",
      "Epoch 215/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1021 - val_loss: 4.0462 - val_acc: 0.0952\n",
      "Epoch 216/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1034 - val_loss: 4.0480 - val_acc: 0.0962\n",
      "Epoch 217/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1035 - val_loss: 4.0459 - val_acc: 0.0958\n",
      "Epoch 218/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1032 - val_loss: 4.0441 - val_acc: 0.0958\n",
      "Epoch 219/250\n",
      " - 2s - loss: 3.9813 - acc: 0.1024 - val_loss: 4.0527 - val_acc: 0.0941\n",
      "Epoch 220/250\n",
      " - 2s - loss: 3.9816 - acc: 0.1029 - val_loss: 4.0484 - val_acc: 0.0959\n",
      "Epoch 221/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1028 - val_loss: 4.0485 - val_acc: 0.0948\n",
      "Epoch 222/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1031 - val_loss: 4.0476 - val_acc: 0.0954\n",
      "Epoch 223/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1034 - val_loss: 4.0457 - val_acc: 0.0956\n",
      "Epoch 224/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1018 - val_loss: 4.0473 - val_acc: 0.0957\n",
      "Epoch 225/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1026 - val_loss: 4.0490 - val_acc: 0.0950\n",
      "Epoch 226/250\n",
      " - 2s - loss: 3.9813 - acc: 0.1028 - val_loss: 4.0437 - val_acc: 0.0960\n",
      "Epoch 227/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1031 - val_loss: 4.0528 - val_acc: 0.0952\n",
      "Epoch 228/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1028 - val_loss: 4.0462 - val_acc: 0.0952\n",
      "Epoch 229/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1033 - val_loss: 4.0518 - val_acc: 0.0942\n",
      "Epoch 230/250\n",
      " - 2s - loss: 3.9823 - acc: 0.1030 - val_loss: 4.0444 - val_acc: 0.0954\n",
      "Epoch 231/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1022 - val_loss: 4.0504 - val_acc: 0.0938\n",
      "Epoch 232/250\n",
      " - 2s - loss: 3.9836 - acc: 0.1034 - val_loss: 4.0484 - val_acc: 0.0944\n",
      "Epoch 233/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1033 - val_loss: 4.0464 - val_acc: 0.0962\n",
      "Epoch 234/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1035 - val_loss: 4.0536 - val_acc: 0.0945\n",
      "Epoch 235/250\n",
      " - 2s - loss: 3.9835 - acc: 0.1022 - val_loss: 4.0482 - val_acc: 0.0948\n",
      "Epoch 236/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1031 - val_loss: 4.0475 - val_acc: 0.0955\n",
      "Epoch 237/250\n",
      " - 2s - loss: 3.9810 - acc: 0.1030 - val_loss: 4.0523 - val_acc: 0.0947\n",
      "Epoch 238/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1027 - val_loss: 4.0476 - val_acc: 0.0956\n",
      "Epoch 239/250\n",
      " - 2s - loss: 3.9821 - acc: 0.1021 - val_loss: 4.0466 - val_acc: 0.0961\n",
      "Epoch 240/250\n",
      " - 2s - loss: 3.9800 - acc: 0.1026 - val_loss: 4.0494 - val_acc: 0.0947\n",
      "Epoch 241/250\n",
      " - 2s - loss: 3.9828 - acc: 0.1040 - val_loss: 4.0539 - val_acc: 0.0951\n",
      "Epoch 242/250\n",
      " - 2s - loss: 3.9815 - acc: 0.1032 - val_loss: 4.0513 - val_acc: 0.0956\n",
      "Epoch 243/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1029 - val_loss: 4.0450 - val_acc: 0.0973\n",
      "Epoch 244/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1031 - val_loss: 4.0470 - val_acc: 0.0949\n",
      "Epoch 245/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1032 - val_loss: 4.0518 - val_acc: 0.0943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1033 - val_loss: 4.0482 - val_acc: 0.0956\n",
      "Epoch 247/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1028 - val_loss: 4.0484 - val_acc: 0.0956\n",
      "Epoch 248/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1041 - val_loss: 4.0504 - val_acc: 0.0954\n",
      "Epoch 249/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1034 - val_loss: 4.0518 - val_acc: 0.0947\n",
      "Epoch 250/250\n",
      " - 2s - loss: 3.9816 - acc: 0.1019 - val_loss: 4.0497 - val_acc: 0.0961\n",
      "Mini-Train:   5 Test Accuracy: 9.61% Learning Rate: 0.0005000\n",
      "Train on 136770 samples, validate on 15266 samples\n",
      "Epoch 1/250\n",
      " - 2s - loss: 3.9813 - acc: 0.1030 - val_loss: 4.0470 - val_acc: 0.0960\n",
      "Epoch 2/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1028 - val_loss: 4.0452 - val_acc: 0.0955\n",
      "Epoch 3/250\n",
      " - 2s - loss: 3.9801 - acc: 0.1041 - val_loss: 4.0466 - val_acc: 0.0956\n",
      "Epoch 4/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1048 - val_loss: 4.0488 - val_acc: 0.0949\n",
      "Epoch 5/250\n",
      " - 2s - loss: 3.9821 - acc: 0.1020 - val_loss: 4.0465 - val_acc: 0.0959\n",
      "Epoch 6/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1027 - val_loss: 4.0473 - val_acc: 0.0959\n",
      "Epoch 7/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1022 - val_loss: 4.0505 - val_acc: 0.0950\n",
      "Epoch 8/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1023 - val_loss: 4.0522 - val_acc: 0.0952\n",
      "Epoch 9/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1031 - val_loss: 4.0456 - val_acc: 0.0959\n",
      "Epoch 10/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1027 - val_loss: 4.0472 - val_acc: 0.0960\n",
      "Epoch 11/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1030 - val_loss: 4.0507 - val_acc: 0.0953\n",
      "Epoch 12/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1030 - val_loss: 4.0435 - val_acc: 0.0961\n",
      "Epoch 13/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1031 - val_loss: 4.0473 - val_acc: 0.0962\n",
      "Epoch 14/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1030 - val_loss: 4.0464 - val_acc: 0.0959\n",
      "Epoch 15/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1035 - val_loss: 4.0449 - val_acc: 0.0962\n",
      "Epoch 16/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1030 - val_loss: 4.0519 - val_acc: 0.0948\n",
      "Epoch 17/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1030 - val_loss: 4.0506 - val_acc: 0.0946\n",
      "Epoch 18/250\n",
      " - 2s - loss: 3.9810 - acc: 0.1021 - val_loss: 4.0488 - val_acc: 0.0954\n",
      "Epoch 19/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1036 - val_loss: 4.0490 - val_acc: 0.0954\n",
      "Epoch 20/250\n",
      " - 2s - loss: 3.9810 - acc: 0.1029 - val_loss: 4.0462 - val_acc: 0.0962\n",
      "Epoch 21/250\n",
      " - 2s - loss: 3.9793 - acc: 0.1018 - val_loss: 4.0452 - val_acc: 0.0955\n",
      "Epoch 22/250\n",
      " - 2s - loss: 3.9800 - acc: 0.1028 - val_loss: 4.0503 - val_acc: 0.0951\n",
      "Epoch 23/250\n",
      " - 2s - loss: 3.9800 - acc: 0.1028 - val_loss: 4.0458 - val_acc: 0.0950\n",
      "Epoch 24/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1028 - val_loss: 4.0510 - val_acc: 0.0954\n",
      "Epoch 25/250\n",
      " - 2s - loss: 3.9800 - acc: 0.1026 - val_loss: 4.0477 - val_acc: 0.0953\n",
      "Epoch 26/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1023 - val_loss: 4.0451 - val_acc: 0.0956\n",
      "Epoch 27/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1041 - val_loss: 4.0483 - val_acc: 0.0953\n",
      "Epoch 28/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1023 - val_loss: 4.0455 - val_acc: 0.0954\n",
      "Epoch 29/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1032 - val_loss: 4.0470 - val_acc: 0.0964\n",
      "Epoch 30/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1014 - val_loss: 4.0467 - val_acc: 0.0954\n",
      "Epoch 31/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1032 - val_loss: 4.0477 - val_acc: 0.0956\n",
      "Epoch 32/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1035 - val_loss: 4.0461 - val_acc: 0.0956\n",
      "Epoch 33/250\n",
      " - 2s - loss: 3.9816 - acc: 0.1027 - val_loss: 4.0546 - val_acc: 0.0945\n",
      "Epoch 34/250\n",
      " - 2s - loss: 3.9822 - acc: 0.1029 - val_loss: 4.0465 - val_acc: 0.0960\n",
      "Epoch 35/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1025 - val_loss: 4.0513 - val_acc: 0.0949\n",
      "Epoch 36/250\n",
      " - 2s - loss: 3.9821 - acc: 0.1036 - val_loss: 4.0436 - val_acc: 0.0967\n",
      "Epoch 37/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1023 - val_loss: 4.0460 - val_acc: 0.0947\n",
      "Epoch 38/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1027 - val_loss: 4.0411 - val_acc: 0.0970\n",
      "Epoch 39/250\n",
      " - 2s - loss: 3.9800 - acc: 0.1025 - val_loss: 4.0488 - val_acc: 0.0949\n",
      "Epoch 40/250\n",
      " - 2s - loss: 3.9815 - acc: 0.1025 - val_loss: 4.0474 - val_acc: 0.0950\n",
      "Epoch 41/250\n",
      " - 2s - loss: 3.9842 - acc: 0.1026 - val_loss: 4.0491 - val_acc: 0.0959\n",
      "Epoch 42/250\n",
      " - 2s - loss: 3.9788 - acc: 0.1032 - val_loss: 4.0470 - val_acc: 0.0950\n",
      "Epoch 43/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1019 - val_loss: 4.0440 - val_acc: 0.0957\n",
      "Epoch 44/250\n",
      " - 2s - loss: 3.9808 - acc: 0.1031 - val_loss: 4.0434 - val_acc: 0.0960\n",
      "Epoch 45/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1024 - val_loss: 4.0446 - val_acc: 0.0959\n",
      "Epoch 46/250\n",
      " - 2s - loss: 3.9808 - acc: 0.1027 - val_loss: 4.0518 - val_acc: 0.0949\n",
      "Epoch 47/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1027 - val_loss: 4.0474 - val_acc: 0.0958\n",
      "Epoch 48/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1025 - val_loss: 4.0531 - val_acc: 0.0956\n",
      "Epoch 49/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1035 - val_loss: 4.0503 - val_acc: 0.0957\n",
      "Epoch 50/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1032 - val_loss: 4.0498 - val_acc: 0.0954\n",
      "Epoch 51/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1032 - val_loss: 4.0477 - val_acc: 0.0957\n",
      "Epoch 52/250\n",
      " - 2s - loss: 3.9808 - acc: 0.1032 - val_loss: 4.0509 - val_acc: 0.0952\n",
      "Epoch 53/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1032 - val_loss: 4.0539 - val_acc: 0.0950\n",
      "Epoch 54/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1021 - val_loss: 4.0445 - val_acc: 0.0959\n",
      "Epoch 55/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1031 - val_loss: 4.0527 - val_acc: 0.0940\n",
      "Epoch 56/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1024 - val_loss: 4.0440 - val_acc: 0.0959\n",
      "Epoch 57/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1024 - val_loss: 4.0468 - val_acc: 0.0955\n",
      "Epoch 58/250\n",
      " - 2s - loss: 3.9808 - acc: 0.1035 - val_loss: 4.0447 - val_acc: 0.0955\n",
      "Epoch 59/250\n",
      " - 2s - loss: 3.9794 - acc: 0.1033 - val_loss: 4.0483 - val_acc: 0.0952\n",
      "Epoch 60/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1026 - val_loss: 4.0484 - val_acc: 0.0947\n",
      "Epoch 61/250\n",
      " - 2s - loss: 3.9820 - acc: 0.1025 - val_loss: 4.0435 - val_acc: 0.0958\n",
      "Epoch 62/250\n",
      " - 2s - loss: 3.9800 - acc: 0.1023 - val_loss: 4.0457 - val_acc: 0.0956\n",
      "Epoch 63/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1022 - val_loss: 4.0477 - val_acc: 0.0960\n",
      "Epoch 64/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1028 - val_loss: 4.0440 - val_acc: 0.0950\n",
      "Epoch 65/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1022 - val_loss: 4.0493 - val_acc: 0.0953\n",
      "Epoch 66/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1029 - val_loss: 4.0487 - val_acc: 0.0949\n",
      "Epoch 67/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1027 - val_loss: 4.0480 - val_acc: 0.0954\n",
      "Epoch 68/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1017 - val_loss: 4.0515 - val_acc: 0.0948\n",
      "Epoch 69/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1033 - val_loss: 4.0481 - val_acc: 0.0959\n",
      "Epoch 70/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1025 - val_loss: 4.0432 - val_acc: 0.0953\n",
      "Epoch 71/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1033 - val_loss: 4.0504 - val_acc: 0.0954\n",
      "Epoch 72/250\n",
      " - 2s - loss: 3.9793 - acc: 0.1028 - val_loss: 4.0477 - val_acc: 0.0949\n",
      "Epoch 73/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1035 - val_loss: 4.0501 - val_acc: 0.0948\n",
      "Epoch 74/250\n",
      " - 2s - loss: 3.9789 - acc: 0.1031 - val_loss: 4.0477 - val_acc: 0.0956\n",
      "Epoch 75/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1028 - val_loss: 4.0455 - val_acc: 0.0956\n",
      "Epoch 76/250\n",
      " - 2s - loss: 3.9794 - acc: 0.1031 - val_loss: 4.0497 - val_acc: 0.0962\n",
      "Epoch 77/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1027 - val_loss: 4.0502 - val_acc: 0.0964\n",
      "Epoch 78/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1033 - val_loss: 4.0432 - val_acc: 0.0973\n",
      "Epoch 79/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1030 - val_loss: 4.0461 - val_acc: 0.0961\n",
      "Epoch 80/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1027 - val_loss: 4.0549 - val_acc: 0.0949\n",
      "Epoch 81/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1026 - val_loss: 4.0489 - val_acc: 0.0965\n",
      "Epoch 82/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1033 - val_loss: 4.0452 - val_acc: 0.0957\n",
      "Epoch 83/250\n",
      " - 2s - loss: 3.9821 - acc: 0.1031 - val_loss: 4.0510 - val_acc: 0.0956\n",
      "Epoch 84/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1038 - val_loss: 4.0476 - val_acc: 0.0954\n",
      "Epoch 85/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1033 - val_loss: 4.0507 - val_acc: 0.0950\n",
      "Epoch 86/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1018 - val_loss: 4.0475 - val_acc: 0.0950\n",
      "Epoch 87/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1036 - val_loss: 4.0459 - val_acc: 0.0959\n",
      "Epoch 88/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1037 - val_loss: 4.0479 - val_acc: 0.0950\n",
      "Epoch 89/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1034 - val_loss: 4.0453 - val_acc: 0.0952\n",
      "Epoch 90/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1038 - val_loss: 4.0513 - val_acc: 0.0958\n",
      "Epoch 91/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 3.9817 - acc: 0.1029 - val_loss: 4.0489 - val_acc: 0.0949\n",
      "Epoch 92/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1035 - val_loss: 4.0478 - val_acc: 0.0953\n",
      "Epoch 93/250\n",
      " - 2s - loss: 3.9825 - acc: 0.1032 - val_loss: 4.0453 - val_acc: 0.0963\n",
      "Epoch 94/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1026 - val_loss: 4.0516 - val_acc: 0.0956\n",
      "Epoch 95/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1037 - val_loss: 4.0494 - val_acc: 0.0950\n",
      "Epoch 96/250\n",
      " - 2s - loss: 3.9848 - acc: 0.1028 - val_loss: 4.0533 - val_acc: 0.0953\n",
      "Epoch 97/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1030 - val_loss: 4.0523 - val_acc: 0.0954\n",
      "Epoch 98/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1024 - val_loss: 4.0482 - val_acc: 0.0956\n",
      "Epoch 99/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1029 - val_loss: 4.0496 - val_acc: 0.0954\n",
      "Epoch 100/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1029 - val_loss: 4.0492 - val_acc: 0.0950\n",
      "Epoch 101/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1023 - val_loss: 4.0487 - val_acc: 0.0951\n",
      "Epoch 102/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1031 - val_loss: 4.0466 - val_acc: 0.0954\n",
      "Epoch 103/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1024 - val_loss: 4.0516 - val_acc: 0.0942\n",
      "Epoch 104/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1024 - val_loss: 4.0499 - val_acc: 0.0950\n",
      "Epoch 105/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1031 - val_loss: 4.0528 - val_acc: 0.0945\n",
      "Epoch 106/250\n",
      " - 2s - loss: 3.9801 - acc: 0.1034 - val_loss: 4.0454 - val_acc: 0.0964\n",
      "Epoch 107/250\n",
      " - 2s - loss: 3.9808 - acc: 0.1037 - val_loss: 4.0483 - val_acc: 0.0960\n",
      "Epoch 108/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1023 - val_loss: 4.0494 - val_acc: 0.0956\n",
      "Epoch 109/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1023 - val_loss: 4.0494 - val_acc: 0.0959\n",
      "Epoch 110/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1026 - val_loss: 4.0525 - val_acc: 0.0947\n",
      "Epoch 111/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1028 - val_loss: 4.0480 - val_acc: 0.0950\n",
      "Epoch 112/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1024 - val_loss: 4.0460 - val_acc: 0.0950\n",
      "Epoch 113/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1028 - val_loss: 4.0516 - val_acc: 0.0951\n",
      "Epoch 114/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1029 - val_loss: 4.0479 - val_acc: 0.0956\n",
      "Epoch 115/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1025 - val_loss: 4.0505 - val_acc: 0.0952\n",
      "Epoch 116/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1031 - val_loss: 4.0490 - val_acc: 0.0959\n",
      "Epoch 117/250\n",
      " - 2s - loss: 3.9824 - acc: 0.1030 - val_loss: 4.0479 - val_acc: 0.0954\n",
      "Epoch 118/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1036 - val_loss: 4.0527 - val_acc: 0.0941\n",
      "Epoch 119/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1029 - val_loss: 4.0474 - val_acc: 0.0954\n",
      "Epoch 120/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1026 - val_loss: 4.0534 - val_acc: 0.0944\n",
      "Epoch 121/250\n",
      " - 2s - loss: 3.9826 - acc: 0.1023 - val_loss: 4.0456 - val_acc: 0.0952\n",
      "Epoch 122/250\n",
      " - 2s - loss: 3.9816 - acc: 0.1026 - val_loss: 4.0434 - val_acc: 0.0954\n",
      "Epoch 123/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1031 - val_loss: 4.0498 - val_acc: 0.0960\n",
      "Epoch 124/250\n",
      " - 2s - loss: 3.9808 - acc: 0.1035 - val_loss: 4.0439 - val_acc: 0.0949\n",
      "Epoch 125/250\n",
      " - 2s - loss: 3.9828 - acc: 0.1026 - val_loss: 4.0458 - val_acc: 0.0966\n",
      "Epoch 126/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1029 - val_loss: 4.0448 - val_acc: 0.0958\n",
      "Epoch 127/250\n",
      " - 2s - loss: 3.9801 - acc: 0.1026 - val_loss: 4.0464 - val_acc: 0.0960\n",
      "Epoch 128/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1044 - val_loss: 4.0501 - val_acc: 0.0947\n",
      "Epoch 129/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1031 - val_loss: 4.0397 - val_acc: 0.0959\n",
      "Epoch 130/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1032 - val_loss: 4.0451 - val_acc: 0.0956\n",
      "Epoch 131/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1026 - val_loss: 4.0466 - val_acc: 0.0950\n",
      "Epoch 132/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1026 - val_loss: 4.0531 - val_acc: 0.0941\n",
      "Epoch 133/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1034 - val_loss: 4.0473 - val_acc: 0.0943\n",
      "Epoch 134/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1040 - val_loss: 4.0451 - val_acc: 0.0959\n",
      "Epoch 135/250\n",
      " - 2s - loss: 3.9789 - acc: 0.1032 - val_loss: 4.0500 - val_acc: 0.0949\n",
      "Epoch 136/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1031 - val_loss: 4.0508 - val_acc: 0.0948\n",
      "Epoch 137/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1034 - val_loss: 4.0481 - val_acc: 0.0957\n",
      "Epoch 138/250\n",
      " - 2s - loss: 3.9823 - acc: 0.1027 - val_loss: 4.0419 - val_acc: 0.0960\n",
      "Epoch 139/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1028 - val_loss: 4.0435 - val_acc: 0.0960\n",
      "Epoch 140/250\n",
      " - 2s - loss: 3.9801 - acc: 0.1029 - val_loss: 4.0459 - val_acc: 0.0956\n",
      "Epoch 141/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1026 - val_loss: 4.0504 - val_acc: 0.0943\n",
      "Epoch 142/250\n",
      " - 2s - loss: 3.9813 - acc: 0.1027 - val_loss: 4.0577 - val_acc: 0.0940\n",
      "Epoch 143/250\n",
      " - 2s - loss: 3.9827 - acc: 0.1028 - val_loss: 4.0540 - val_acc: 0.0949\n",
      "Epoch 144/250\n",
      " - 2s - loss: 3.9825 - acc: 0.1026 - val_loss: 4.0462 - val_acc: 0.0962\n",
      "Epoch 145/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1022 - val_loss: 4.0434 - val_acc: 0.0958\n",
      "Epoch 146/250\n",
      " - 2s - loss: 3.9819 - acc: 0.1030 - val_loss: 4.0498 - val_acc: 0.0945\n",
      "Epoch 147/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1024 - val_loss: 4.0455 - val_acc: 0.0952\n",
      "Epoch 148/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1035 - val_loss: 4.0463 - val_acc: 0.0960\n",
      "Epoch 149/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1028 - val_loss: 4.0447 - val_acc: 0.0961\n",
      "Epoch 150/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1030 - val_loss: 4.0480 - val_acc: 0.0950\n",
      "Epoch 151/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1035 - val_loss: 4.0495 - val_acc: 0.0956\n",
      "Epoch 152/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1032 - val_loss: 4.0482 - val_acc: 0.0951\n",
      "Epoch 153/250\n",
      " - 2s - loss: 3.9793 - acc: 0.1028 - val_loss: 4.0494 - val_acc: 0.0949\n",
      "Epoch 154/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1030 - val_loss: 4.0469 - val_acc: 0.0960\n",
      "Epoch 155/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1025 - val_loss: 4.0510 - val_acc: 0.0943\n",
      "Epoch 156/250\n",
      " - 2s - loss: 3.9794 - acc: 0.1045 - val_loss: 4.0434 - val_acc: 0.0966\n",
      "Epoch 157/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1028 - val_loss: 4.0485 - val_acc: 0.0958\n",
      "Epoch 158/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1022 - val_loss: 4.0469 - val_acc: 0.0964\n",
      "Epoch 159/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1029 - val_loss: 4.0420 - val_acc: 0.0963\n",
      "Epoch 160/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1031 - val_loss: 4.0480 - val_acc: 0.0957\n",
      "Epoch 161/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1031 - val_loss: 4.0451 - val_acc: 0.0959\n",
      "Epoch 162/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1026 - val_loss: 4.0468 - val_acc: 0.0954\n",
      "Epoch 163/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1028 - val_loss: 4.0452 - val_acc: 0.0958\n",
      "Epoch 164/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1028 - val_loss: 4.0433 - val_acc: 0.0960\n",
      "Epoch 165/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1029 - val_loss: 4.0472 - val_acc: 0.0956\n",
      "Epoch 166/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1036 - val_loss: 4.0442 - val_acc: 0.0959\n",
      "Epoch 167/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1030 - val_loss: 4.0589 - val_acc: 0.0939\n",
      "Epoch 168/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1028 - val_loss: 4.0440 - val_acc: 0.0959\n",
      "Epoch 169/250\n",
      " - 2s - loss: 3.9812 - acc: 0.1033 - val_loss: 4.0486 - val_acc: 0.0954\n",
      "Epoch 170/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1040 - val_loss: 4.0515 - val_acc: 0.0945\n",
      "Epoch 171/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1035 - val_loss: 4.0526 - val_acc: 0.0944\n",
      "Epoch 172/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1038 - val_loss: 4.0459 - val_acc: 0.0958\n",
      "Epoch 173/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1036 - val_loss: 4.0456 - val_acc: 0.0960\n",
      "Epoch 174/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1029 - val_loss: 4.0441 - val_acc: 0.0960\n",
      "Epoch 175/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1027 - val_loss: 4.0480 - val_acc: 0.0951\n",
      "Epoch 176/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1029 - val_loss: 4.0487 - val_acc: 0.0952\n",
      "Epoch 177/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1026 - val_loss: 4.0473 - val_acc: 0.0962\n",
      "Epoch 178/250\n",
      " - 2s - loss: 3.9814 - acc: 0.1032 - val_loss: 4.0531 - val_acc: 0.0945\n",
      "Epoch 179/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1033 - val_loss: 4.0487 - val_acc: 0.0952\n",
      "Epoch 180/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1032 - val_loss: 4.0456 - val_acc: 0.0962\n",
      "Epoch 181/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1016 - val_loss: 4.0437 - val_acc: 0.0962\n",
      "Epoch 182/250\n",
      " - 2s - loss: 3.9820 - acc: 0.1036 - val_loss: 4.0463 - val_acc: 0.0947\n",
      "Epoch 183/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1038 - val_loss: 4.0444 - val_acc: 0.0965\n",
      "Epoch 184/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1027 - val_loss: 4.0462 - val_acc: 0.0959\n",
      "Epoch 185/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1030 - val_loss: 4.0524 - val_acc: 0.0939\n",
      "Epoch 186/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1022 - val_loss: 4.0439 - val_acc: 0.0958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/250\n",
      " - 2s - loss: 3.9800 - acc: 0.1029 - val_loss: 4.0460 - val_acc: 0.0961\n",
      "Epoch 188/250\n",
      " - 2s - loss: 3.9789 - acc: 0.1041 - val_loss: 4.0446 - val_acc: 0.0958\n",
      "Epoch 189/250\n",
      " - 2s - loss: 3.9800 - acc: 0.1029 - val_loss: 4.0453 - val_acc: 0.0956\n",
      "Epoch 190/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1025 - val_loss: 4.0444 - val_acc: 0.0960\n",
      "Epoch 191/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1033 - val_loss: 4.0467 - val_acc: 0.0947\n",
      "Epoch 192/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1031 - val_loss: 4.0422 - val_acc: 0.0962\n",
      "Epoch 193/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1033 - val_loss: 4.0434 - val_acc: 0.0955\n",
      "Epoch 194/250\n",
      " - 2s - loss: 3.9825 - acc: 0.1023 - val_loss: 4.0510 - val_acc: 0.0948\n",
      "Epoch 195/250\n",
      " - 2s - loss: 3.9810 - acc: 0.1030 - val_loss: 4.0438 - val_acc: 0.0957\n",
      "Epoch 196/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1039 - val_loss: 4.0465 - val_acc: 0.0956\n",
      "Epoch 197/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1024 - val_loss: 4.0450 - val_acc: 0.0956\n",
      "Epoch 198/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1028 - val_loss: 4.0496 - val_acc: 0.0954\n",
      "Epoch 199/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1031 - val_loss: 4.0549 - val_acc: 0.0947\n",
      "Epoch 200/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1034 - val_loss: 4.0493 - val_acc: 0.0953\n",
      "Epoch 201/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1023 - val_loss: 4.0443 - val_acc: 0.0960\n",
      "Epoch 202/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1033 - val_loss: 4.0488 - val_acc: 0.0949\n",
      "Epoch 203/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1040 - val_loss: 4.0503 - val_acc: 0.0958\n",
      "Epoch 204/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1034 - val_loss: 4.0522 - val_acc: 0.0947\n",
      "Epoch 205/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1022 - val_loss: 4.0466 - val_acc: 0.0948\n",
      "Epoch 206/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1025 - val_loss: 4.0472 - val_acc: 0.0951\n",
      "Epoch 207/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1031 - val_loss: 4.0443 - val_acc: 0.0960\n",
      "Epoch 208/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1030 - val_loss: 4.0459 - val_acc: 0.0964\n",
      "Epoch 209/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1029 - val_loss: 4.0500 - val_acc: 0.0947\n",
      "Epoch 210/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1036 - val_loss: 4.0432 - val_acc: 0.0950\n",
      "Epoch 211/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1036 - val_loss: 4.0461 - val_acc: 0.0958\n",
      "Epoch 212/250\n",
      " - 2s - loss: 3.9793 - acc: 0.1020 - val_loss: 4.0496 - val_acc: 0.0950\n",
      "Epoch 213/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1036 - val_loss: 4.0482 - val_acc: 0.0962\n",
      "Epoch 214/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1028 - val_loss: 4.0460 - val_acc: 0.0962\n",
      "Epoch 215/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1016 - val_loss: 4.0465 - val_acc: 0.0961\n",
      "Epoch 216/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1026 - val_loss: 4.0433 - val_acc: 0.0962\n",
      "Epoch 217/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1030 - val_loss: 4.0495 - val_acc: 0.0948\n",
      "Epoch 218/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1025 - val_loss: 4.0497 - val_acc: 0.0954\n",
      "Epoch 219/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1032 - val_loss: 4.0527 - val_acc: 0.0948\n",
      "Epoch 220/250\n",
      " - 2s - loss: 3.9821 - acc: 0.1027 - val_loss: 4.0481 - val_acc: 0.0952\n",
      "Epoch 221/250\n",
      " - 2s - loss: 3.9789 - acc: 0.1029 - val_loss: 4.0461 - val_acc: 0.0962\n",
      "Epoch 222/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1034 - val_loss: 4.0430 - val_acc: 0.0965\n",
      "Epoch 223/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1027 - val_loss: 4.0464 - val_acc: 0.0961\n",
      "Epoch 224/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1031 - val_loss: 4.0500 - val_acc: 0.0938\n",
      "Epoch 225/250\n",
      " - 2s - loss: 3.9788 - acc: 0.1040 - val_loss: 4.0471 - val_acc: 0.0962\n",
      "Epoch 226/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1025 - val_loss: 4.0447 - val_acc: 0.0966\n",
      "Epoch 227/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1023 - val_loss: 4.0421 - val_acc: 0.0952\n",
      "Epoch 228/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1028 - val_loss: 4.0429 - val_acc: 0.0958\n",
      "Epoch 229/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1037 - val_loss: 4.0487 - val_acc: 0.0949\n",
      "Epoch 230/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1030 - val_loss: 4.0414 - val_acc: 0.0956\n",
      "Epoch 231/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1039 - val_loss: 4.0436 - val_acc: 0.0958\n",
      "Epoch 232/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1035 - val_loss: 4.0534 - val_acc: 0.0955\n",
      "Epoch 233/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1032 - val_loss: 4.0487 - val_acc: 0.0958\n",
      "Epoch 234/250\n",
      " - 2s - loss: 3.9793 - acc: 0.1026 - val_loss: 4.0458 - val_acc: 0.0952\n",
      "Epoch 235/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1022 - val_loss: 4.0466 - val_acc: 0.0961\n",
      "Epoch 236/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1028 - val_loss: 4.0489 - val_acc: 0.0955\n",
      "Epoch 237/250\n",
      " - 2s - loss: 3.9810 - acc: 0.1029 - val_loss: 4.0454 - val_acc: 0.0964\n",
      "Epoch 238/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1033 - val_loss: 4.0450 - val_acc: 0.0947\n",
      "Epoch 239/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1032 - val_loss: 4.0409 - val_acc: 0.0973\n",
      "Epoch 240/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1024 - val_loss: 4.0486 - val_acc: 0.0945\n",
      "Epoch 241/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1033 - val_loss: 4.0443 - val_acc: 0.0959\n",
      "Epoch 242/250\n",
      " - 2s - loss: 3.9824 - acc: 0.1034 - val_loss: 4.0490 - val_acc: 0.0954\n",
      "Epoch 243/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1024 - val_loss: 4.0469 - val_acc: 0.0951\n",
      "Epoch 244/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1030 - val_loss: 4.0523 - val_acc: 0.0958\n",
      "Epoch 245/250\n",
      " - 2s - loss: 3.9800 - acc: 0.1030 - val_loss: 4.0504 - val_acc: 0.0947\n",
      "Epoch 246/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1028 - val_loss: 4.0483 - val_acc: 0.0949\n",
      "Epoch 247/250\n",
      " - 2s - loss: 3.9788 - acc: 0.1022 - val_loss: 4.0490 - val_acc: 0.0952\n",
      "Epoch 248/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1040 - val_loss: 4.0473 - val_acc: 0.0956\n",
      "Epoch 249/250\n",
      " - 2s - loss: 3.9789 - acc: 0.1024 - val_loss: 4.0475 - val_acc: 0.0962\n",
      "Epoch 250/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1031 - val_loss: 4.0486 - val_acc: 0.0952\n",
      "Mini-Train:   6 Test Accuracy: 9.52% Learning Rate: 0.0004167\n",
      "Train on 136770 samples, validate on 15266 samples\n",
      "Epoch 1/250\n",
      " - 2s - loss: 3.9800 - acc: 0.1026 - val_loss: 4.0495 - val_acc: 0.0952\n",
      "Epoch 2/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1030 - val_loss: 4.0462 - val_acc: 0.0959\n",
      "Epoch 3/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1023 - val_loss: 4.0457 - val_acc: 0.0963\n",
      "Epoch 4/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1030 - val_loss: 4.0429 - val_acc: 0.0971\n",
      "Epoch 5/250\n",
      " - 2s - loss: 3.9794 - acc: 0.1033 - val_loss: 4.0448 - val_acc: 0.0973\n",
      "Epoch 6/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1030 - val_loss: 4.0450 - val_acc: 0.0953\n",
      "Epoch 7/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1020 - val_loss: 4.0471 - val_acc: 0.0956\n",
      "Epoch 8/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1031 - val_loss: 4.0462 - val_acc: 0.0958\n",
      "Epoch 9/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1024 - val_loss: 4.0441 - val_acc: 0.0956\n",
      "Epoch 10/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1024 - val_loss: 4.0458 - val_acc: 0.0958\n",
      "Epoch 11/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1033 - val_loss: 4.0591 - val_acc: 0.0932\n",
      "Epoch 12/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1040 - val_loss: 4.0483 - val_acc: 0.0948\n",
      "Epoch 13/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1020 - val_loss: 4.0477 - val_acc: 0.0955\n",
      "Epoch 14/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1029 - val_loss: 4.0463 - val_acc: 0.0965\n",
      "Epoch 15/250\n",
      " - 2s - loss: 3.9821 - acc: 0.1022 - val_loss: 4.0460 - val_acc: 0.0956\n",
      "Epoch 16/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1038 - val_loss: 4.0451 - val_acc: 0.0952\n",
      "Epoch 17/250\n",
      " - 2s - loss: 3.9801 - acc: 0.1025 - val_loss: 4.0490 - val_acc: 0.0962\n",
      "Epoch 18/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1036 - val_loss: 4.0495 - val_acc: 0.0952\n",
      "Epoch 19/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1031 - val_loss: 4.0441 - val_acc: 0.0960\n",
      "Epoch 20/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1036 - val_loss: 4.0529 - val_acc: 0.0945\n",
      "Epoch 21/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1035 - val_loss: 4.0459 - val_acc: 0.0956\n",
      "Epoch 22/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1029 - val_loss: 4.0446 - val_acc: 0.0956\n",
      "Epoch 23/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1032 - val_loss: 4.0475 - val_acc: 0.0971\n",
      "Epoch 24/250\n",
      " - 2s - loss: 3.9788 - acc: 0.1033 - val_loss: 4.0440 - val_acc: 0.0956\n",
      "Epoch 25/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1028 - val_loss: 4.0478 - val_acc: 0.0944\n",
      "Epoch 26/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1029 - val_loss: 4.0471 - val_acc: 0.0958\n",
      "Epoch 27/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1029 - val_loss: 4.0474 - val_acc: 0.0956\n",
      "Epoch 28/250\n",
      " - 2s - loss: 3.9750 - acc: 0.1037 - val_loss: 4.0446 - val_acc: 0.0958\n",
      "Epoch 29/250\n",
      " - 2s - loss: 3.9793 - acc: 0.1027 - val_loss: 4.0452 - val_acc: 0.0953\n",
      "Epoch 30/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1020 - val_loss: 4.0491 - val_acc: 0.0957\n",
      "Epoch 31/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1031 - val_loss: 4.0486 - val_acc: 0.0953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1031 - val_loss: 4.0460 - val_acc: 0.0961\n",
      "Epoch 33/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1027 - val_loss: 4.0461 - val_acc: 0.0947\n",
      "Epoch 34/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1034 - val_loss: 4.0479 - val_acc: 0.0950\n",
      "Epoch 35/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1033 - val_loss: 4.0482 - val_acc: 0.0949\n",
      "Epoch 36/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1035 - val_loss: 4.0449 - val_acc: 0.0962\n",
      "Epoch 37/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1025 - val_loss: 4.0466 - val_acc: 0.0947\n",
      "Epoch 38/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1025 - val_loss: 4.0509 - val_acc: 0.0947\n",
      "Epoch 39/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1029 - val_loss: 4.0497 - val_acc: 0.0943\n",
      "Epoch 40/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1035 - val_loss: 4.0431 - val_acc: 0.0955\n",
      "Epoch 41/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1035 - val_loss: 4.0416 - val_acc: 0.0960\n",
      "Epoch 42/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1029 - val_loss: 4.0494 - val_acc: 0.0942\n",
      "Epoch 43/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1034 - val_loss: 4.0457 - val_acc: 0.0960\n",
      "Epoch 44/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1027 - val_loss: 4.0468 - val_acc: 0.0957\n",
      "Epoch 45/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1037 - val_loss: 4.0469 - val_acc: 0.0957\n",
      "Epoch 46/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1031 - val_loss: 4.0428 - val_acc: 0.0962\n",
      "Epoch 47/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1020 - val_loss: 4.0524 - val_acc: 0.0950\n",
      "Epoch 48/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1033 - val_loss: 4.0434 - val_acc: 0.0960\n",
      "Epoch 49/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1033 - val_loss: 4.0475 - val_acc: 0.0952\n",
      "Epoch 50/250\n",
      " - 2s - loss: 3.9811 - acc: 0.1037 - val_loss: 4.0557 - val_acc: 0.0945\n",
      "Epoch 51/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1025 - val_loss: 4.0436 - val_acc: 0.0951\n",
      "Epoch 52/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1036 - val_loss: 4.0474 - val_acc: 0.0962\n",
      "Epoch 53/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1044 - val_loss: 4.0473 - val_acc: 0.0958\n",
      "Epoch 54/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1032 - val_loss: 4.0419 - val_acc: 0.0963\n",
      "Epoch 55/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1038 - val_loss: 4.0441 - val_acc: 0.0964\n",
      "Epoch 56/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1028 - val_loss: 4.0454 - val_acc: 0.0956\n",
      "Epoch 57/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1027 - val_loss: 4.0447 - val_acc: 0.0955\n",
      "Epoch 58/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1036 - val_loss: 4.0474 - val_acc: 0.0958\n",
      "Epoch 59/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1029 - val_loss: 4.0466 - val_acc: 0.0956\n",
      "Epoch 60/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1031 - val_loss: 4.0565 - val_acc: 0.0939\n",
      "Epoch 61/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1034 - val_loss: 4.0482 - val_acc: 0.0959\n",
      "Epoch 62/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1026 - val_loss: 4.0500 - val_acc: 0.0949\n",
      "Epoch 63/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1034 - val_loss: 4.0446 - val_acc: 0.0959\n",
      "Epoch 64/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1036 - val_loss: 4.0457 - val_acc: 0.0952\n",
      "Epoch 65/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1024 - val_loss: 4.0466 - val_acc: 0.0962\n",
      "Epoch 66/250\n",
      " - 2s - loss: 3.9793 - acc: 0.1032 - val_loss: 4.0467 - val_acc: 0.0958\n",
      "Epoch 67/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1032 - val_loss: 4.0441 - val_acc: 0.0960\n",
      "Epoch 68/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1034 - val_loss: 4.0458 - val_acc: 0.0959\n",
      "Epoch 69/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1027 - val_loss: 4.0438 - val_acc: 0.0962\n",
      "Epoch 70/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1047 - val_loss: 4.0463 - val_acc: 0.0958\n",
      "Epoch 71/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1030 - val_loss: 4.0468 - val_acc: 0.0959\n",
      "Epoch 72/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1035 - val_loss: 4.0477 - val_acc: 0.0959\n",
      "Epoch 73/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1038 - val_loss: 4.0453 - val_acc: 0.0955\n",
      "Epoch 74/250\n",
      " - 2s - loss: 3.9822 - acc: 0.1023 - val_loss: 4.0438 - val_acc: 0.0954\n",
      "Epoch 75/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1030 - val_loss: 4.0431 - val_acc: 0.0958\n",
      "Epoch 76/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1027 - val_loss: 4.0436 - val_acc: 0.0957\n",
      "Epoch 77/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1032 - val_loss: 4.0435 - val_acc: 0.0964\n",
      "Epoch 78/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1036 - val_loss: 4.0469 - val_acc: 0.0962\n",
      "Epoch 79/250\n",
      " - 2s - loss: 3.9794 - acc: 0.1027 - val_loss: 4.0464 - val_acc: 0.0962\n",
      "Epoch 80/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1040 - val_loss: 4.0452 - val_acc: 0.0956\n",
      "Epoch 81/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1036 - val_loss: 4.0469 - val_acc: 0.0951\n",
      "Epoch 82/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1024 - val_loss: 4.0507 - val_acc: 0.0958\n",
      "Epoch 83/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1030 - val_loss: 4.0422 - val_acc: 0.0959\n",
      "Epoch 84/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1038 - val_loss: 4.0466 - val_acc: 0.0955\n",
      "Epoch 85/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1045 - val_loss: 4.0426 - val_acc: 0.0962\n",
      "Epoch 86/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1026 - val_loss: 4.0464 - val_acc: 0.0965\n",
      "Epoch 87/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1035 - val_loss: 4.0431 - val_acc: 0.0958\n",
      "Epoch 88/250\n",
      " - 2s - loss: 3.9808 - acc: 0.1025 - val_loss: 4.0502 - val_acc: 0.0958\n",
      "Epoch 89/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1033 - val_loss: 4.0471 - val_acc: 0.0956\n",
      "Epoch 90/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1028 - val_loss: 4.0462 - val_acc: 0.0959\n",
      "Epoch 91/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1024 - val_loss: 4.0421 - val_acc: 0.0957\n",
      "Epoch 92/250\n",
      " - 2s - loss: 3.9801 - acc: 0.1031 - val_loss: 4.0464 - val_acc: 0.0955\n",
      "Epoch 93/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1032 - val_loss: 4.0467 - val_acc: 0.0968\n",
      "Epoch 94/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1040 - val_loss: 4.0393 - val_acc: 0.0964\n",
      "Epoch 95/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1037 - val_loss: 4.0417 - val_acc: 0.0959\n",
      "Epoch 96/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1039 - val_loss: 4.0463 - val_acc: 0.0953\n",
      "Epoch 97/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1025 - val_loss: 4.0479 - val_acc: 0.0949\n",
      "Epoch 98/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1030 - val_loss: 4.0432 - val_acc: 0.0964\n",
      "Epoch 99/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1033 - val_loss: 4.0438 - val_acc: 0.0960\n",
      "Epoch 100/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1028 - val_loss: 4.0489 - val_acc: 0.0952\n",
      "Epoch 101/250\n",
      " - 2s - loss: 3.9793 - acc: 0.1034 - val_loss: 4.0486 - val_acc: 0.0954\n",
      "Epoch 102/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1030 - val_loss: 4.0495 - val_acc: 0.0954\n",
      "Epoch 103/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1033 - val_loss: 4.0455 - val_acc: 0.0964\n",
      "Epoch 104/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1027 - val_loss: 4.0443 - val_acc: 0.0971\n",
      "Epoch 105/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1031 - val_loss: 4.0422 - val_acc: 0.0960\n",
      "Epoch 106/250\n",
      " - 2s - loss: 3.9788 - acc: 0.1035 - val_loss: 4.0423 - val_acc: 0.0966\n",
      "Epoch 107/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1039 - val_loss: 4.0435 - val_acc: 0.0956\n",
      "Epoch 108/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1026 - val_loss: 4.0437 - val_acc: 0.0959\n",
      "Epoch 109/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1030 - val_loss: 4.0442 - val_acc: 0.0966\n",
      "Epoch 110/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1022 - val_loss: 4.0499 - val_acc: 0.0952\n",
      "Epoch 111/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1030 - val_loss: 4.0437 - val_acc: 0.0969\n",
      "Epoch 112/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1026 - val_loss: 4.0452 - val_acc: 0.0956\n",
      "Epoch 113/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1026 - val_loss: 4.0456 - val_acc: 0.0955\n",
      "Epoch 114/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1026 - val_loss: 4.0424 - val_acc: 0.0962\n",
      "Epoch 115/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1021 - val_loss: 4.0479 - val_acc: 0.0956\n",
      "Epoch 116/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1025 - val_loss: 4.0430 - val_acc: 0.0960\n",
      "Epoch 117/250\n",
      " - 2s - loss: 3.9788 - acc: 0.1031 - val_loss: 4.0462 - val_acc: 0.0952\n",
      "Epoch 118/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1039 - val_loss: 4.0462 - val_acc: 0.0959\n",
      "Epoch 119/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1035 - val_loss: 4.0463 - val_acc: 0.0950\n",
      "Epoch 120/250\n",
      " - 2s - loss: 3.9793 - acc: 0.1031 - val_loss: 4.0448 - val_acc: 0.0954\n",
      "Epoch 121/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1028 - val_loss: 4.0465 - val_acc: 0.0962\n",
      "Epoch 122/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1032 - val_loss: 4.0471 - val_acc: 0.0956\n",
      "Epoch 123/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1034 - val_loss: 4.0462 - val_acc: 0.0958\n",
      "Epoch 124/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1027 - val_loss: 4.0452 - val_acc: 0.0964\n",
      "Epoch 125/250\n",
      " - 2s - loss: 3.9788 - acc: 0.1029 - val_loss: 4.0488 - val_acc: 0.0956\n",
      "Epoch 126/250\n",
      " - 2s - loss: 3.9789 - acc: 0.1036 - val_loss: 4.0450 - val_acc: 0.0966\n",
      "Epoch 127/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1031 - val_loss: 4.0465 - val_acc: 0.0960\n",
      "Epoch 128/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 3.9816 - acc: 0.1025 - val_loss: 4.0453 - val_acc: 0.0952\n",
      "Epoch 129/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1030 - val_loss: 4.0444 - val_acc: 0.0948\n",
      "Epoch 130/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1028 - val_loss: 4.0474 - val_acc: 0.0957\n",
      "Epoch 131/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1031 - val_loss: 4.0457 - val_acc: 0.0964\n",
      "Epoch 132/250\n",
      " - 2s - loss: 3.9794 - acc: 0.1033 - val_loss: 4.0480 - val_acc: 0.0960\n",
      "Epoch 133/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1038 - val_loss: 4.0430 - val_acc: 0.0962\n",
      "Epoch 134/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1035 - val_loss: 4.0491 - val_acc: 0.0957\n",
      "Epoch 135/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1033 - val_loss: 4.0445 - val_acc: 0.0959\n",
      "Epoch 136/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1037 - val_loss: 4.0442 - val_acc: 0.0958\n",
      "Epoch 137/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1034 - val_loss: 4.0433 - val_acc: 0.0954\n",
      "Epoch 138/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1038 - val_loss: 4.0500 - val_acc: 0.0952\n",
      "Epoch 139/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1030 - val_loss: 4.0448 - val_acc: 0.0959\n",
      "Epoch 140/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1035 - val_loss: 4.0444 - val_acc: 0.0962\n",
      "Epoch 141/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1035 - val_loss: 4.0482 - val_acc: 0.0960\n",
      "Epoch 142/250\n",
      " - 2s - loss: 3.9801 - acc: 0.1031 - val_loss: 4.0472 - val_acc: 0.0954\n",
      "Epoch 143/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1032 - val_loss: 4.0472 - val_acc: 0.0967\n",
      "Epoch 144/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1034 - val_loss: 4.0494 - val_acc: 0.0954\n",
      "Epoch 145/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1029 - val_loss: 4.0443 - val_acc: 0.0962\n",
      "Epoch 146/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1034 - val_loss: 4.0441 - val_acc: 0.0965\n",
      "Epoch 147/250\n",
      " - 2s - loss: 3.9808 - acc: 0.1030 - val_loss: 4.0429 - val_acc: 0.0958\n",
      "Epoch 148/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1027 - val_loss: 4.0423 - val_acc: 0.0954\n",
      "Epoch 149/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1034 - val_loss: 4.0461 - val_acc: 0.0963\n",
      "Epoch 150/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1044 - val_loss: 4.0498 - val_acc: 0.0954\n",
      "Epoch 151/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1026 - val_loss: 4.0508 - val_acc: 0.0944\n",
      "Epoch 152/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1039 - val_loss: 4.0508 - val_acc: 0.0956\n",
      "Epoch 153/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1037 - val_loss: 4.0486 - val_acc: 0.0964\n",
      "Epoch 154/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1037 - val_loss: 4.0496 - val_acc: 0.0945\n",
      "Epoch 155/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1026 - val_loss: 4.0434 - val_acc: 0.0968\n",
      "Epoch 156/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1034 - val_loss: 4.0458 - val_acc: 0.0962\n",
      "Epoch 157/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1014 - val_loss: 4.0511 - val_acc: 0.0950\n",
      "Epoch 158/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1020 - val_loss: 4.0464 - val_acc: 0.0955\n",
      "Epoch 159/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1034 - val_loss: 4.0458 - val_acc: 0.0955\n",
      "Epoch 160/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1030 - val_loss: 4.0445 - val_acc: 0.0962\n",
      "Epoch 161/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1036 - val_loss: 4.0443 - val_acc: 0.0960\n",
      "Epoch 162/250\n",
      " - 2s - loss: 3.9807 - acc: 0.1025 - val_loss: 4.0478 - val_acc: 0.0958\n",
      "Epoch 163/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1034 - val_loss: 4.0464 - val_acc: 0.0954\n",
      "Epoch 164/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1024 - val_loss: 4.0458 - val_acc: 0.0961\n",
      "Epoch 165/250\n",
      " - 2s - loss: 3.9809 - acc: 0.1019 - val_loss: 4.0436 - val_acc: 0.0961\n",
      "Epoch 166/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1029 - val_loss: 4.0454 - val_acc: 0.0971\n",
      "Epoch 167/250\n",
      " - 2s - loss: 3.9798 - acc: 0.1035 - val_loss: 4.0430 - val_acc: 0.0962\n",
      "Epoch 168/250\n",
      " - 2s - loss: 3.9801 - acc: 0.1035 - val_loss: 4.0451 - val_acc: 0.0965\n",
      "Epoch 169/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1031 - val_loss: 4.0442 - val_acc: 0.0964\n",
      "Epoch 170/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1038 - val_loss: 4.0480 - val_acc: 0.0949\n",
      "Epoch 171/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1030 - val_loss: 4.0565 - val_acc: 0.0943\n",
      "Epoch 172/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1040 - val_loss: 4.0411 - val_acc: 0.0970\n",
      "Epoch 173/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1030 - val_loss: 4.0450 - val_acc: 0.0957\n",
      "Epoch 174/250\n",
      " - 2s - loss: 3.9813 - acc: 0.1024 - val_loss: 4.0445 - val_acc: 0.0961\n",
      "Epoch 175/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1039 - val_loss: 4.0457 - val_acc: 0.0952\n",
      "Epoch 176/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1038 - val_loss: 4.0433 - val_acc: 0.0958\n",
      "Epoch 177/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1038 - val_loss: 4.0420 - val_acc: 0.0967\n",
      "Epoch 178/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1030 - val_loss: 4.0474 - val_acc: 0.0964\n",
      "Epoch 179/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1030 - val_loss: 4.0462 - val_acc: 0.0959\n",
      "Epoch 180/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1032 - val_loss: 4.0463 - val_acc: 0.0958\n",
      "Epoch 181/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1029 - val_loss: 4.0463 - val_acc: 0.0962\n",
      "Epoch 182/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1029 - val_loss: 4.0415 - val_acc: 0.0965\n",
      "Epoch 183/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1023 - val_loss: 4.0505 - val_acc: 0.0951\n",
      "Epoch 184/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1030 - val_loss: 4.0515 - val_acc: 0.0949\n",
      "Epoch 185/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1039 - val_loss: 4.0410 - val_acc: 0.0968\n",
      "Epoch 186/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1032 - val_loss: 4.0513 - val_acc: 0.0952\n",
      "Epoch 187/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1030 - val_loss: 4.0439 - val_acc: 0.0968\n",
      "Epoch 188/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1020 - val_loss: 4.0445 - val_acc: 0.0968\n",
      "Epoch 189/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1024 - val_loss: 4.0415 - val_acc: 0.0959\n",
      "Epoch 190/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1031 - val_loss: 4.0462 - val_acc: 0.0958\n",
      "Epoch 191/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1038 - val_loss: 4.0495 - val_acc: 0.0955\n",
      "Epoch 192/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1038 - val_loss: 4.0452 - val_acc: 0.0963\n",
      "Epoch 193/250\n",
      " - 2s - loss: 3.9788 - acc: 0.1044 - val_loss: 4.0425 - val_acc: 0.0966\n",
      "Epoch 194/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1033 - val_loss: 4.0423 - val_acc: 0.0963\n",
      "Epoch 195/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1036 - val_loss: 4.0434 - val_acc: 0.0962\n",
      "Epoch 196/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1031 - val_loss: 4.0456 - val_acc: 0.0964\n",
      "Epoch 197/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1032 - val_loss: 4.0478 - val_acc: 0.0962\n",
      "Epoch 198/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1027 - val_loss: 4.0509 - val_acc: 0.0959\n",
      "Epoch 199/250\n",
      " - 2s - loss: 3.9817 - acc: 0.1021 - val_loss: 4.0445 - val_acc: 0.0963\n",
      "Epoch 200/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1031 - val_loss: 4.0489 - val_acc: 0.0956\n",
      "Epoch 201/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1035 - val_loss: 4.0446 - val_acc: 0.0962\n",
      "Epoch 202/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1032 - val_loss: 4.0461 - val_acc: 0.0958\n",
      "Epoch 203/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1039 - val_loss: 4.0453 - val_acc: 0.0952\n",
      "Epoch 204/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1026 - val_loss: 4.0451 - val_acc: 0.0955\n",
      "Epoch 205/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1022 - val_loss: 4.0459 - val_acc: 0.0960\n",
      "Epoch 206/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1022 - val_loss: 4.0466 - val_acc: 0.0965\n",
      "Epoch 207/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1035 - val_loss: 4.0486 - val_acc: 0.0958\n",
      "Epoch 208/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1036 - val_loss: 4.0515 - val_acc: 0.0952\n",
      "Epoch 209/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1040 - val_loss: 4.0460 - val_acc: 0.0952\n",
      "Epoch 210/250\n",
      " - 2s - loss: 3.9793 - acc: 0.1028 - val_loss: 4.0427 - val_acc: 0.0971\n",
      "Epoch 211/250\n",
      " - 2s - loss: 3.9789 - acc: 0.1034 - val_loss: 4.0494 - val_acc: 0.0960\n",
      "Epoch 212/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1026 - val_loss: 4.0525 - val_acc: 0.0945\n",
      "Epoch 213/250\n",
      " - 2s - loss: 3.9794 - acc: 0.1024 - val_loss: 4.0451 - val_acc: 0.0970\n",
      "Epoch 214/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1045 - val_loss: 4.0472 - val_acc: 0.0949\n",
      "Epoch 215/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1026 - val_loss: 4.0506 - val_acc: 0.0950\n",
      "Epoch 216/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1037 - val_loss: 4.0505 - val_acc: 0.0952\n",
      "Epoch 217/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1035 - val_loss: 4.0442 - val_acc: 0.0953\n",
      "Epoch 218/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1030 - val_loss: 4.0434 - val_acc: 0.0958\n",
      "Epoch 219/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1039 - val_loss: 4.0425 - val_acc: 0.0962\n",
      "Epoch 220/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1032 - val_loss: 4.0409 - val_acc: 0.0964\n",
      "Epoch 221/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1030 - val_loss: 4.0460 - val_acc: 0.0971\n",
      "Epoch 222/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1042 - val_loss: 4.0505 - val_acc: 0.0951\n",
      "Epoch 223/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1033 - val_loss: 4.0449 - val_acc: 0.0964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1031 - val_loss: 4.0476 - val_acc: 0.0947\n",
      "Epoch 225/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1029 - val_loss: 4.0468 - val_acc: 0.0960\n",
      "Epoch 226/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1036 - val_loss: 4.0493 - val_acc: 0.0945\n",
      "Epoch 227/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1027 - val_loss: 4.0459 - val_acc: 0.0966\n",
      "Epoch 228/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1037 - val_loss: 4.0485 - val_acc: 0.0952\n",
      "Epoch 229/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1030 - val_loss: 4.0433 - val_acc: 0.0961\n",
      "Epoch 230/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1028 - val_loss: 4.0483 - val_acc: 0.0951\n",
      "Epoch 231/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1033 - val_loss: 4.0474 - val_acc: 0.0959\n",
      "Epoch 232/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1040 - val_loss: 4.0474 - val_acc: 0.0959\n",
      "Epoch 233/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1029 - val_loss: 4.0444 - val_acc: 0.0962\n",
      "Epoch 234/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1039 - val_loss: 4.0433 - val_acc: 0.0961\n",
      "Epoch 235/250\n",
      " - 2s - loss: 3.9804 - acc: 0.1035 - val_loss: 4.0435 - val_acc: 0.0963\n",
      "Epoch 236/250\n",
      " - 2s - loss: 3.9788 - acc: 0.1032 - val_loss: 4.0468 - val_acc: 0.0957\n",
      "Epoch 237/250\n",
      " - 2s - loss: 3.9802 - acc: 0.1026 - val_loss: 4.0420 - val_acc: 0.0960\n",
      "Epoch 238/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1027 - val_loss: 4.0469 - val_acc: 0.0952\n",
      "Epoch 239/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1032 - val_loss: 4.0420 - val_acc: 0.0962\n",
      "Epoch 240/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1036 - val_loss: 4.0460 - val_acc: 0.0968\n",
      "Epoch 241/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1035 - val_loss: 4.0458 - val_acc: 0.0952\n",
      "Epoch 242/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1036 - val_loss: 4.0448 - val_acc: 0.0952\n",
      "Epoch 243/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1033 - val_loss: 4.0469 - val_acc: 0.0953\n",
      "Epoch 244/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1033 - val_loss: 4.0507 - val_acc: 0.0947\n",
      "Epoch 245/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1030 - val_loss: 4.0436 - val_acc: 0.0969\n",
      "Epoch 246/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1032 - val_loss: 4.0472 - val_acc: 0.0954\n",
      "Epoch 247/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1030 - val_loss: 4.0423 - val_acc: 0.0969\n",
      "Epoch 248/250\n",
      " - 2s - loss: 3.9806 - acc: 0.1025 - val_loss: 4.0480 - val_acc: 0.0958\n",
      "Epoch 249/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1025 - val_loss: 4.0437 - val_acc: 0.0975\n",
      "Epoch 250/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1029 - val_loss: 4.0431 - val_acc: 0.0957\n",
      "Mini-Train:   7 Test Accuracy: 9.57% Learning Rate: 0.0003571\n",
      "Train on 136770 samples, validate on 15266 samples\n",
      "Epoch 1/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1035 - val_loss: 4.0412 - val_acc: 0.0956\n",
      "Epoch 2/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1041 - val_loss: 4.0489 - val_acc: 0.0957\n",
      "Epoch 3/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1026 - val_loss: 4.0437 - val_acc: 0.0960\n",
      "Epoch 4/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1030 - val_loss: 4.0486 - val_acc: 0.0954\n",
      "Epoch 5/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1040 - val_loss: 4.0468 - val_acc: 0.0956\n",
      "Epoch 6/250\n",
      " - 2s - loss: 3.9793 - acc: 0.1037 - val_loss: 4.0407 - val_acc: 0.0967\n",
      "Epoch 7/250\n",
      " - 2s - loss: 3.9808 - acc: 0.1021 - val_loss: 4.0451 - val_acc: 0.0966\n",
      "Epoch 8/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1040 - val_loss: 4.0434 - val_acc: 0.0965\n",
      "Epoch 9/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1033 - val_loss: 4.0426 - val_acc: 0.0969\n",
      "Epoch 10/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1033 - val_loss: 4.0478 - val_acc: 0.0960\n",
      "Epoch 11/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1028 - val_loss: 4.0485 - val_acc: 0.0958\n",
      "Epoch 12/250\n",
      " - 2s - loss: 3.9803 - acc: 0.1030 - val_loss: 4.0461 - val_acc: 0.0956\n",
      "Epoch 13/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1041 - val_loss: 4.0447 - val_acc: 0.0964\n",
      "Epoch 14/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1036 - val_loss: 4.0466 - val_acc: 0.0956\n",
      "Epoch 15/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1033 - val_loss: 4.0436 - val_acc: 0.0961\n",
      "Epoch 16/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1023 - val_loss: 4.0506 - val_acc: 0.0951\n",
      "Epoch 17/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1041 - val_loss: 4.0416 - val_acc: 0.0967\n",
      "Epoch 18/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1039 - val_loss: 4.0426 - val_acc: 0.0961\n",
      "Epoch 19/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1031 - val_loss: 4.0441 - val_acc: 0.0962\n",
      "Epoch 20/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1029 - val_loss: 4.0457 - val_acc: 0.0958\n",
      "Epoch 21/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1029 - val_loss: 4.0454 - val_acc: 0.0957\n",
      "Epoch 22/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1031 - val_loss: 4.0481 - val_acc: 0.0954\n",
      "Epoch 23/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1036 - val_loss: 4.0465 - val_acc: 0.0956\n",
      "Epoch 24/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1031 - val_loss: 4.0439 - val_acc: 0.0964\n",
      "Epoch 25/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1033 - val_loss: 4.0472 - val_acc: 0.0952\n",
      "Epoch 26/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1032 - val_loss: 4.0455 - val_acc: 0.0959\n",
      "Epoch 27/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1031 - val_loss: 4.0450 - val_acc: 0.0963\n",
      "Epoch 28/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1035 - val_loss: 4.0420 - val_acc: 0.0961\n",
      "Epoch 29/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1031 - val_loss: 4.0443 - val_acc: 0.0964\n",
      "Epoch 30/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1025 - val_loss: 4.0490 - val_acc: 0.0946\n",
      "Epoch 31/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1032 - val_loss: 4.0457 - val_acc: 0.0956\n",
      "Epoch 32/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1030 - val_loss: 4.0453 - val_acc: 0.0958\n",
      "Epoch 33/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1028 - val_loss: 4.0426 - val_acc: 0.0966\n",
      "Epoch 34/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1025 - val_loss: 4.0487 - val_acc: 0.0949\n",
      "Epoch 35/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1033 - val_loss: 4.0442 - val_acc: 0.0958\n",
      "Epoch 36/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1032 - val_loss: 4.0438 - val_acc: 0.0957\n",
      "Epoch 37/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1029 - val_loss: 4.0421 - val_acc: 0.0955\n",
      "Epoch 38/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1033 - val_loss: 4.0448 - val_acc: 0.0962\n",
      "Epoch 39/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1030 - val_loss: 4.0397 - val_acc: 0.0954\n",
      "Epoch 40/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1041 - val_loss: 4.0412 - val_acc: 0.0958\n",
      "Epoch 41/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1037 - val_loss: 4.0436 - val_acc: 0.0959\n",
      "Epoch 42/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1044 - val_loss: 4.0428 - val_acc: 0.0954\n",
      "Epoch 43/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1038 - val_loss: 4.0424 - val_acc: 0.0962\n",
      "Epoch 44/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1034 - val_loss: 4.0407 - val_acc: 0.0962\n",
      "Epoch 45/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1039 - val_loss: 4.0461 - val_acc: 0.0959\n",
      "Epoch 46/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1029 - val_loss: 4.0430 - val_acc: 0.0958\n",
      "Epoch 47/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1035 - val_loss: 4.0446 - val_acc: 0.0955\n",
      "Epoch 48/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1033 - val_loss: 4.0417 - val_acc: 0.0966\n",
      "Epoch 49/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1029 - val_loss: 4.0437 - val_acc: 0.0958\n",
      "Epoch 50/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1031 - val_loss: 4.0435 - val_acc: 0.0960\n",
      "Epoch 51/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1033 - val_loss: 4.0467 - val_acc: 0.0960\n",
      "Epoch 52/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1036 - val_loss: 4.0466 - val_acc: 0.0968\n",
      "Epoch 53/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1032 - val_loss: 4.0413 - val_acc: 0.0962\n",
      "Epoch 54/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1030 - val_loss: 4.0464 - val_acc: 0.0962\n",
      "Epoch 55/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1029 - val_loss: 4.0449 - val_acc: 0.0956\n",
      "Epoch 56/250\n",
      " - 2s - loss: 3.9750 - acc: 0.1043 - val_loss: 4.0431 - val_acc: 0.0960\n",
      "Epoch 57/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1037 - val_loss: 4.0424 - val_acc: 0.0966\n",
      "Epoch 58/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1028 - val_loss: 4.0419 - val_acc: 0.0966\n",
      "Epoch 59/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1031 - val_loss: 4.0457 - val_acc: 0.0962\n",
      "Epoch 60/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1032 - val_loss: 4.0436 - val_acc: 0.0962\n",
      "Epoch 61/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1039 - val_loss: 4.0469 - val_acc: 0.0960\n",
      "Epoch 62/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1044 - val_loss: 4.0488 - val_acc: 0.0952\n",
      "Epoch 63/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1026 - val_loss: 4.0462 - val_acc: 0.0952\n",
      "Epoch 64/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1031 - val_loss: 4.0426 - val_acc: 0.0971\n",
      "Epoch 65/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1025 - val_loss: 4.0438 - val_acc: 0.0964\n",
      "Epoch 66/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1026 - val_loss: 4.0444 - val_acc: 0.0959\n",
      "Epoch 67/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1036 - val_loss: 4.0428 - val_acc: 0.0965\n",
      "Epoch 68/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1030 - val_loss: 4.0444 - val_acc: 0.0962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1039 - val_loss: 4.0446 - val_acc: 0.0960\n",
      "Epoch 70/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1033 - val_loss: 4.0398 - val_acc: 0.0965\n",
      "Epoch 71/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1033 - val_loss: 4.0398 - val_acc: 0.0962\n",
      "Epoch 72/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1039 - val_loss: 4.0444 - val_acc: 0.0960\n",
      "Epoch 73/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1034 - val_loss: 4.0438 - val_acc: 0.0958\n",
      "Epoch 74/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1038 - val_loss: 4.0488 - val_acc: 0.0952\n",
      "Epoch 75/250\n",
      " - 2s - loss: 3.9792 - acc: 0.1026 - val_loss: 4.0452 - val_acc: 0.0956\n",
      "Epoch 76/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1029 - val_loss: 4.0451 - val_acc: 0.0958\n",
      "Epoch 77/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1043 - val_loss: 4.0415 - val_acc: 0.0967\n",
      "Epoch 78/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1031 - val_loss: 4.0425 - val_acc: 0.0964\n",
      "Epoch 79/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1032 - val_loss: 4.0513 - val_acc: 0.0944\n",
      "Epoch 80/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1040 - val_loss: 4.0463 - val_acc: 0.0968\n",
      "Epoch 81/250\n",
      " - 2s - loss: 3.9789 - acc: 0.1022 - val_loss: 4.0462 - val_acc: 0.0958\n",
      "Epoch 82/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1034 - val_loss: 4.0451 - val_acc: 0.0967\n",
      "Epoch 83/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1034 - val_loss: 4.0437 - val_acc: 0.0958\n",
      "Epoch 84/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1032 - val_loss: 4.0455 - val_acc: 0.0956\n",
      "Epoch 85/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1030 - val_loss: 4.0450 - val_acc: 0.0961\n",
      "Epoch 86/250\n",
      " - 2s - loss: 3.9797 - acc: 0.1030 - val_loss: 4.0459 - val_acc: 0.0955\n",
      "Epoch 87/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1042 - val_loss: 4.0425 - val_acc: 0.0958\n",
      "Epoch 88/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1035 - val_loss: 4.0424 - val_acc: 0.0966\n",
      "Epoch 89/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1036 - val_loss: 4.0466 - val_acc: 0.0964\n",
      "Epoch 90/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1024 - val_loss: 4.0449 - val_acc: 0.0954\n",
      "Epoch 91/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1044 - val_loss: 4.0443 - val_acc: 0.0961\n",
      "Epoch 92/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1033 - val_loss: 4.0421 - val_acc: 0.0964\n",
      "Epoch 93/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1025 - val_loss: 4.0462 - val_acc: 0.0964\n",
      "Epoch 94/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1041 - val_loss: 4.0442 - val_acc: 0.0967\n",
      "Epoch 95/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1026 - val_loss: 4.0448 - val_acc: 0.0965\n",
      "Epoch 96/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1032 - val_loss: 4.0474 - val_acc: 0.0951\n",
      "Epoch 97/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1034 - val_loss: 4.0447 - val_acc: 0.0964\n",
      "Epoch 98/250\n",
      " - 2s - loss: 3.9789 - acc: 0.1031 - val_loss: 4.0476 - val_acc: 0.0954\n",
      "Epoch 99/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1035 - val_loss: 4.0462 - val_acc: 0.0959\n",
      "Epoch 100/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1043 - val_loss: 4.0436 - val_acc: 0.0957\n",
      "Epoch 101/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1036 - val_loss: 4.0427 - val_acc: 0.0960\n",
      "Epoch 102/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1034 - val_loss: 4.0481 - val_acc: 0.0958\n",
      "Epoch 103/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1036 - val_loss: 4.0423 - val_acc: 0.0966\n",
      "Epoch 104/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1036 - val_loss: 4.0459 - val_acc: 0.0958\n",
      "Epoch 105/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1029 - val_loss: 4.0482 - val_acc: 0.0962\n",
      "Epoch 106/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1036 - val_loss: 4.0445 - val_acc: 0.0958\n",
      "Epoch 107/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1032 - val_loss: 4.0484 - val_acc: 0.0958\n",
      "Epoch 108/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1027 - val_loss: 4.0441 - val_acc: 0.0955\n",
      "Epoch 109/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1025 - val_loss: 4.0464 - val_acc: 0.0962\n",
      "Epoch 110/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1025 - val_loss: 4.0484 - val_acc: 0.0953\n",
      "Epoch 111/250\n",
      " - 2s - loss: 3.9754 - acc: 0.1035 - val_loss: 4.0448 - val_acc: 0.0955\n",
      "Epoch 112/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1035 - val_loss: 4.0426 - val_acc: 0.0964\n",
      "Epoch 113/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1036 - val_loss: 4.0416 - val_acc: 0.0968\n",
      "Epoch 114/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1037 - val_loss: 4.0409 - val_acc: 0.0973\n",
      "Epoch 115/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1035 - val_loss: 4.0453 - val_acc: 0.0968\n",
      "Epoch 116/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1035 - val_loss: 4.0429 - val_acc: 0.0957\n",
      "Epoch 117/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1033 - val_loss: 4.0468 - val_acc: 0.0958\n",
      "Epoch 118/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1032 - val_loss: 4.0433 - val_acc: 0.0969\n",
      "Epoch 119/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1037 - val_loss: 4.0420 - val_acc: 0.0962\n",
      "Epoch 120/250\n",
      " - 2s - loss: 3.9746 - acc: 0.1035 - val_loss: 4.0421 - val_acc: 0.0958\n",
      "Epoch 121/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1035 - val_loss: 4.0418 - val_acc: 0.0968\n",
      "Epoch 122/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1035 - val_loss: 4.0460 - val_acc: 0.0957\n",
      "Epoch 123/250\n",
      " - 2s - loss: 3.9801 - acc: 0.1030 - val_loss: 4.0452 - val_acc: 0.0956\n",
      "Epoch 124/250\n",
      " - 2s - loss: 3.9793 - acc: 0.1036 - val_loss: 4.0457 - val_acc: 0.0965\n",
      "Epoch 125/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1037 - val_loss: 4.0429 - val_acc: 0.0968\n",
      "Epoch 126/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1032 - val_loss: 4.0423 - val_acc: 0.0960\n",
      "Epoch 127/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1034 - val_loss: 4.0414 - val_acc: 0.0973\n",
      "Epoch 128/250\n",
      " - 2s - loss: 3.9794 - acc: 0.1026 - val_loss: 4.0435 - val_acc: 0.0949\n",
      "Epoch 129/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1042 - val_loss: 4.0420 - val_acc: 0.0961\n",
      "Epoch 130/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1031 - val_loss: 4.0454 - val_acc: 0.0949\n",
      "Epoch 131/250\n",
      " - 2s - loss: 3.9789 - acc: 0.1030 - val_loss: 4.0466 - val_acc: 0.0959\n",
      "Epoch 132/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1032 - val_loss: 4.0445 - val_acc: 0.0964\n",
      "Epoch 133/250\n",
      " - 2s - loss: 3.9753 - acc: 0.1044 - val_loss: 4.0465 - val_acc: 0.0953\n",
      "Epoch 134/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1030 - val_loss: 4.0436 - val_acc: 0.0966\n",
      "Epoch 135/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1035 - val_loss: 4.0479 - val_acc: 0.0952\n",
      "Epoch 136/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1034 - val_loss: 4.0443 - val_acc: 0.0966\n",
      "Epoch 137/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1036 - val_loss: 4.0478 - val_acc: 0.0960\n",
      "Epoch 138/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1036 - val_loss: 4.0486 - val_acc: 0.0950\n",
      "Epoch 139/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1035 - val_loss: 4.0430 - val_acc: 0.0956\n",
      "Epoch 140/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1029 - val_loss: 4.0457 - val_acc: 0.0956\n",
      "Epoch 141/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1037 - val_loss: 4.0439 - val_acc: 0.0958\n",
      "Epoch 142/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1029 - val_loss: 4.0453 - val_acc: 0.0956\n",
      "Epoch 143/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1029 - val_loss: 4.0453 - val_acc: 0.0963\n",
      "Epoch 144/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1038 - val_loss: 4.0426 - val_acc: 0.0966\n",
      "Epoch 145/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1031 - val_loss: 4.0462 - val_acc: 0.0968\n",
      "Epoch 146/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1026 - val_loss: 4.0426 - val_acc: 0.0956\n",
      "Epoch 147/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1034 - val_loss: 4.0472 - val_acc: 0.0950\n",
      "Epoch 148/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1023 - val_loss: 4.0461 - val_acc: 0.0964\n",
      "Epoch 149/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1027 - val_loss: 4.0447 - val_acc: 0.0956\n",
      "Epoch 150/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1038 - val_loss: 4.0449 - val_acc: 0.0968\n",
      "Epoch 151/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1032 - val_loss: 4.0427 - val_acc: 0.0961\n",
      "Epoch 152/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1037 - val_loss: 4.0417 - val_acc: 0.0962\n",
      "Epoch 153/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1039 - val_loss: 4.0438 - val_acc: 0.0958\n",
      "Epoch 154/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1028 - val_loss: 4.0434 - val_acc: 0.0964\n",
      "Epoch 155/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1032 - val_loss: 4.0439 - val_acc: 0.0962\n",
      "Epoch 156/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1039 - val_loss: 4.0423 - val_acc: 0.0960\n",
      "Epoch 157/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1020 - val_loss: 4.0431 - val_acc: 0.0968\n",
      "Epoch 158/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1033 - val_loss: 4.0440 - val_acc: 0.0953\n",
      "Epoch 159/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1027 - val_loss: 4.0441 - val_acc: 0.0958\n",
      "Epoch 160/250\n",
      " - 2s - loss: 3.9805 - acc: 0.1034 - val_loss: 4.0448 - val_acc: 0.0961\n",
      "Epoch 161/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1024 - val_loss: 4.0474 - val_acc: 0.0956\n",
      "Epoch 162/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1034 - val_loss: 4.0403 - val_acc: 0.0964\n",
      "Epoch 163/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1032 - val_loss: 4.0428 - val_acc: 0.0963\n",
      "Epoch 164/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1042 - val_loss: 4.0478 - val_acc: 0.0965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1031 - val_loss: 4.0420 - val_acc: 0.0967\n",
      "Epoch 166/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1035 - val_loss: 4.0467 - val_acc: 0.0956\n",
      "Epoch 167/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1035 - val_loss: 4.0423 - val_acc: 0.0967\n",
      "Epoch 168/250\n",
      " - 2s - loss: 3.9796 - acc: 0.1018 - val_loss: 4.0471 - val_acc: 0.0965\n",
      "Epoch 169/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1040 - val_loss: 4.0449 - val_acc: 0.0954\n",
      "Epoch 170/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1036 - val_loss: 4.0458 - val_acc: 0.0953\n",
      "Epoch 171/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1032 - val_loss: 4.0435 - val_acc: 0.0966\n",
      "Epoch 172/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1034 - val_loss: 4.0441 - val_acc: 0.0966\n",
      "Epoch 173/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1031 - val_loss: 4.0434 - val_acc: 0.0956\n",
      "Epoch 174/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1042 - val_loss: 4.0426 - val_acc: 0.0960\n",
      "Epoch 175/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1021 - val_loss: 4.0424 - val_acc: 0.0971\n",
      "Epoch 176/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1036 - val_loss: 4.0466 - val_acc: 0.0956\n",
      "Epoch 177/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1033 - val_loss: 4.0453 - val_acc: 0.0960\n",
      "Epoch 178/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1034 - val_loss: 4.0493 - val_acc: 0.0962\n",
      "Epoch 179/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1035 - val_loss: 4.0464 - val_acc: 0.0954\n",
      "Epoch 180/250\n",
      " - 2s - loss: 3.9788 - acc: 0.1022 - val_loss: 4.0454 - val_acc: 0.0953\n",
      "Epoch 181/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1034 - val_loss: 4.0442 - val_acc: 0.0956\n",
      "Epoch 182/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1022 - val_loss: 4.0460 - val_acc: 0.0956\n",
      "Epoch 183/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1034 - val_loss: 4.0413 - val_acc: 0.0959\n",
      "Epoch 184/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1040 - val_loss: 4.0461 - val_acc: 0.0962\n",
      "Epoch 185/250\n",
      " - 2s - loss: 3.9739 - acc: 0.1037 - val_loss: 4.0414 - val_acc: 0.0965\n",
      "Epoch 186/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1034 - val_loss: 4.0410 - val_acc: 0.0967\n",
      "Epoch 187/250\n",
      " - 2s - loss: 3.9794 - acc: 0.1032 - val_loss: 4.0470 - val_acc: 0.0959\n",
      "Epoch 188/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1034 - val_loss: 4.0424 - val_acc: 0.0961\n",
      "Epoch 189/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1042 - val_loss: 4.0448 - val_acc: 0.0965\n",
      "Epoch 190/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1036 - val_loss: 4.0428 - val_acc: 0.0958\n",
      "Epoch 191/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1035 - val_loss: 4.0431 - val_acc: 0.0960\n",
      "Epoch 192/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1028 - val_loss: 4.0451 - val_acc: 0.0951\n",
      "Epoch 193/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1031 - val_loss: 4.0501 - val_acc: 0.0951\n",
      "Epoch 194/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1044 - val_loss: 4.0428 - val_acc: 0.0963\n",
      "Epoch 195/250\n",
      " - 2s - loss: 3.9746 - acc: 0.1034 - val_loss: 4.0438 - val_acc: 0.0962\n",
      "Epoch 196/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1040 - val_loss: 4.0431 - val_acc: 0.0956\n",
      "Epoch 197/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1033 - val_loss: 4.0474 - val_acc: 0.0962\n",
      "Epoch 198/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1035 - val_loss: 4.0450 - val_acc: 0.0956\n",
      "Epoch 199/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1035 - val_loss: 4.0416 - val_acc: 0.0961\n",
      "Epoch 200/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1032 - val_loss: 4.0451 - val_acc: 0.0958\n",
      "Epoch 201/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1039 - val_loss: 4.0514 - val_acc: 0.0948\n",
      "Epoch 202/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1037 - val_loss: 4.0455 - val_acc: 0.0955\n",
      "Epoch 203/250\n",
      " - 2s - loss: 3.9790 - acc: 0.1024 - val_loss: 4.0484 - val_acc: 0.0957\n",
      "Epoch 204/250\n",
      " - 2s - loss: 3.9750 - acc: 0.1036 - val_loss: 4.0449 - val_acc: 0.0954\n",
      "Epoch 205/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1037 - val_loss: 4.0415 - val_acc: 0.0960\n",
      "Epoch 206/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1029 - val_loss: 4.0449 - val_acc: 0.0963\n",
      "Epoch 207/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1033 - val_loss: 4.0488 - val_acc: 0.0956\n",
      "Epoch 208/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1029 - val_loss: 4.0425 - val_acc: 0.0973\n",
      "Epoch 209/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1037 - val_loss: 4.0447 - val_acc: 0.0954\n",
      "Epoch 210/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1034 - val_loss: 4.0423 - val_acc: 0.0960\n",
      "Epoch 211/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1036 - val_loss: 4.0419 - val_acc: 0.0958\n",
      "Epoch 212/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1028 - val_loss: 4.0468 - val_acc: 0.0958\n",
      "Epoch 213/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1034 - val_loss: 4.0462 - val_acc: 0.0964\n",
      "Epoch 214/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1038 - val_loss: 4.0459 - val_acc: 0.0961\n",
      "Epoch 215/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1036 - val_loss: 4.0440 - val_acc: 0.0957\n",
      "Epoch 216/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1035 - val_loss: 4.0459 - val_acc: 0.0962\n",
      "Epoch 217/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1035 - val_loss: 4.0450 - val_acc: 0.0964\n",
      "Epoch 218/250\n",
      " - 2s - loss: 3.9744 - acc: 0.1033 - val_loss: 4.0448 - val_acc: 0.0962\n",
      "Epoch 219/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1031 - val_loss: 4.0470 - val_acc: 0.0954\n",
      "Epoch 220/250\n",
      " - 2s - loss: 3.9742 - acc: 0.1034 - val_loss: 4.0454 - val_acc: 0.0950\n",
      "Epoch 221/250\n",
      " - 2s - loss: 3.9795 - acc: 0.1033 - val_loss: 4.0451 - val_acc: 0.0956\n",
      "Epoch 222/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1038 - val_loss: 4.0436 - val_acc: 0.0969\n",
      "Epoch 223/250\n",
      " - 2s - loss: 3.9786 - acc: 0.1030 - val_loss: 4.0496 - val_acc: 0.0949\n",
      "Epoch 224/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1042 - val_loss: 4.0441 - val_acc: 0.0960\n",
      "Epoch 225/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1035 - val_loss: 4.0460 - val_acc: 0.0953\n",
      "Epoch 226/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1038 - val_loss: 4.0418 - val_acc: 0.0956\n",
      "Epoch 227/250\n",
      " - 2s - loss: 3.9753 - acc: 0.1028 - val_loss: 4.0440 - val_acc: 0.0964\n",
      "Epoch 228/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1036 - val_loss: 4.0424 - val_acc: 0.0968\n",
      "Epoch 229/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1037 - val_loss: 4.0444 - val_acc: 0.0966\n",
      "Epoch 230/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1040 - val_loss: 4.0455 - val_acc: 0.0954\n",
      "Epoch 231/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1029 - val_loss: 4.0441 - val_acc: 0.0961\n",
      "Epoch 232/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1031 - val_loss: 4.0428 - val_acc: 0.0957\n",
      "Epoch 233/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1043 - val_loss: 4.0459 - val_acc: 0.0968\n",
      "Epoch 234/250\n",
      " - 2s - loss: 3.9748 - acc: 0.1033 - val_loss: 4.0425 - val_acc: 0.0971\n",
      "Epoch 235/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1039 - val_loss: 4.0472 - val_acc: 0.0962\n",
      "Epoch 236/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1030 - val_loss: 4.0472 - val_acc: 0.0944\n",
      "Epoch 237/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1035 - val_loss: 4.0424 - val_acc: 0.0964\n",
      "Epoch 238/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1031 - val_loss: 4.0485 - val_acc: 0.0952\n",
      "Epoch 239/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1035 - val_loss: 4.0471 - val_acc: 0.0957\n",
      "Epoch 240/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1024 - val_loss: 4.0430 - val_acc: 0.0962\n",
      "Epoch 241/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1035 - val_loss: 4.0440 - val_acc: 0.0961\n",
      "Epoch 242/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1032 - val_loss: 4.0432 - val_acc: 0.0957\n",
      "Epoch 243/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1034 - val_loss: 4.0445 - val_acc: 0.0962\n",
      "Epoch 244/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1033 - val_loss: 4.0446 - val_acc: 0.0962\n",
      "Epoch 245/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1027 - val_loss: 4.0403 - val_acc: 0.0958\n",
      "Epoch 246/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1040 - val_loss: 4.0547 - val_acc: 0.0947\n",
      "Epoch 247/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1034 - val_loss: 4.0461 - val_acc: 0.0956\n",
      "Epoch 248/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1029 - val_loss: 4.0477 - val_acc: 0.0951\n",
      "Epoch 249/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1038 - val_loss: 4.0420 - val_acc: 0.0962\n",
      "Epoch 250/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1035 - val_loss: 4.0447 - val_acc: 0.0962\n",
      "Mini-Train:   8 Test Accuracy: 9.62% Learning Rate: 0.0003125\n",
      "Train on 136770 samples, validate on 15266 samples\n",
      "Epoch 1/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1033 - val_loss: 4.0460 - val_acc: 0.0961\n",
      "Epoch 2/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1031 - val_loss: 4.0476 - val_acc: 0.0951\n",
      "Epoch 3/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1029 - val_loss: 4.0501 - val_acc: 0.0951\n",
      "Epoch 4/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1027 - val_loss: 4.0413 - val_acc: 0.0968\n",
      "Epoch 5/250\n",
      " - 2s - loss: 3.9740 - acc: 0.1038 - val_loss: 4.0450 - val_acc: 0.0963\n",
      "Epoch 6/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1038 - val_loss: 4.0427 - val_acc: 0.0963\n",
      "Epoch 7/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1042 - val_loss: 4.0386 - val_acc: 0.0972\n",
      "Epoch 8/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1039 - val_loss: 4.0403 - val_acc: 0.0964\n",
      "Epoch 9/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 2s - loss: 3.9762 - acc: 0.1035 - val_loss: 4.0467 - val_acc: 0.0960\n",
      "Epoch 10/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1035 - val_loss: 4.0420 - val_acc: 0.0969\n",
      "Epoch 11/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1036 - val_loss: 4.0435 - val_acc: 0.0957\n",
      "Epoch 12/250\n",
      " - 2s - loss: 3.9800 - acc: 0.1024 - val_loss: 4.0454 - val_acc: 0.0949\n",
      "Epoch 13/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1038 - val_loss: 4.0420 - val_acc: 0.0962\n",
      "Epoch 14/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1041 - val_loss: 4.0469 - val_acc: 0.0960\n",
      "Epoch 15/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1040 - val_loss: 4.0455 - val_acc: 0.0957\n",
      "Epoch 16/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1035 - val_loss: 4.0467 - val_acc: 0.0954\n",
      "Epoch 17/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1029 - val_loss: 4.0428 - val_acc: 0.0960\n",
      "Epoch 18/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1035 - val_loss: 4.0459 - val_acc: 0.0957\n",
      "Epoch 19/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1032 - val_loss: 4.0459 - val_acc: 0.0961\n",
      "Epoch 20/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1032 - val_loss: 4.0515 - val_acc: 0.0943\n",
      "Epoch 21/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1025 - val_loss: 4.0439 - val_acc: 0.0953\n",
      "Epoch 22/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1038 - val_loss: 4.0415 - val_acc: 0.0969\n",
      "Epoch 23/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1033 - val_loss: 4.0429 - val_acc: 0.0958\n",
      "Epoch 24/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1028 - val_loss: 4.0433 - val_acc: 0.0964\n",
      "Epoch 25/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1041 - val_loss: 4.0438 - val_acc: 0.0962\n",
      "Epoch 26/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1032 - val_loss: 4.0514 - val_acc: 0.0947\n",
      "Epoch 27/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1036 - val_loss: 4.0433 - val_acc: 0.0960\n",
      "Epoch 28/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1026 - val_loss: 4.0428 - val_acc: 0.0968\n",
      "Epoch 29/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1046 - val_loss: 4.0466 - val_acc: 0.0953\n",
      "Epoch 30/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1034 - val_loss: 4.0463 - val_acc: 0.0968\n",
      "Epoch 31/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1025 - val_loss: 4.0467 - val_acc: 0.0950\n",
      "Epoch 32/250\n",
      " - 2s - loss: 3.9789 - acc: 0.1028 - val_loss: 4.0429 - val_acc: 0.0962\n",
      "Epoch 33/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1039 - val_loss: 4.0443 - val_acc: 0.0962\n",
      "Epoch 34/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1038 - val_loss: 4.0421 - val_acc: 0.0956\n",
      "Epoch 35/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1034 - val_loss: 4.0460 - val_acc: 0.0954\n",
      "Epoch 36/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1026 - val_loss: 4.0431 - val_acc: 0.0963\n",
      "Epoch 37/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1037 - val_loss: 4.0457 - val_acc: 0.0962\n",
      "Epoch 38/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1033 - val_loss: 4.0437 - val_acc: 0.0963\n",
      "Epoch 39/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1034 - val_loss: 4.0453 - val_acc: 0.0962\n",
      "Epoch 40/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1031 - val_loss: 4.0431 - val_acc: 0.0958\n",
      "Epoch 41/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1034 - val_loss: 4.0473 - val_acc: 0.0958\n",
      "Epoch 42/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1038 - val_loss: 4.0437 - val_acc: 0.0960\n",
      "Epoch 43/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1037 - val_loss: 4.0483 - val_acc: 0.0954\n",
      "Epoch 44/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1032 - val_loss: 4.0422 - val_acc: 0.0964\n",
      "Epoch 45/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1032 - val_loss: 4.0462 - val_acc: 0.0956\n",
      "Epoch 46/250\n",
      " - 2s - loss: 3.9748 - acc: 0.1034 - val_loss: 4.0454 - val_acc: 0.0964\n",
      "Epoch 47/250\n",
      " - 2s - loss: 3.9747 - acc: 0.1031 - val_loss: 4.0404 - val_acc: 0.0968\n",
      "Epoch 48/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1038 - val_loss: 4.0435 - val_acc: 0.0960\n",
      "Epoch 49/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1034 - val_loss: 4.0412 - val_acc: 0.0962\n",
      "Epoch 50/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1032 - val_loss: 4.0425 - val_acc: 0.0958\n",
      "Epoch 51/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1031 - val_loss: 4.0491 - val_acc: 0.0949\n",
      "Epoch 52/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1031 - val_loss: 4.0438 - val_acc: 0.0955\n",
      "Epoch 53/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1041 - val_loss: 4.0457 - val_acc: 0.0966\n",
      "Epoch 54/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1024 - val_loss: 4.0452 - val_acc: 0.0952\n",
      "Epoch 55/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1033 - val_loss: 4.0458 - val_acc: 0.0963\n",
      "Epoch 56/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1034 - val_loss: 4.0453 - val_acc: 0.0956\n",
      "Epoch 57/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1038 - val_loss: 4.0432 - val_acc: 0.0962\n",
      "Epoch 58/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1035 - val_loss: 4.0431 - val_acc: 0.0964\n",
      "Epoch 59/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1028 - val_loss: 4.0452 - val_acc: 0.0964\n",
      "Epoch 60/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1035 - val_loss: 4.0424 - val_acc: 0.0950\n",
      "Epoch 61/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1034 - val_loss: 4.0443 - val_acc: 0.0956\n",
      "Epoch 62/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1041 - val_loss: 4.0443 - val_acc: 0.0964\n",
      "Epoch 63/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1028 - val_loss: 4.0406 - val_acc: 0.0964\n",
      "Epoch 64/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1041 - val_loss: 4.0481 - val_acc: 0.0949\n",
      "Epoch 65/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1035 - val_loss: 4.0443 - val_acc: 0.0958\n",
      "Epoch 66/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1033 - val_loss: 4.0466 - val_acc: 0.0954\n",
      "Epoch 67/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1045 - val_loss: 4.0455 - val_acc: 0.0943\n",
      "Epoch 68/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1037 - val_loss: 4.0437 - val_acc: 0.0955\n",
      "Epoch 69/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1029 - val_loss: 4.0434 - val_acc: 0.0960\n",
      "Epoch 70/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1025 - val_loss: 4.0444 - val_acc: 0.0964\n",
      "Epoch 71/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1031 - val_loss: 4.0442 - val_acc: 0.0959\n",
      "Epoch 72/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1034 - val_loss: 4.0423 - val_acc: 0.0964\n",
      "Epoch 73/250\n",
      " - 2s - loss: 3.9734 - acc: 0.1028 - val_loss: 4.0482 - val_acc: 0.0952\n",
      "Epoch 74/250\n",
      " - 2s - loss: 3.9739 - acc: 0.1039 - val_loss: 4.0441 - val_acc: 0.0958\n",
      "Epoch 75/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1040 - val_loss: 4.0438 - val_acc: 0.0961\n",
      "Epoch 76/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1036 - val_loss: 4.0456 - val_acc: 0.0953\n",
      "Epoch 77/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1043 - val_loss: 4.0396 - val_acc: 0.0958\n",
      "Epoch 78/250\n",
      " - 2s - loss: 3.9744 - acc: 0.1036 - val_loss: 4.0444 - val_acc: 0.0964\n",
      "Epoch 79/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1029 - val_loss: 4.0456 - val_acc: 0.0955\n",
      "Epoch 80/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1029 - val_loss: 4.0497 - val_acc: 0.0947\n",
      "Epoch 81/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1035 - val_loss: 4.0438 - val_acc: 0.0964\n",
      "Epoch 82/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1028 - val_loss: 4.0410 - val_acc: 0.0967\n",
      "Epoch 83/250\n",
      " - 2s - loss: 3.9788 - acc: 0.1028 - val_loss: 4.0440 - val_acc: 0.0966\n",
      "Epoch 84/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1031 - val_loss: 4.0451 - val_acc: 0.0964\n",
      "Epoch 85/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1036 - val_loss: 4.0438 - val_acc: 0.0961\n",
      "Epoch 86/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1038 - val_loss: 4.0429 - val_acc: 0.0964\n",
      "Epoch 87/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1030 - val_loss: 4.0444 - val_acc: 0.0956\n",
      "Epoch 88/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1038 - val_loss: 4.0448 - val_acc: 0.0960\n",
      "Epoch 89/250\n",
      " - 2s - loss: 3.9753 - acc: 0.1031 - val_loss: 4.0432 - val_acc: 0.0959\n",
      "Epoch 90/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1034 - val_loss: 4.0450 - val_acc: 0.0960\n",
      "Epoch 91/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1032 - val_loss: 4.0467 - val_acc: 0.0950\n",
      "Epoch 92/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1032 - val_loss: 4.0475 - val_acc: 0.0955\n",
      "Epoch 93/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1037 - val_loss: 4.0465 - val_acc: 0.0953\n",
      "Epoch 94/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1044 - val_loss: 4.0429 - val_acc: 0.0966\n",
      "Epoch 95/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1032 - val_loss: 4.0410 - val_acc: 0.0956\n",
      "Epoch 96/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1028 - val_loss: 4.0466 - val_acc: 0.0952\n",
      "Epoch 97/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1033 - val_loss: 4.0472 - val_acc: 0.0958\n",
      "Epoch 98/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1037 - val_loss: 4.0414 - val_acc: 0.0959\n",
      "Epoch 99/250\n",
      " - 2s - loss: 3.9746 - acc: 0.1038 - val_loss: 4.0441 - val_acc: 0.0956\n",
      "Epoch 100/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1036 - val_loss: 4.0453 - val_acc: 0.0962\n",
      "Epoch 101/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1036 - val_loss: 4.0419 - val_acc: 0.0966\n",
      "Epoch 102/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1026 - val_loss: 4.0412 - val_acc: 0.0970\n",
      "Epoch 103/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1041 - val_loss: 4.0463 - val_acc: 0.0968\n",
      "Epoch 104/250\n",
      " - 2s - loss: 3.9742 - acc: 0.1034 - val_loss: 4.0434 - val_acc: 0.0962\n",
      "Epoch 105/250\n",
      " - 2s - loss: 3.9799 - acc: 0.1023 - val_loss: 4.0525 - val_acc: 0.0950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/250\n",
      " - 2s - loss: 3.9742 - acc: 0.1041 - val_loss: 4.0466 - val_acc: 0.0950\n",
      "Epoch 107/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1036 - val_loss: 4.0430 - val_acc: 0.0970\n",
      "Epoch 108/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1026 - val_loss: 4.0439 - val_acc: 0.0961\n",
      "Epoch 109/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1040 - val_loss: 4.0420 - val_acc: 0.0963\n",
      "Epoch 110/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1031 - val_loss: 4.0429 - val_acc: 0.0964\n",
      "Epoch 111/250\n",
      " - 2s - loss: 3.9741 - acc: 0.1033 - val_loss: 4.0427 - val_acc: 0.0967\n",
      "Epoch 112/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1036 - val_loss: 4.0429 - val_acc: 0.0956\n",
      "Epoch 113/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1018 - val_loss: 4.0411 - val_acc: 0.0956\n",
      "Epoch 114/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1034 - val_loss: 4.0451 - val_acc: 0.0963\n",
      "Epoch 115/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1037 - val_loss: 4.0412 - val_acc: 0.0963\n",
      "Epoch 116/250\n",
      " - 2s - loss: 3.9750 - acc: 0.1038 - val_loss: 4.0432 - val_acc: 0.0968\n",
      "Epoch 117/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1036 - val_loss: 4.0414 - val_acc: 0.0964\n",
      "Epoch 118/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1031 - val_loss: 4.0446 - val_acc: 0.0965\n",
      "Epoch 119/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1027 - val_loss: 4.0441 - val_acc: 0.0960\n",
      "Epoch 120/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1030 - val_loss: 4.0442 - val_acc: 0.0962\n",
      "Epoch 121/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1032 - val_loss: 4.0419 - val_acc: 0.0964\n",
      "Epoch 122/250\n",
      " - 2s - loss: 3.9754 - acc: 0.1042 - val_loss: 4.0414 - val_acc: 0.0966\n",
      "Epoch 123/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1031 - val_loss: 4.0461 - val_acc: 0.0962\n",
      "Epoch 124/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1035 - val_loss: 4.0425 - val_acc: 0.0971\n",
      "Epoch 125/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1026 - val_loss: 4.0440 - val_acc: 0.0955\n",
      "Epoch 126/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1029 - val_loss: 4.0478 - val_acc: 0.0956\n",
      "Epoch 127/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1030 - val_loss: 4.0489 - val_acc: 0.0952\n",
      "Epoch 128/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1033 - val_loss: 4.0438 - val_acc: 0.0968\n",
      "Epoch 129/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1031 - val_loss: 4.0422 - val_acc: 0.0962\n",
      "Epoch 130/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1033 - val_loss: 4.0405 - val_acc: 0.0966\n",
      "Epoch 131/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1032 - val_loss: 4.0428 - val_acc: 0.0969\n",
      "Epoch 132/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1040 - val_loss: 4.0432 - val_acc: 0.0964\n",
      "Epoch 133/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1030 - val_loss: 4.0449 - val_acc: 0.0965\n",
      "Epoch 134/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1033 - val_loss: 4.0458 - val_acc: 0.0963\n",
      "Epoch 135/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1035 - val_loss: 4.0481 - val_acc: 0.0948\n",
      "Epoch 136/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1038 - val_loss: 4.0461 - val_acc: 0.0958\n",
      "Epoch 137/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1035 - val_loss: 4.0440 - val_acc: 0.0957\n",
      "Epoch 138/250\n",
      " - 2s - loss: 3.9747 - acc: 0.1034 - val_loss: 4.0403 - val_acc: 0.0964\n",
      "Epoch 139/250\n",
      " - 2s - loss: 3.9753 - acc: 0.1039 - val_loss: 4.0429 - val_acc: 0.0959\n",
      "Epoch 140/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1039 - val_loss: 4.0433 - val_acc: 0.0952\n",
      "Epoch 141/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1031 - val_loss: 4.0441 - val_acc: 0.0958\n",
      "Epoch 142/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1034 - val_loss: 4.0450 - val_acc: 0.0957\n",
      "Epoch 143/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1032 - val_loss: 4.0497 - val_acc: 0.0960\n",
      "Epoch 144/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1034 - val_loss: 4.0435 - val_acc: 0.0957\n",
      "Epoch 145/250\n",
      " - 2s - loss: 3.9746 - acc: 0.1037 - val_loss: 4.0453 - val_acc: 0.0957\n",
      "Epoch 146/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1028 - val_loss: 4.0449 - val_acc: 0.0959\n",
      "Epoch 147/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1032 - val_loss: 4.0428 - val_acc: 0.0962\n",
      "Epoch 148/250\n",
      " - 2s - loss: 3.9746 - acc: 0.1038 - val_loss: 4.0444 - val_acc: 0.0957\n",
      "Epoch 149/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1038 - val_loss: 4.0424 - val_acc: 0.0962\n",
      "Epoch 150/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1029 - val_loss: 4.0416 - val_acc: 0.0955\n",
      "Epoch 151/250\n",
      " - 2s - loss: 3.9731 - acc: 0.1045 - val_loss: 4.0409 - val_acc: 0.0959\n",
      "Epoch 152/250\n",
      " - 2s - loss: 3.9748 - acc: 0.1036 - val_loss: 4.0422 - val_acc: 0.0960\n",
      "Epoch 153/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1030 - val_loss: 4.0434 - val_acc: 0.0969\n",
      "Epoch 154/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1041 - val_loss: 4.0423 - val_acc: 0.0965\n",
      "Epoch 155/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1033 - val_loss: 4.0444 - val_acc: 0.0967\n",
      "Epoch 156/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1033 - val_loss: 4.0491 - val_acc: 0.0946\n",
      "Epoch 157/250\n",
      " - 2s - loss: 3.9746 - acc: 0.1028 - val_loss: 4.0452 - val_acc: 0.0964\n",
      "Epoch 158/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1031 - val_loss: 4.0427 - val_acc: 0.0954\n",
      "Epoch 159/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1038 - val_loss: 4.0438 - val_acc: 0.0964\n",
      "Epoch 160/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1040 - val_loss: 4.0424 - val_acc: 0.0960\n",
      "Epoch 161/250\n",
      " - 2s - loss: 3.9753 - acc: 0.1036 - val_loss: 4.0437 - val_acc: 0.0964\n",
      "Epoch 162/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1033 - val_loss: 4.0431 - val_acc: 0.0964\n",
      "Epoch 163/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1037 - val_loss: 4.0442 - val_acc: 0.0964\n",
      "Epoch 164/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1037 - val_loss: 4.0444 - val_acc: 0.0963\n",
      "Epoch 165/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1030 - val_loss: 4.0433 - val_acc: 0.0961\n",
      "Epoch 166/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1032 - val_loss: 4.0477 - val_acc: 0.0955\n",
      "Epoch 167/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1038 - val_loss: 4.0482 - val_acc: 0.0954\n",
      "Epoch 168/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1039 - val_loss: 4.0405 - val_acc: 0.0960\n",
      "Epoch 169/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1030 - val_loss: 4.0410 - val_acc: 0.0960\n",
      "Epoch 170/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1035 - val_loss: 4.0447 - val_acc: 0.0956\n",
      "Epoch 171/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1031 - val_loss: 4.0428 - val_acc: 0.0964\n",
      "Epoch 172/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1039 - val_loss: 4.0454 - val_acc: 0.0960\n",
      "Epoch 173/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1039 - val_loss: 4.0434 - val_acc: 0.0962\n",
      "Epoch 174/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1037 - val_loss: 4.0415 - val_acc: 0.0962\n",
      "Epoch 175/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1037 - val_loss: 4.0435 - val_acc: 0.0956\n",
      "Epoch 176/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1026 - val_loss: 4.0444 - val_acc: 0.0968\n",
      "Epoch 177/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1029 - val_loss: 4.0461 - val_acc: 0.0961\n",
      "Epoch 178/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1034 - val_loss: 4.0449 - val_acc: 0.0962\n",
      "Epoch 179/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1035 - val_loss: 4.0418 - val_acc: 0.0960\n",
      "Epoch 180/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1026 - val_loss: 4.0442 - val_acc: 0.0962\n",
      "Epoch 181/250\n",
      " - 2s - loss: 3.9750 - acc: 0.1031 - val_loss: 4.0440 - val_acc: 0.0957\n",
      "Epoch 182/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1024 - val_loss: 4.0468 - val_acc: 0.0963\n",
      "Epoch 183/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1033 - val_loss: 4.0460 - val_acc: 0.0960\n",
      "Epoch 184/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1030 - val_loss: 4.0488 - val_acc: 0.0956\n",
      "Epoch 185/250\n",
      " - 2s - loss: 3.9747 - acc: 0.1039 - val_loss: 4.0451 - val_acc: 0.0953\n",
      "Epoch 186/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1033 - val_loss: 4.0518 - val_acc: 0.0952\n",
      "Epoch 187/250\n",
      " - 2s - loss: 3.9783 - acc: 0.1028 - val_loss: 4.0453 - val_acc: 0.0957\n",
      "Epoch 188/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1040 - val_loss: 4.0471 - val_acc: 0.0960\n",
      "Epoch 189/250\n",
      " - 2s - loss: 3.9754 - acc: 0.1043 - val_loss: 4.0494 - val_acc: 0.0949\n",
      "Epoch 190/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1035 - val_loss: 4.0442 - val_acc: 0.0962\n",
      "Epoch 191/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1038 - val_loss: 4.0425 - val_acc: 0.0958\n",
      "Epoch 192/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1028 - val_loss: 4.0460 - val_acc: 0.0959\n",
      "Epoch 193/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1035 - val_loss: 4.0447 - val_acc: 0.0953\n",
      "Epoch 194/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1039 - val_loss: 4.0449 - val_acc: 0.0960\n",
      "Epoch 195/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1030 - val_loss: 4.0448 - val_acc: 0.0961\n",
      "Epoch 196/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1033 - val_loss: 4.0434 - val_acc: 0.0961\n",
      "Epoch 197/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1037 - val_loss: 4.0450 - val_acc: 0.0964\n",
      "Epoch 198/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1031 - val_loss: 4.0445 - val_acc: 0.0958\n",
      "Epoch 199/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1036 - val_loss: 4.0440 - val_acc: 0.0956\n",
      "Epoch 200/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1034 - val_loss: 4.0408 - val_acc: 0.0962\n",
      "Epoch 201/250\n",
      " - 2s - loss: 3.9754 - acc: 0.1031 - val_loss: 4.0424 - val_acc: 0.0960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1032 - val_loss: 4.0459 - val_acc: 0.0956\n",
      "Epoch 203/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1035 - val_loss: 4.0431 - val_acc: 0.0959\n",
      "Epoch 204/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1036 - val_loss: 4.0446 - val_acc: 0.0949\n",
      "Epoch 205/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1033 - val_loss: 4.0426 - val_acc: 0.0960\n",
      "Epoch 206/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1039 - val_loss: 4.0456 - val_acc: 0.0955\n",
      "Epoch 207/250\n",
      " - 2s - loss: 3.9738 - acc: 0.1038 - val_loss: 4.0417 - val_acc: 0.0966\n",
      "Epoch 208/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1033 - val_loss: 4.0425 - val_acc: 0.0965\n",
      "Epoch 209/250\n",
      " - 2s - loss: 3.9788 - acc: 0.1031 - val_loss: 4.0446 - val_acc: 0.0962\n",
      "Epoch 210/250\n",
      " - 2s - loss: 3.9740 - acc: 0.1034 - val_loss: 4.0425 - val_acc: 0.0964\n",
      "Epoch 211/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1032 - val_loss: 4.0412 - val_acc: 0.0960\n",
      "Epoch 212/250\n",
      " - 2s - loss: 3.9784 - acc: 0.1032 - val_loss: 4.0412 - val_acc: 0.0973\n",
      "Epoch 213/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1030 - val_loss: 4.0476 - val_acc: 0.0951\n",
      "Epoch 214/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1033 - val_loss: 4.0462 - val_acc: 0.0954\n",
      "Epoch 215/250\n",
      " - 2s - loss: 3.9780 - acc: 0.1037 - val_loss: 4.0436 - val_acc: 0.0960\n",
      "Epoch 216/250\n",
      " - 2s - loss: 3.9737 - acc: 0.1027 - val_loss: 4.0444 - val_acc: 0.0962\n",
      "Epoch 217/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1032 - val_loss: 4.0460 - val_acc: 0.0967\n",
      "Epoch 218/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1037 - val_loss: 4.0402 - val_acc: 0.0972\n",
      "Epoch 219/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1035 - val_loss: 4.0452 - val_acc: 0.0958\n",
      "Epoch 220/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1028 - val_loss: 4.0446 - val_acc: 0.0961\n",
      "Epoch 221/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1038 - val_loss: 4.0439 - val_acc: 0.0960\n",
      "Epoch 222/250\n",
      " - 2s - loss: 3.9753 - acc: 0.1042 - val_loss: 4.0422 - val_acc: 0.0964\n",
      "Epoch 223/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1038 - val_loss: 4.0443 - val_acc: 0.0955\n",
      "Epoch 224/250\n",
      " - 2s - loss: 3.9754 - acc: 0.1044 - val_loss: 4.0426 - val_acc: 0.0962\n",
      "Epoch 225/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1034 - val_loss: 4.0465 - val_acc: 0.0950\n",
      "Epoch 226/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1026 - val_loss: 4.0475 - val_acc: 0.0954\n",
      "Epoch 227/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1036 - val_loss: 4.0398 - val_acc: 0.0957\n",
      "Epoch 228/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1040 - val_loss: 4.0433 - val_acc: 0.0961\n",
      "Epoch 229/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1030 - val_loss: 4.0430 - val_acc: 0.0964\n",
      "Epoch 230/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1037 - val_loss: 4.0449 - val_acc: 0.0960\n",
      "Epoch 231/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1033 - val_loss: 4.0459 - val_acc: 0.0947\n",
      "Epoch 232/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1039 - val_loss: 4.0452 - val_acc: 0.0955\n",
      "Epoch 233/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1031 - val_loss: 4.0418 - val_acc: 0.0960\n",
      "Epoch 234/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1038 - val_loss: 4.0411 - val_acc: 0.0967\n",
      "Epoch 235/250\n",
      " - 2s - loss: 3.9743 - acc: 0.1036 - val_loss: 4.0465 - val_acc: 0.0956\n",
      "Epoch 236/250\n",
      " - 2s - loss: 3.9737 - acc: 0.1035 - val_loss: 4.0430 - val_acc: 0.0962\n",
      "Epoch 237/250\n",
      " - 2s - loss: 3.9754 - acc: 0.1033 - val_loss: 4.0412 - val_acc: 0.0969\n",
      "Epoch 238/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1034 - val_loss: 4.0419 - val_acc: 0.0956\n",
      "Epoch 239/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1041 - val_loss: 4.0421 - val_acc: 0.0965\n",
      "Epoch 240/250\n",
      " - 2s - loss: 3.9736 - acc: 0.1045 - val_loss: 4.0428 - val_acc: 0.0954\n",
      "Epoch 241/250\n",
      " - 2s - loss: 3.9733 - acc: 0.1042 - val_loss: 4.0450 - val_acc: 0.0953\n",
      "Epoch 242/250\n",
      " - 2s - loss: 3.9735 - acc: 0.1031 - val_loss: 4.0469 - val_acc: 0.0956\n",
      "Epoch 243/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1037 - val_loss: 4.0442 - val_acc: 0.0963\n",
      "Epoch 244/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1034 - val_loss: 4.0466 - val_acc: 0.0960\n",
      "Epoch 245/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1036 - val_loss: 4.0441 - val_acc: 0.0964\n",
      "Epoch 246/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1039 - val_loss: 4.0412 - val_acc: 0.0960\n",
      "Epoch 247/250\n",
      " - 2s - loss: 3.9729 - acc: 0.1047 - val_loss: 4.0447 - val_acc: 0.0960\n",
      "Epoch 248/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1044 - val_loss: 4.0426 - val_acc: 0.0969\n",
      "Epoch 249/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1039 - val_loss: 4.0448 - val_acc: 0.0962\n",
      "Epoch 250/250\n",
      " - 2s - loss: 3.9742 - acc: 0.1029 - val_loss: 4.0405 - val_acc: 0.0967\n",
      "Mini-Train:   9 Test Accuracy: 9.67% Learning Rate: 0.0002778\n",
      "Train on 136770 samples, validate on 15266 samples\n",
      "Epoch 1/250\n",
      " - 2s - loss: 3.9750 - acc: 0.1033 - val_loss: 4.0406 - val_acc: 0.0962\n",
      "Epoch 2/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1035 - val_loss: 4.0444 - val_acc: 0.0956\n",
      "Epoch 3/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1031 - val_loss: 4.0424 - val_acc: 0.0964\n",
      "Epoch 4/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1038 - val_loss: 4.0399 - val_acc: 0.0964\n",
      "Epoch 5/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1030 - val_loss: 4.0417 - val_acc: 0.0965\n",
      "Epoch 6/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1034 - val_loss: 4.0455 - val_acc: 0.0957\n",
      "Epoch 7/250\n",
      " - 2s - loss: 3.9781 - acc: 0.1042 - val_loss: 4.0431 - val_acc: 0.0961\n",
      "Epoch 8/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1027 - val_loss: 4.0434 - val_acc: 0.0956\n",
      "Epoch 9/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1032 - val_loss: 4.0473 - val_acc: 0.0958\n",
      "Epoch 10/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1040 - val_loss: 4.0423 - val_acc: 0.0953\n",
      "Epoch 11/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1032 - val_loss: 4.0438 - val_acc: 0.0957\n",
      "Epoch 12/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1034 - val_loss: 4.0460 - val_acc: 0.0960\n",
      "Epoch 13/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1045 - val_loss: 4.0448 - val_acc: 0.0965\n",
      "Epoch 14/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1030 - val_loss: 4.0477 - val_acc: 0.0964\n",
      "Epoch 15/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1039 - val_loss: 4.0438 - val_acc: 0.0962\n",
      "Epoch 16/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1036 - val_loss: 4.0410 - val_acc: 0.0960\n",
      "Epoch 17/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1023 - val_loss: 4.0484 - val_acc: 0.0956\n",
      "Epoch 18/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1034 - val_loss: 4.0434 - val_acc: 0.0951\n",
      "Epoch 19/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1036 - val_loss: 4.0430 - val_acc: 0.0960\n",
      "Epoch 20/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1035 - val_loss: 4.0431 - val_acc: 0.0960\n",
      "Epoch 21/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1044 - val_loss: 4.0450 - val_acc: 0.0965\n",
      "Epoch 22/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1036 - val_loss: 4.0468 - val_acc: 0.0954\n",
      "Epoch 23/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1043 - val_loss: 4.0450 - val_acc: 0.0962\n",
      "Epoch 24/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1029 - val_loss: 4.0458 - val_acc: 0.0945\n",
      "Epoch 25/250\n",
      " - 2s - loss: 3.9738 - acc: 0.1040 - val_loss: 4.0424 - val_acc: 0.0958\n",
      "Epoch 26/250\n",
      " - 2s - loss: 3.9741 - acc: 0.1029 - val_loss: 4.0409 - val_acc: 0.0959\n",
      "Epoch 27/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1034 - val_loss: 4.0416 - val_acc: 0.0969\n",
      "Epoch 28/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1035 - val_loss: 4.0418 - val_acc: 0.0960\n",
      "Epoch 29/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1040 - val_loss: 4.0442 - val_acc: 0.0964\n",
      "Epoch 30/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1034 - val_loss: 4.0443 - val_acc: 0.0968\n",
      "Epoch 31/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1040 - val_loss: 4.0435 - val_acc: 0.0961\n",
      "Epoch 32/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1027 - val_loss: 4.0462 - val_acc: 0.0961\n",
      "Epoch 33/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1033 - val_loss: 4.0453 - val_acc: 0.0956\n",
      "Epoch 34/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1028 - val_loss: 4.0446 - val_acc: 0.0960\n",
      "Epoch 35/250\n",
      " - 2s - loss: 3.9753 - acc: 0.1038 - val_loss: 4.0477 - val_acc: 0.0948\n",
      "Epoch 36/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1030 - val_loss: 4.0435 - val_acc: 0.0963\n",
      "Epoch 37/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1039 - val_loss: 4.0442 - val_acc: 0.0956\n",
      "Epoch 38/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1041 - val_loss: 4.0464 - val_acc: 0.0955\n",
      "Epoch 39/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1027 - val_loss: 4.0436 - val_acc: 0.0961\n",
      "Epoch 40/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1029 - val_loss: 4.0468 - val_acc: 0.0956\n",
      "Epoch 41/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1040 - val_loss: 4.0464 - val_acc: 0.0960\n",
      "Epoch 42/250\n",
      " - 2s - loss: 3.9744 - acc: 0.1030 - val_loss: 4.0434 - val_acc: 0.0962\n",
      "Epoch 43/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1026 - val_loss: 4.0422 - val_acc: 0.0961\n",
      "Epoch 44/250\n",
      " - 2s - loss: 3.9741 - acc: 0.1032 - val_loss: 4.0443 - val_acc: 0.0956\n",
      "Epoch 45/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1034 - val_loss: 4.0442 - val_acc: 0.0966\n",
      "Epoch 46/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1043 - val_loss: 4.0420 - val_acc: 0.0965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1030 - val_loss: 4.0414 - val_acc: 0.0960\n",
      "Epoch 48/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1034 - val_loss: 4.0428 - val_acc: 0.0956\n",
      "Epoch 49/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1043 - val_loss: 4.0433 - val_acc: 0.0960\n",
      "Epoch 50/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1031 - val_loss: 4.0454 - val_acc: 0.0958\n",
      "Epoch 51/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1040 - val_loss: 4.0471 - val_acc: 0.0954\n",
      "Epoch 52/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1042 - val_loss: 4.0437 - val_acc: 0.0972\n",
      "Epoch 53/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1034 - val_loss: 4.0438 - val_acc: 0.0967\n",
      "Epoch 54/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1037 - val_loss: 4.0430 - val_acc: 0.0958\n",
      "Epoch 55/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1032 - val_loss: 4.0462 - val_acc: 0.0958\n",
      "Epoch 56/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1029 - val_loss: 4.0429 - val_acc: 0.0964\n",
      "Epoch 57/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1037 - val_loss: 4.0418 - val_acc: 0.0967\n",
      "Epoch 58/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1036 - val_loss: 4.0485 - val_acc: 0.0958\n",
      "Epoch 59/250\n",
      " - 2s - loss: 3.9753 - acc: 0.1036 - val_loss: 4.0428 - val_acc: 0.0955\n",
      "Epoch 60/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1033 - val_loss: 4.0446 - val_acc: 0.0963\n",
      "Epoch 61/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1028 - val_loss: 4.0443 - val_acc: 0.0961\n",
      "Epoch 62/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1036 - val_loss: 4.0462 - val_acc: 0.0953\n",
      "Epoch 63/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1038 - val_loss: 4.0433 - val_acc: 0.0958\n",
      "Epoch 64/250\n",
      " - 2s - loss: 3.9736 - acc: 0.1042 - val_loss: 4.0451 - val_acc: 0.0958\n",
      "Epoch 65/250\n",
      " - 2s - loss: 3.9750 - acc: 0.1032 - val_loss: 4.0411 - val_acc: 0.0955\n",
      "Epoch 66/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1040 - val_loss: 4.0428 - val_acc: 0.0963\n",
      "Epoch 67/250\n",
      " - 2s - loss: 3.9754 - acc: 0.1030 - val_loss: 4.0423 - val_acc: 0.0964\n",
      "Epoch 68/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1035 - val_loss: 4.0467 - val_acc: 0.0950\n",
      "Epoch 69/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1037 - val_loss: 4.0428 - val_acc: 0.0968\n",
      "Epoch 70/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1040 - val_loss: 4.0437 - val_acc: 0.0960\n",
      "Epoch 71/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1035 - val_loss: 4.0404 - val_acc: 0.0964\n",
      "Epoch 72/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1038 - val_loss: 4.0453 - val_acc: 0.0960\n",
      "Epoch 73/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1028 - val_loss: 4.0455 - val_acc: 0.0956\n",
      "Epoch 74/250\n",
      " - 2s - loss: 3.9731 - acc: 0.1045 - val_loss: 4.0443 - val_acc: 0.0960\n",
      "Epoch 75/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1031 - val_loss: 4.0438 - val_acc: 0.0956\n",
      "Epoch 76/250\n",
      " - 2s - loss: 3.9741 - acc: 0.1038 - val_loss: 4.0480 - val_acc: 0.0960\n",
      "Epoch 77/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1025 - val_loss: 4.0412 - val_acc: 0.0962\n",
      "Epoch 78/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1036 - val_loss: 4.0406 - val_acc: 0.0962\n",
      "Epoch 79/250\n",
      " - 2s - loss: 3.9743 - acc: 0.1037 - val_loss: 4.0395 - val_acc: 0.0958\n",
      "Epoch 80/250\n",
      " - 2s - loss: 3.9748 - acc: 0.1039 - val_loss: 4.0429 - val_acc: 0.0963\n",
      "Epoch 81/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1036 - val_loss: 4.0410 - val_acc: 0.0962\n",
      "Epoch 82/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1041 - val_loss: 4.0456 - val_acc: 0.0958\n",
      "Epoch 83/250\n",
      " - 2s - loss: 3.9750 - acc: 0.1040 - val_loss: 4.0437 - val_acc: 0.0965\n",
      "Epoch 84/250\n",
      " - 2s - loss: 3.9739 - acc: 0.1035 - val_loss: 4.0444 - val_acc: 0.0947\n",
      "Epoch 85/250\n",
      " - 2s - loss: 3.9747 - acc: 0.1029 - val_loss: 4.0415 - val_acc: 0.0961\n",
      "Epoch 86/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1030 - val_loss: 4.0446 - val_acc: 0.0965\n",
      "Epoch 87/250\n",
      " - 2s - loss: 3.9746 - acc: 0.1033 - val_loss: 4.0442 - val_acc: 0.0957\n",
      "Epoch 88/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1026 - val_loss: 4.0419 - val_acc: 0.0964\n",
      "Epoch 89/250\n",
      " - 2s - loss: 3.9791 - acc: 0.1032 - val_loss: 4.0414 - val_acc: 0.0968\n",
      "Epoch 90/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1039 - val_loss: 4.0431 - val_acc: 0.0960\n",
      "Epoch 91/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1036 - val_loss: 4.0462 - val_acc: 0.0957\n",
      "Epoch 92/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1029 - val_loss: 4.0432 - val_acc: 0.0958\n",
      "Epoch 93/250\n",
      " - 2s - loss: 3.9742 - acc: 0.1034 - val_loss: 4.0470 - val_acc: 0.0951\n",
      "Epoch 94/250\n",
      " - 2s - loss: 3.9743 - acc: 0.1035 - val_loss: 4.0478 - val_acc: 0.0963\n",
      "Epoch 95/250\n",
      " - 2s - loss: 3.9746 - acc: 0.1039 - val_loss: 4.0429 - val_acc: 0.0962\n",
      "Epoch 96/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1039 - val_loss: 4.0446 - val_acc: 0.0960\n",
      "Epoch 97/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1034 - val_loss: 4.0399 - val_acc: 0.0964\n",
      "Epoch 98/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1025 - val_loss: 4.0446 - val_acc: 0.0959\n",
      "Epoch 99/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1035 - val_loss: 4.0447 - val_acc: 0.0961\n",
      "Epoch 100/250\n",
      " - 2s - loss: 3.9732 - acc: 0.1040 - val_loss: 4.0406 - val_acc: 0.0962\n",
      "Epoch 101/250\n",
      " - 2s - loss: 3.9747 - acc: 0.1036 - val_loss: 4.0438 - val_acc: 0.0955\n",
      "Epoch 102/250\n",
      " - 2s - loss: 3.9753 - acc: 0.1035 - val_loss: 4.0418 - val_acc: 0.0959\n",
      "Epoch 103/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1031 - val_loss: 4.0459 - val_acc: 0.0952\n",
      "Epoch 104/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1028 - val_loss: 4.0450 - val_acc: 0.0962\n",
      "Epoch 105/250\n",
      " - 2s - loss: 3.9744 - acc: 0.1030 - val_loss: 4.0424 - val_acc: 0.0962\n",
      "Epoch 106/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1032 - val_loss: 4.0425 - val_acc: 0.0960\n",
      "Epoch 107/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1034 - val_loss: 4.0452 - val_acc: 0.0960\n",
      "Epoch 108/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1030 - val_loss: 4.0453 - val_acc: 0.0955\n",
      "Epoch 109/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1033 - val_loss: 4.0393 - val_acc: 0.0962\n",
      "Epoch 110/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1031 - val_loss: 4.0430 - val_acc: 0.0966\n",
      "Epoch 111/250\n",
      " - 2s - loss: 3.9743 - acc: 0.1039 - val_loss: 4.0415 - val_acc: 0.0969\n",
      "Epoch 112/250\n",
      " - 2s - loss: 3.9748 - acc: 0.1029 - val_loss: 4.0395 - val_acc: 0.0965\n",
      "Epoch 113/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1028 - val_loss: 4.0429 - val_acc: 0.0964\n",
      "Epoch 114/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1037 - val_loss: 4.0420 - val_acc: 0.0964\n",
      "Epoch 115/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1031 - val_loss: 4.0446 - val_acc: 0.0960\n",
      "Epoch 116/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1031 - val_loss: 4.0432 - val_acc: 0.0959\n",
      "Epoch 117/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1030 - val_loss: 4.0440 - val_acc: 0.0958\n",
      "Epoch 118/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1029 - val_loss: 4.0431 - val_acc: 0.0960\n",
      "Epoch 119/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1032 - val_loss: 4.0452 - val_acc: 0.0963\n",
      "Epoch 120/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1028 - val_loss: 4.0482 - val_acc: 0.0959\n",
      "Epoch 121/250\n",
      " - 2s - loss: 3.9736 - acc: 0.1034 - val_loss: 4.0434 - val_acc: 0.0962\n",
      "Epoch 122/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1026 - val_loss: 4.0454 - val_acc: 0.0962\n",
      "Epoch 123/250\n",
      " - 2s - loss: 3.9753 - acc: 0.1045 - val_loss: 4.0453 - val_acc: 0.0956\n",
      "Epoch 124/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1038 - val_loss: 4.0434 - val_acc: 0.0962\n",
      "Epoch 125/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1033 - val_loss: 4.0409 - val_acc: 0.0964\n",
      "Epoch 126/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1035 - val_loss: 4.0446 - val_acc: 0.0960\n",
      "Epoch 127/250\n",
      " - 2s - loss: 3.9743 - acc: 0.1040 - val_loss: 4.0418 - val_acc: 0.0963\n",
      "Epoch 128/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1030 - val_loss: 4.0480 - val_acc: 0.0958\n",
      "Epoch 129/250\n",
      " - 2s - loss: 3.9747 - acc: 0.1030 - val_loss: 4.0450 - val_acc: 0.0964\n",
      "Epoch 130/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1024 - val_loss: 4.0432 - val_acc: 0.0968\n",
      "Epoch 131/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1034 - val_loss: 4.0417 - val_acc: 0.0962\n",
      "Epoch 132/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1039 - val_loss: 4.0441 - val_acc: 0.0973\n",
      "Epoch 133/250\n",
      " - 2s - loss: 3.9741 - acc: 0.1033 - val_loss: 4.0486 - val_acc: 0.0956\n",
      "Epoch 134/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1026 - val_loss: 4.0449 - val_acc: 0.0956\n",
      "Epoch 135/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1031 - val_loss: 4.0465 - val_acc: 0.0966\n",
      "Epoch 136/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1031 - val_loss: 4.0405 - val_acc: 0.0968\n",
      "Epoch 137/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1030 - val_loss: 4.0439 - val_acc: 0.0966\n",
      "Epoch 138/250\n",
      " - 2s - loss: 3.9773 - acc: 0.1036 - val_loss: 4.0427 - val_acc: 0.0952\n",
      "Epoch 139/250\n",
      " - 2s - loss: 3.9737 - acc: 0.1031 - val_loss: 4.0428 - val_acc: 0.0961\n",
      "Epoch 140/250\n",
      " - 2s - loss: 3.9767 - acc: 0.1038 - val_loss: 4.0464 - val_acc: 0.0952\n",
      "Epoch 141/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1036 - val_loss: 4.0420 - val_acc: 0.0962\n",
      "Epoch 142/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1039 - val_loss: 4.0432 - val_acc: 0.0968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/250\n",
      " - 2s - loss: 3.9743 - acc: 0.1033 - val_loss: 4.0458 - val_acc: 0.0953\n",
      "Epoch 144/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1042 - val_loss: 4.0482 - val_acc: 0.0955\n",
      "Epoch 145/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1043 - val_loss: 4.0413 - val_acc: 0.0967\n",
      "Epoch 146/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1038 - val_loss: 4.0429 - val_acc: 0.0958\n",
      "Epoch 147/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1028 - val_loss: 4.0439 - val_acc: 0.0956\n",
      "Epoch 148/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1038 - val_loss: 4.0467 - val_acc: 0.0954\n",
      "Epoch 149/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1036 - val_loss: 4.0437 - val_acc: 0.0967\n",
      "Epoch 150/250\n",
      " - 2s - loss: 3.9782 - acc: 0.1041 - val_loss: 4.0447 - val_acc: 0.0957\n",
      "Epoch 151/250\n",
      " - 2s - loss: 3.9778 - acc: 0.1034 - val_loss: 4.0444 - val_acc: 0.0958\n",
      "Epoch 152/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1036 - val_loss: 4.0407 - val_acc: 0.0962\n",
      "Epoch 153/250\n",
      " - 2s - loss: 3.9745 - acc: 0.1038 - val_loss: 4.0427 - val_acc: 0.0958\n",
      "Epoch 154/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1034 - val_loss: 4.0453 - val_acc: 0.0957\n",
      "Epoch 155/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1039 - val_loss: 4.0436 - val_acc: 0.0963\n",
      "Epoch 156/250\n",
      " - 2s - loss: 3.9731 - acc: 0.1040 - val_loss: 4.0456 - val_acc: 0.0954\n",
      "Epoch 157/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1030 - val_loss: 4.0454 - val_acc: 0.0956\n",
      "Epoch 158/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1025 - val_loss: 4.0418 - val_acc: 0.0961\n",
      "Epoch 159/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1034 - val_loss: 4.0440 - val_acc: 0.0962\n",
      "Epoch 160/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1033 - val_loss: 4.0459 - val_acc: 0.0958\n",
      "Epoch 161/250\n",
      " - 2s - loss: 3.9746 - acc: 0.1034 - val_loss: 4.0454 - val_acc: 0.0952\n",
      "Epoch 162/250\n",
      " - 2s - loss: 3.9747 - acc: 0.1040 - val_loss: 4.0456 - val_acc: 0.0954\n",
      "Epoch 163/250\n",
      " - 2s - loss: 3.9743 - acc: 0.1034 - val_loss: 4.0439 - val_acc: 0.0960\n",
      "Epoch 164/250\n",
      " - 2s - loss: 3.9747 - acc: 0.1028 - val_loss: 4.0458 - val_acc: 0.0956\n",
      "Epoch 165/250\n",
      " - 2s - loss: 3.9747 - acc: 0.1044 - val_loss: 4.0450 - val_acc: 0.0962\n",
      "Epoch 166/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1027 - val_loss: 4.0455 - val_acc: 0.0969\n",
      "Epoch 167/250\n",
      " - 2s - loss: 3.9779 - acc: 0.1032 - val_loss: 4.0461 - val_acc: 0.0968\n",
      "Epoch 168/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1026 - val_loss: 4.0443 - val_acc: 0.0954\n",
      "Epoch 169/250\n",
      " - 2s - loss: 3.9748 - acc: 0.1027 - val_loss: 4.0404 - val_acc: 0.0967\n",
      "Epoch 170/250\n",
      " - 2s - loss: 3.9770 - acc: 0.1023 - val_loss: 4.0452 - val_acc: 0.0962\n",
      "Epoch 171/250\n",
      " - 2s - loss: 3.9745 - acc: 0.1030 - val_loss: 4.0417 - val_acc: 0.0962\n",
      "Epoch 172/250\n",
      " - 2s - loss: 3.9746 - acc: 0.1035 - val_loss: 4.0443 - val_acc: 0.0969\n",
      "Epoch 173/250\n",
      " - 2s - loss: 3.9754 - acc: 0.1035 - val_loss: 4.0466 - val_acc: 0.0966\n",
      "Epoch 174/250\n",
      " - 2s - loss: 3.9757 - acc: 0.1036 - val_loss: 4.0436 - val_acc: 0.0962\n",
      "Epoch 175/250\n",
      " - 2s - loss: 3.9761 - acc: 0.1032 - val_loss: 4.0441 - val_acc: 0.0963\n",
      "Epoch 176/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1029 - val_loss: 4.0429 - val_acc: 0.0968\n",
      "Epoch 177/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1025 - val_loss: 4.0434 - val_acc: 0.0950\n",
      "Epoch 178/250\n",
      " - 2s - loss: 3.9750 - acc: 0.1038 - val_loss: 4.0474 - val_acc: 0.0961\n",
      "Epoch 179/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1042 - val_loss: 4.0426 - val_acc: 0.0959\n",
      "Epoch 180/250\n",
      " - 2s - loss: 3.9751 - acc: 0.1040 - val_loss: 4.0445 - val_acc: 0.0957\n",
      "Epoch 181/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1031 - val_loss: 4.0432 - val_acc: 0.0971\n",
      "Epoch 182/250\n",
      " - 2s - loss: 3.9771 - acc: 0.1042 - val_loss: 4.0452 - val_acc: 0.0961\n",
      "Epoch 183/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1035 - val_loss: 4.0488 - val_acc: 0.0952\n",
      "Epoch 184/250\n",
      " - 2s - loss: 3.9787 - acc: 0.1033 - val_loss: 4.0447 - val_acc: 0.0966\n",
      "Epoch 185/250\n",
      " - 2s - loss: 3.9744 - acc: 0.1036 - val_loss: 4.0416 - val_acc: 0.0961\n",
      "Epoch 186/250\n",
      " - 2s - loss: 3.9748 - acc: 0.1030 - val_loss: 4.0427 - val_acc: 0.0962\n",
      "Epoch 187/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1033 - val_loss: 4.0422 - val_acc: 0.0972\n",
      "Epoch 188/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1041 - val_loss: 4.0422 - val_acc: 0.0962\n",
      "Epoch 189/250\n",
      " - 2s - loss: 3.9740 - acc: 0.1043 - val_loss: 4.0413 - val_acc: 0.0963\n",
      "Epoch 190/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1031 - val_loss: 4.0480 - val_acc: 0.0949\n",
      "Epoch 191/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1040 - val_loss: 4.0432 - val_acc: 0.0964\n",
      "Epoch 192/250\n",
      " - 2s - loss: 3.9759 - acc: 0.1040 - val_loss: 4.0421 - val_acc: 0.0968\n",
      "Epoch 193/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1030 - val_loss: 4.0470 - val_acc: 0.0960\n",
      "Epoch 194/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1036 - val_loss: 4.0426 - val_acc: 0.0963\n",
      "Epoch 195/250\n",
      " - 2s - loss: 3.9762 - acc: 0.1032 - val_loss: 4.0438 - val_acc: 0.0956\n",
      "Epoch 196/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1031 - val_loss: 4.0405 - val_acc: 0.0966\n",
      "Epoch 197/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1034 - val_loss: 4.0448 - val_acc: 0.0954\n",
      "Epoch 198/250\n",
      " - 2s - loss: 3.9744 - acc: 0.1037 - val_loss: 4.0449 - val_acc: 0.0945\n",
      "Epoch 199/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1031 - val_loss: 4.0454 - val_acc: 0.0956\n",
      "Epoch 200/250\n",
      " - 2s - loss: 3.9736 - acc: 0.1048 - val_loss: 4.0439 - val_acc: 0.0961\n",
      "Epoch 201/250\n",
      " - 2s - loss: 3.9747 - acc: 0.1039 - val_loss: 4.0445 - val_acc: 0.0952\n",
      "Epoch 202/250\n",
      " - 2s - loss: 3.9737 - acc: 0.1034 - val_loss: 4.0426 - val_acc: 0.0958\n",
      "Epoch 203/250\n",
      " - 2s - loss: 3.9776 - acc: 0.1028 - val_loss: 4.0409 - val_acc: 0.0964\n",
      "Epoch 204/250\n",
      " - 2s - loss: 3.9747 - acc: 0.1042 - val_loss: 4.0425 - val_acc: 0.0964\n",
      "Epoch 205/250\n",
      " - 2s - loss: 3.9753 - acc: 0.1039 - val_loss: 4.0435 - val_acc: 0.0962\n",
      "Epoch 206/250\n",
      " - 2s - loss: 3.9754 - acc: 0.1036 - val_loss: 4.0417 - val_acc: 0.0968\n",
      "Epoch 207/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1037 - val_loss: 4.0452 - val_acc: 0.0958\n",
      "Epoch 208/250\n",
      " - 2s - loss: 3.9739 - acc: 0.1033 - val_loss: 4.0421 - val_acc: 0.0962\n",
      "Epoch 209/250\n",
      " - 2s - loss: 3.9777 - acc: 0.1030 - val_loss: 4.0417 - val_acc: 0.0962\n",
      "Epoch 210/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1036 - val_loss: 4.0429 - val_acc: 0.0967\n",
      "Epoch 211/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1038 - val_loss: 4.0449 - val_acc: 0.0952\n",
      "Epoch 212/250\n",
      " - 2s - loss: 3.9754 - acc: 0.1029 - val_loss: 4.0430 - val_acc: 0.0965\n",
      "Epoch 213/250\n",
      " - 2s - loss: 3.9756 - acc: 0.1042 - val_loss: 4.0448 - val_acc: 0.0960\n",
      "Epoch 214/250\n",
      " - 2s - loss: 3.9740 - acc: 0.1042 - val_loss: 4.0417 - val_acc: 0.0962\n",
      "Epoch 215/250\n",
      " - 2s - loss: 3.9772 - acc: 0.1038 - val_loss: 4.0421 - val_acc: 0.0956\n",
      "Epoch 216/250\n",
      " - 2s - loss: 3.9748 - acc: 0.1031 - val_loss: 4.0417 - val_acc: 0.0959\n",
      "Epoch 217/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1039 - val_loss: 4.0450 - val_acc: 0.0962\n",
      "Epoch 218/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1036 - val_loss: 4.0428 - val_acc: 0.0958\n",
      "Epoch 219/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1037 - val_loss: 4.0449 - val_acc: 0.0962\n",
      "Epoch 220/250\n",
      " - 2s - loss: 3.9760 - acc: 0.1044 - val_loss: 4.0413 - val_acc: 0.0962\n",
      "Epoch 221/250\n",
      " - 2s - loss: 3.9746 - acc: 0.1041 - val_loss: 4.0403 - val_acc: 0.0965\n",
      "Epoch 222/250\n",
      " - 2s - loss: 3.9774 - acc: 0.1028 - val_loss: 4.0415 - val_acc: 0.0961\n",
      "Epoch 223/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1030 - val_loss: 4.0416 - val_acc: 0.0966\n",
      "Epoch 224/250\n",
      " - 2s - loss: 3.9745 - acc: 0.1039 - val_loss: 4.0429 - val_acc: 0.0968\n",
      "Epoch 225/250\n",
      " - 2s - loss: 3.9755 - acc: 0.1037 - val_loss: 4.0445 - val_acc: 0.0957\n",
      "Epoch 226/250\n",
      " - 2s - loss: 3.9742 - acc: 0.1039 - val_loss: 4.0447 - val_acc: 0.0956\n",
      "Epoch 227/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1033 - val_loss: 4.0413 - val_acc: 0.0962\n",
      "Epoch 228/250\n",
      " - 2s - loss: 3.9785 - acc: 0.1029 - val_loss: 4.0446 - val_acc: 0.0960\n",
      "Epoch 229/250\n",
      " - 2s - loss: 3.9734 - acc: 0.1037 - val_loss: 4.0415 - val_acc: 0.0962\n",
      "Epoch 230/250\n",
      " - 2s - loss: 3.9734 - acc: 0.1036 - val_loss: 4.0421 - val_acc: 0.0964\n",
      "Epoch 231/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1034 - val_loss: 4.0436 - val_acc: 0.0961\n",
      "Epoch 232/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1024 - val_loss: 4.0456 - val_acc: 0.0952\n",
      "Epoch 233/250\n",
      " - 2s - loss: 3.9754 - acc: 0.1037 - val_loss: 4.0396 - val_acc: 0.0965\n",
      "Epoch 234/250\n",
      " - 2s - loss: 3.9763 - acc: 0.1041 - val_loss: 4.0441 - val_acc: 0.0959\n",
      "Epoch 235/250\n",
      " - 2s - loss: 3.9766 - acc: 0.1027 - val_loss: 4.0471 - val_acc: 0.0948\n",
      "Epoch 236/250\n",
      " - 2s - loss: 3.9744 - acc: 0.1035 - val_loss: 4.0487 - val_acc: 0.0952\n",
      "Epoch 237/250\n",
      " - 2s - loss: 3.9769 - acc: 0.1040 - val_loss: 4.0467 - val_acc: 0.0958\n",
      "Epoch 238/250\n",
      " - 2s - loss: 3.9740 - acc: 0.1038 - val_loss: 4.0424 - val_acc: 0.0956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1044 - val_loss: 4.0424 - val_acc: 0.0951\n",
      "Epoch 240/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1037 - val_loss: 4.0466 - val_acc: 0.0958\n",
      "Epoch 241/250\n",
      " - 2s - loss: 3.9758 - acc: 0.1039 - val_loss: 4.0430 - val_acc: 0.0962\n",
      "Epoch 242/250\n",
      " - 2s - loss: 3.9732 - acc: 0.1032 - val_loss: 4.0401 - val_acc: 0.0958\n",
      "Epoch 243/250\n",
      " - 2s - loss: 3.9775 - acc: 0.1029 - val_loss: 4.0427 - val_acc: 0.0964\n",
      "Epoch 244/250\n",
      " - 2s - loss: 3.9768 - acc: 0.1034 - val_loss: 4.0406 - val_acc: 0.0956\n",
      "Epoch 245/250\n",
      " - 2s - loss: 3.9752 - acc: 0.1039 - val_loss: 4.0444 - val_acc: 0.0950\n",
      "Epoch 246/250\n",
      " - 2s - loss: 3.9765 - acc: 0.1038 - val_loss: 4.0421 - val_acc: 0.0960\n",
      "Epoch 247/250\n",
      " - 2s - loss: 3.9749 - acc: 0.1035 - val_loss: 4.0430 - val_acc: 0.0966\n",
      "Epoch 248/250\n",
      " - 2s - loss: 3.9735 - acc: 0.1045 - val_loss: 4.0430 - val_acc: 0.0963\n",
      "Epoch 249/250\n",
      " - 2s - loss: 3.9764 - acc: 0.1037 - val_loss: 4.0419 - val_acc: 0.0960\n",
      "Epoch 250/250\n",
      " - 2s - loss: 3.9750 - acc: 0.1033 - val_loss: 4.0444 - val_acc: 0.0960\n",
      "Mini-Train:  10 Test Accuracy: 9.60% Learning Rate: 0.0002500\n"
     ]
    }
   ],
   "source": [
    "LR = 0.005\n",
    "DECAY = 1e-4\n",
    "DO = 0.15\n",
    "EPOCHS = 250\n",
    "MINI_TRAINS = 10\n",
    "\n",
    "X_train = data_dict[\"X_train_1\"]\n",
    "y_train = to_categorical(data_dict[\"y_train_1\"], 128)\n",
    "X_test = data_dict[\"X_test_1\"]\n",
    "y_test = to_categorical(data_dict[\"y_test_1\"], 128)\n",
    "\n",
    "_input = Input(shape=(12,))\n",
    "x = Dense(128)(_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(DO)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = Dense(256)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(DO)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "x = Dense(128)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(DO)(x)\n",
    "x = Activation(\"relu\")(x)\n",
    "\n",
    "output = Dense(128, activation='softmax')(x)\n",
    "model = Model(inputs=_input, outputs=output)\n",
    "\n",
    "OPTIMIZER = Adam(lr=LR, decay=DECAY)\n",
    "\n",
    "model.compile(optimizer=OPTIMIZER, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "for idx in range(MINI_TRAINS):\n",
    "    temp_lr = LR / (2 * (idx + 1))\n",
    "    \n",
    "    K.set_value(OPTIMIZER.lr, temp_lr)\n",
    "    \n",
    "#     print(\"\\nMini-Train: {:3d} Learning Rate: {:2.7f}\".format((idx + 1), temp_lr))\n",
    "    \n",
    "    model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=EPOCHS, batch_size=1024, verbose=2)\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, batch_size=1024, verbose=0)\n",
    "    \n",
    "    print(\"Mini-Train: {:3d} Test Accuracy: {:2.2f}% Learning Rate: {:2.7f}\".format((idx + 1), score[1] * 100, temp_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression()\n",
    "\n",
    "logit.fit(X_train, data_dict[\"y_train_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04146469278134416\n"
     ]
    }
   ],
   "source": [
    "score = logit.score(X_test, data_dict[\"y_test_1\"])\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04100615747412551\n"
     ]
    }
   ],
   "source": [
    "logit2 = LogisticRegression(C=1e5)\n",
    "\n",
    "logit2.fit(X_train, data_dict[\"y_train_1\"])\n",
    "score = logit2.score(X_test, data_dict[\"y_test_1\"])\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
